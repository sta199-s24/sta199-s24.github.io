[
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you‚Äôre having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you‚Äôll find an entry called Container Manager (CMGR Coursework Containers).\n\nIf the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it‚Äôs been resolved. If there‚Äôs a deadline coming up soon, post on the Ed Discussions to let us know that there‚Äôs an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don‚Äôt anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you‚Äôve tried and the errors you see (including verbatim errors and/or screenshots).\n\nAnother approach is to request a restart of your container. To do so, select your container as you usually do and then, instead of Login, click on Request Restart. Read the warning in the next page, and then click once more to restart your container.",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 199: Introduction to Data Science and Statistical Thinking",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses and the timeline of topics and assignments might be updated throughout the semester.\n\n\n\n\n\n\n\n\nWEEK\nDATE\nPREPARE\nTOPIC\nMATERIALS\nDUE\n\n\n\n\n1\nWed, Jan 10\n\n\nLab 0: Hello, World and STA 199!\nüíª lab 0\n\n\n\n\n\n\nThu, Jan 11\n\n\nWelcome to STA 199\nüñ•Ô∏è slides 00  ‚å®Ô∏è ae 00\n\n\n\n\n2\nMon, Jan 15\n\n\nNo lab - Martin Luther King Jr.¬†Day holiday\n\n\n\n\n\n\n\n\nTue, Jan 16\nüìó r4ds - intro  üìò ims - chp 1\nMeet the toolkit\nüñ•Ô∏è slides 01  ‚å®Ô∏è ae 01\n\n\n\n\n\n\nThu, Jan 18\nüìó r4ds - chp 1  üé• Data and visualization  üé• Visualising data with ggplot2\nGrammar of graphics\nüñ•Ô∏è slides 02  ‚å®Ô∏è ae 02  ‚úÖ ae 02\n\n\n\n\n3\nMon, Jan 22\nüìó r4ds - chp 2\nLab 1: Data visualization\nüíª lab 1  ‚úÖ lab 1\n\n\n\n\n\n\nTue, Jan 23\nüìò ims - chp 4  üìò ims - chp 5  üé• Visualizing numerical data  üé• Visualizing categorical data\nVisualizing various types of data\nüñ•Ô∏è slides 03  ‚å®Ô∏è ae 02 (cont.)  ‚úÖ ae 02\n\n\n\n\n\n\nThu, Jan 25\nüìò ims - chp 6\nData visualization overview\nüñ•Ô∏è slides 04  ‚å®Ô∏è ae 03  ‚úÖ ae 03\n\n\n\n\n4\nMon, Jan 29\nüé• Grammar of data wrangling  üìó r4ds - chp 3.1-3.5\nLab 2: Data wrangling\nüíª lab 2  ‚úÖ lab 2\nLab 1 at 8 am\n\n\n\n\nTue, Jan 30\nüé• Working with a single data frame  üìó r4ds - chp 3.6-3.7  üìó r4ds - chp 4\nGrammar of data wrangling\nüñ•Ô∏è slides 05  ‚å®Ô∏è ae 04  ‚úÖ ae 04\n\n\n\n\n\n\nThu, Feb 1\nüé• Tidying data  üìó r4ds - chp 5\nTidying data\nüñ•Ô∏è slides 06  ‚å®Ô∏è ae 05  ‚úÖ ae 05\n\n\n\n\n5\nMon, Feb 5\nüé• Working with multiple data frames\nLab 3: Data tidying and joining\nüíª lab 3  ‚úÖ lab 3\nLab 2 at 8 am\n\n\n\n\nTue, Feb 6\nüìó r4ds - chp 19.1-19.3\nJoining data\nüñ•Ô∏è slides 07  ‚å®Ô∏è ae 06  ‚úÖ ae 06\n\n\n\n\n\n\nThu, Feb 8\nüé• Data types  üé• Data classes  üìó r4ds - chp 16\nData types and classes\nüñ•Ô∏è slides 08  ‚å®Ô∏è ae 07  ‚úÖ ae 07\n\n\n\n\n6\nMon, Feb 12\n\n\nWork on Exam 1 Review\nüìù exam 1 review  ‚úÖ exam 1 review\nLab 3 at 8 am\n\n\n\n\nTue, Feb 13\n\n\nExam 1 Review\nüñ•Ô∏è slides 09\n\n\n\n\n\n\nThu, Feb 15\n\n\nExam 1 - In-class + take-home released\n\n\n\n\n\n\n7\nMon, Feb 19\n\n\nProject milestone 1 - Working collaboratively\nüìì project milestone 1\nExam 1 take-home at 8 am\n\n\n\n\nTue, Feb 20\nüé• Importing data  üé• Recoding data  üìó r4ds - chp 7  üìó r4ds - chp 17.1 - 17.3\nImporting and recoding data\nüñ•Ô∏è slides 10  ‚å®Ô∏è ae 08  ‚úÖ ae 08\n\n\n\n\n\n\nThu, Feb 22\nüé• Web scraping  üé• Scraping top 250 movies on IMDB  üé• Web scraping considerations  üìó r4ds - chp 24.1 - 24.6\nWeb scraping\nüñ•Ô∏è slides 11  ‚å®Ô∏è ae 09  ‚å®Ô∏è ae 09  ‚úÖ ae 09\n\n\n\n\n8\nMon, Feb 26\n\n\nLab 4: Web scraping and ethics\nüíª lab 4\nProject milestone 1 at 8 am\n\n\n\n\nTue, Feb 27\nüé• Functions  üé• Iteration üìó r4ds - chp 25.1 - 25.2\nWorking with Chat GPT\nüñ•Ô∏è slides 12  ‚å®Ô∏è ae 09  ‚úÖ ae 09\n\n\n\n\n\n\nThu, Feb 29\nüé• Misrepresentation  üé• Data privacy  üé• Algorithmic bias  üìï mdsr - chp 8  üé• Alberto Cairo - How charts lie  üé• Joy Buolamwini - How I‚Äôm fighting bias in algorithms\nData science ethics\nüñ•Ô∏è slides 13\n\n\n\n\n9\nMon, Mar 4\n\n\nLab 5: Topic TBA\nüíª lab 5\nLab 4 at 8 am\n\n\n\n\nTue, Mar 5\nüé• The language of models  üìò ims - chp 7.1\nThe language of models\nüñ•Ô∏è slides 14  ‚å®Ô∏è ae 10  ‚úÖ ae 10\n\n\n\n\n\n\nThu, Mar 7\nüé• Fitting and interpreting models  üé• Modeling nonlinear relationships  üìò ims - chp 7.2\nLinear regression with a single predictor\nüñ•Ô∏è slides 15  ‚å®Ô∏è ae 11  ‚úÖ ae 11\n\n\n\n\n10\nMon, Mar 11\n\n\nüå¥ No lab - Spring Break\n\n\n\n\n\n\n\n\nTue, Mar 12\n\n\nüå¥ No lecture - Spring Break\n\n\n\n\n\n\n\n\nThu, Mar 14\n\n\nüå¥ No lecture - Spring Break\n\n\n\n\n\n\n11\nMon, Mar 18\n\n\nProject milestone 2 - Project proposals\nüìì project milestone 2\nLab 5 at 8 am\n\n\n\n\nTue, Mar 19\nüé• Models with multiple predictors  üé• More models with multiple predictors  üìò ims - chp 8.1-8.2\nLinear regression with multiple predictors I\nüñ•Ô∏è slides 16  ‚å®Ô∏è ae 12  ‚úÖ ae 12\n\n\n\n\n\n\nThu, Mar 21\nüìò ims - chp 8.3-8.5\nLinear regression with multiple predictors II\nüñ•Ô∏è slides 17\n\n\n\n\n12\nMon, Mar 25\n\n\nLab 6: Modeling I\nüíª lab 6\nProject milestone 2 at 8 am\n\n\n\n\nTue, Mar 26\nüé• Logistic regression  üé• Prediction and overfitting\nModel selection and overfitting\nüñ•Ô∏è slides 18 ‚å®Ô∏è ae 13  ‚úÖ ae 13\n\n\n\n\n\n\nThu, Mar 28\nüìò ims - chp 9\nLogistic regression\nüñ•Ô∏è slides 19  ‚å®Ô∏è ae 14\n\n\n\n\n13\nMon, Apr 1\n\n\nLab 7: Modeling II\nüíª lab 7\nLab 6 at 8 am\n\n\n\n\nTue, Apr 2\nüé• Quantifying uncertainty  üé• Bootstrapping  üìò ims - chp 12\nQuantifying uncertainty with bootstrap intervals\n\n\n\n\n\n\n\n\nThu, Apr 4\nüìò ims - chp 11\nMaking decisions with randomization tests\n\n\n\n\n\n\n14\nMon, Apr 8\n\n\nWork on Exam 2 Review\n\n\nLab 7 at 8 am\n\n\n\n\nTue, Apr 9\n\n\nExam 2 Review\n\n\n\n\n\n\n\n\nThu, Apr 11\n\n\nExam 2 - In-class + take-home released\n\n\n\n\n\n\n15\nMon, Apr 15\n\n\nProject milestone 3 - Peer review\nüìì project milestone 3\nExam 2 take-home at 8 am  Project milestone 3 at the end of lab session\n\n\n\n\nTue, Apr 16\n\n\nCommunicating data science results effectively\n\n\n\n\n\n\n\n\nThu, Apr 18\n\n\nCustomizing Quarto reports and presentations\n\n\n\n\n\n\n16\nMon, Apr 22\n\n\nProject milestone 4 - Project presentations\nüìì project milestone 4\nProject presentations + writeup at the beginning of lab session\n\n\n\n\nTue, Apr 23\n\n\nLooking further: Topic TBA",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "computing-cheatsheets.html",
    "href": "computing-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://www.rstudio.com/resources/cheatsheets. We haven‚Äôt covered every function and functionality listed on them, but you might still find them useful as references.",
    "crumbs": [
      "Computing",
      "Cheatsheets"
    ]
  },
  {
    "objectID": "slides/07-joining-data.html#while-you-wait-for-class-to-begin",
    "href": "slides/07-joining-data.html#while-you-wait-for-class-to-begin",
    "title": "Joining data",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\n\nGo to your ae repo, click Pull to get today‚Äôs application exercise to get ready for later.\nQuestions from the prepare materials?"
  },
  {
    "objectID": "slides/07-joining-data.html#announcements",
    "href": "slides/07-joining-data.html#announcements",
    "title": "Joining data",
    "section": "Announcements",
    "text": "Announcements\n\nExam 1 in class next week on Thursday ‚Äì cheat sheet (1 page, both sides, hand-written or typed, must be prepared by you)\nExam 1 take home starts after class on Thursday, due at 8 am on Monday (open resources, internet, etc., closed to other humans)\nNext week in lab: Exam 1 review ‚Äì come with questions!\nNo new lab assigned next week during exam"
  },
  {
    "objectID": "slides/07-joining-data.html#study-tips-for-the-exam",
    "href": "slides/07-joining-data.html#study-tips-for-the-exam",
    "title": "Joining data",
    "section": "Study tips for the exam",
    "text": "Study tips for the exam\n\nGo over lecture materials and application exercises\nReview labs and feedback you‚Äôve received so far\nDo the exercises at the end of readings from both books\nDo the exam review over (to be posted on Friday)\nGo to lab on Monday with questions"
  },
  {
    "objectID": "slides/07-joining-data.html#questions-from-last-time",
    "href": "slides/07-joining-data.html#questions-from-last-time",
    "title": "Joining data",
    "section": "Questions from last time",
    "text": "Questions from last time\nIs there a limit to a tibble size?\nNo, a tibble (i.e., a data frame) can be any number of rows or columns. However when you print it, it will only print the first 10 rows and the columns that fit across the screen, document, etc.\nIf you want to see more rows and columns, you can\n\nopen it in the data viewer with view(df)\nexplicitly print more rows with, e.g., df |&gt; print(n = 25)\nexplicitly select() or relocate() columns"
  },
  {
    "objectID": "slides/07-joining-data.html#options-for-a-tibble",
    "href": "slides/07-joining-data.html#options-for-a-tibble",
    "title": "Joining data",
    "section": "Options for a tibble",
    "text": "Options for a tibble\n\nDefaultprint()select()relocate()\n\n\n\nlibrary(tidyverse)\nmidwest\n\n# A tibble: 437 √ó 28\n     PID county   state  area poptotal popdensity popwhite popblack popamerindian popasian\n   &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;    &lt;int&gt;\n 1   561 ADAMS    IL    0.052    66090      1271.    63917     1702            98      249\n 2   562 ALEXAND‚Ä¶ IL    0.014    10626       759      7054     3496            19       48\n 3   563 BOND     IL    0.022    14991       681.    14477      429            35       16\n 4   564 BOONE    IL    0.017    30806      1812.    29344      127            46      150\n 5   565 BROWN    IL    0.018     5836       324.     5264      547            14        5\n 6   566 BUREAU   IL    0.05     35688       714.    35157       50            65      195\n 7   567 CALHOUN  IL    0.017     5322       313.     5298        1             8       15\n 8   568 CARROLL  IL    0.027    16805       622.    16519      111            30       61\n 9   569 CASS     IL    0.024    13437       560.    13384       16             8       23\n10   570 CHAMPAI‚Ä¶ IL    0.058   173025      2983.   146506    16559           331     8033\n# ‚Ñπ 427 more rows\n# ‚Ñπ 18 more variables: popother &lt;int&gt;, percwhite &lt;dbl&gt;, percblack &lt;dbl&gt;,\n#   percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;, popadults &lt;int&gt;,\n#   perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;, poppovertyknown &lt;int&gt;,\n#   percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;, percchildbelowpovert &lt;dbl&gt;,\n#   percadultpoverty &lt;dbl&gt;, percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\n\n\n\nmidwest |&gt;\n  print(n = 13)\n\n# A tibble: 437 √ó 28\n     PID county   state  area poptotal popdensity popwhite popblack popamerindian popasian\n   &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;    &lt;int&gt;\n 1   561 ADAMS    IL    0.052    66090      1271.    63917     1702            98      249\n 2   562 ALEXAND‚Ä¶ IL    0.014    10626       759      7054     3496            19       48\n 3   563 BOND     IL    0.022    14991       681.    14477      429            35       16\n 4   564 BOONE    IL    0.017    30806      1812.    29344      127            46      150\n 5   565 BROWN    IL    0.018     5836       324.     5264      547            14        5\n 6   566 BUREAU   IL    0.05     35688       714.    35157       50            65      195\n 7   567 CALHOUN  IL    0.017     5322       313.     5298        1             8       15\n 8   568 CARROLL  IL    0.027    16805       622.    16519      111            30       61\n 9   569 CASS     IL    0.024    13437       560.    13384       16             8       23\n10   570 CHAMPAI‚Ä¶ IL    0.058   173025      2983.   146506    16559           331     8033\n11   571 CHRISTI‚Ä¶ IL    0.042    34418       819.    34176       82            51       89\n12   572 CLARK    IL    0.03     15921       531.    15842       10            26       36\n13   573 CLAY     IL    0.028    14460       516.    14403        4            17       29\n# ‚Ñπ 424 more rows\n# ‚Ñπ 18 more variables: popother &lt;int&gt;, percwhite &lt;dbl&gt;, percblack &lt;dbl&gt;,\n#   percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;, popadults &lt;int&gt;,\n#   perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;, poppovertyknown &lt;int&gt;,\n#   percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;, percchildbelowpovert &lt;dbl&gt;,\n#   percadultpoverty &lt;dbl&gt;, percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\n\n\n\nmidwest |&gt;\n  select(county, state, percbelowpoverty, percollege)\n\n# A tibble: 437 √ó 4\n   county    state percbelowpoverty percollege\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n 1 ADAMS     IL               13.2        19.6\n 2 ALEXANDER IL               32.2        11.2\n 3 BOND      IL               12.1        17.0\n 4 BOONE     IL                7.21       17.3\n 5 BROWN     IL               13.5        14.5\n 6 BUREAU    IL               10.4        18.9\n 7 CALHOUN   IL               15.1        11.9\n 8 CARROLL   IL               11.7        16.2\n 9 CASS      IL               13.9        14.1\n10 CHAMPAIGN IL               15.6        41.3\n# ‚Ñπ 427 more rows\n\n\n\n\n\nmidwest |&gt;\n  relocate(county, state, percbelowpoverty, percollege)\n\n# A tibble: 437 √ó 28\n   county    state percbelowpoverty percollege   PID  area poptotal popdensity popwhite\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;\n 1 ADAMS     IL               13.2        19.6   561 0.052    66090      1271.    63917\n 2 ALEXANDER IL               32.2        11.2   562 0.014    10626       759      7054\n 3 BOND      IL               12.1        17.0   563 0.022    14991       681.    14477\n 4 BOONE     IL                7.21       17.3   564 0.017    30806      1812.    29344\n 5 BROWN     IL               13.5        14.5   565 0.018     5836       324.     5264\n 6 BUREAU    IL               10.4        18.9   566 0.05     35688       714.    35157\n 7 CALHOUN   IL               15.1        11.9   567 0.017     5322       313.     5298\n 8 CARROLL   IL               11.7        16.2   568 0.027    16805       622.    16519\n 9 CASS      IL               13.9        14.1   569 0.024    13437       560.    13384\n10 CHAMPAIGN IL               15.6        41.3   570 0.058   173025      2983.   146506\n# ‚Ñπ 427 more rows\n# ‚Ñπ 19 more variables: popblack &lt;int&gt;, popamerindian &lt;int&gt;, popasian &lt;int&gt;,\n#   popother &lt;int&gt;, percwhite &lt;dbl&gt;, percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;,\n#   percasian &lt;dbl&gt;, percother &lt;dbl&gt;, popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percchildbelowpovert &lt;dbl&gt;,\n#   percadultpoverty &lt;dbl&gt;, percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;"
  },
  {
    "objectID": "slides/07-joining-data.html#from-last-time-pivoting",
    "href": "slides/07-joining-data.html#from-last-time-pivoting",
    "title": "Joining data",
    "section": "From last time: pivoting",
    "text": "From last time: pivoting\n\n\nData sets can‚Äôt be labeled as wide or long but they can be made wider or longer for a certain analysis that requires a certain format\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do so within the pivot_longer() function.\nYou can tweak a plot forever, but at some point the tweaks are likely not very productive. However, you should always be critical of defaults (however pretty they might be) and see if you can improve the plot to better portray your data / results / what you want to communicate."
  },
  {
    "objectID": "slides/07-joining-data.html#why-join",
    "href": "slides/07-joining-data.html#why-join",
    "title": "Joining data",
    "section": "Why join?",
    "text": "Why join?\nSuppose we want to answer questions like:\n\nIs there a relationship between\n- number of QS courses taken\n- having scored a 4 or 5 on the AP stats exam\n- motivation for taking course\n- ‚Ä¶\nand performance in this course?‚Äù\n\n\nEach of these would require joining class performance data with an outside data source so we can have all relevant information (columns) in a single data frame."
  },
  {
    "objectID": "slides/07-joining-data.html#setup",
    "href": "slides/07-joining-data.html#setup",
    "title": "Joining data",
    "section": "Setup",
    "text": "Setup\nFor the next few slides‚Ä¶\n\n\n\nx &lt;- tibble(\n  id = c(1, 2, 3),\n  value_x = c(\"x1\", \"x2\", \"x3\")\n  )\n\nx\n\n# A tibble: 3 √ó 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2     \n3     3 x3     \n\n\n\n\ny &lt;- tibble(\n  id = c(1, 2, 4),\n  value_y = c(\"y1\", \"y2\", \"y4\")\n  )\n\ny\n\n# A tibble: 3 √ó 2\n     id value_y\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 y1     \n2     2 y2     \n3     4 y4"
  },
  {
    "objectID": "slides/07-joining-data.html#left_join",
    "href": "slides/07-joining-data.html#left_join",
    "title": "Joining data",
    "section": "left_join()",
    "text": "left_join()\n\n\n\n\n\nleft_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 3 √ó 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;"
  },
  {
    "objectID": "slides/07-joining-data.html#right_join",
    "href": "slides/07-joining-data.html#right_join",
    "title": "Joining data",
    "section": "right_join()",
    "text": "right_join()\n\n\n\n\n\nright_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 3 √ó 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "slides/07-joining-data.html#full_join",
    "href": "slides/07-joining-data.html#full_join",
    "title": "Joining data",
    "section": "full_join()",
    "text": "full_join()\n\n\n\n\n\nfull_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 4 √ó 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;   \n4     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "slides/07-joining-data.html#inner_join",
    "href": "slides/07-joining-data.html#inner_join",
    "title": "Joining data",
    "section": "inner_join()",
    "text": "inner_join()\n\n\n\n\n\ninner_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 2 √ó 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2"
  },
  {
    "objectID": "slides/07-joining-data.html#semi_join",
    "href": "slides/07-joining-data.html#semi_join",
    "title": "Joining data",
    "section": "semi_join()",
    "text": "semi_join()\n\n\n\n\n\nsemi_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 2 √ó 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2"
  },
  {
    "objectID": "slides/07-joining-data.html#anti_join",
    "href": "slides/07-joining-data.html#anti_join",
    "title": "Joining data",
    "section": "anti_join()",
    "text": "anti_join()\n\n\n\n\n\nanti_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 1 √ó 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     3 x3"
  },
  {
    "objectID": "slides/07-joining-data.html#nycflights13-airport-capacity",
    "href": "slides/07-joining-data.html#nycflights13-airport-capacity",
    "title": "Joining data",
    "section": "nycflights13 & airport capacity",
    "text": "nycflights13 & airport capacity\nYou‚Äôve previously seen the flights data available in the nycflights13 package which details all flights from one of the 3 major NYC airports in 2013.\nToday we would like to answer a specific question:\n\nWhat was the passenger capacity (i.e., maximum number of passengers) that could have flown out of the three airports in 2013?\n\n\nTo answer this we will need to know how many passenger seats each plane had available - each flight record has a tailnum which is a unique identifier for the plane, this can be linked to the planes data set which has the number of available seats for each plane."
  },
  {
    "objectID": "slides/07-joining-data.html#attempt-1",
    "href": "slides/07-joining-data.html#attempt-1",
    "title": "Joining data",
    "section": "Attempt 1",
    "text": "Attempt 1\n\nlibrary(nycflights13)\n\nleft_join(flights, planes) |&gt;\n  group_by(origin) |&gt;\n  summarize(capacity = sum(seats))\n\n\n\nJoining with `by = join_by(year, tailnum)`\n\n\n# A tibble: 3 √ó 2\n  origin capacity\n  &lt;chr&gt;     &lt;int&gt;\n1 EWR          NA\n2 JFK          NA\n3 LGA          NA"
  },
  {
    "objectID": "slides/07-joining-data.html#attempt-2",
    "href": "slides/07-joining-data.html#attempt-2",
    "title": "Joining data",
    "section": "Attempt 2",
    "text": "Attempt 2\n\nleft_join(flights, planes) |&gt;\n  group_by(origin) |&gt;\n  summarize(capacity = sum(seats, na.rm = TRUE))\n\n\n\nJoining with `by = join_by(year, tailnum)`\n\n\n# A tibble: 3 √ó 2\n  origin capacity\n  &lt;chr&gt;     &lt;int&gt;\n1 EWR      345268\n2 JFK      179412\n3 LGA       89686"
  },
  {
    "objectID": "slides/07-joining-data.html#attempt-3",
    "href": "slides/07-joining-data.html#attempt-3",
    "title": "Joining data",
    "section": "Attempt 3",
    "text": "Attempt 3\n\nleft_join(\n  flights, planes,\n  by = c(\"tailnum\" = \"tailnum\")\n) |&gt;\n  group_by(origin) |&gt;\n  summarize(capacity = sum(seats, na.rm = TRUE))\n\n\n\n# A tibble: 3 √ó 2\n  origin capacity\n  &lt;chr&gt;     &lt;int&gt;\n1 EWR    14454251\n2 JFK    13874081\n3 LGA    10522985"
  },
  {
    "objectID": "slides/07-joining-data.html#goal",
    "href": "slides/07-joining-data.html#goal",
    "title": "Joining data",
    "section": "Goal",
    "text": "Goal\nMake a bar plot of total populations of continents, where the input data are:\n\nCountries and populations\nCountries and continents"
  },
  {
    "objectID": "slides/07-joining-data.html#ae-06-population-joining",
    "href": "slides/07-joining-data.html#ae-06-population-joining",
    "title": "Joining data",
    "section": "ae-06-population-joining",
    "text": "ae-06-population-joining\n\n\nGo to the project navigator in RStudio (top right corner of your RStudio window) and open the project called ae.\nIf there are any uncommitted files, commit them, and then click Pull.\nOpen the file called ae-06-population-joining.qmd and render it.\n\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II.html#while-you-wait-for-class-to-begin",
    "href": "slides/17-linear-model-multiple-predictors-II.html#while-you-wait-for-class-to-begin",
    "title": "Linear regression with a multiple predictors II",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\n\nAny questions from prepare materials?"
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II.html#project-proposals",
    "href": "slides/17-linear-model-multiple-predictors-II.html#project-proposals",
    "title": "Linear regression with a multiple predictors II",
    "section": "Project proposals",
    "text": "Project proposals\n\nAny questions?"
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II.html#application-exercise-ae-12-modeling-penguins-multi",
    "href": "slides/17-linear-model-multiple-predictors-II.html#application-exercise-ae-12-modeling-penguins-multi",
    "title": "Linear regression with a multiple predictors II",
    "section": "Application exercise: ae-12-modeling-penguins-multi",
    "text": "Application exercise: ae-12-modeling-penguins-multi\n\nContinue work on ae-12-modeling-penguins-multi.qmd.\n\nGoals:\n\nRecap modeling with a single predictor\nFit and interpret models with multiple predictors\nDistinguish between additive and interaction models"
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II.html#goals",
    "href": "slides/17-linear-model-multiple-predictors-II.html#goals",
    "title": "Linear regression with a multiple predictors II",
    "section": "Goals",
    "text": "Goals\n\nReview prediction and interpretation of model results\nReview main and interaction effects models\nDiscuss model selection further"
  },
  {
    "objectID": "slides/17-linear-model-multiple-predictors-II.html#application-exercise-ae-13-modeling-loans",
    "href": "slides/17-linear-model-multiple-predictors-II.html#application-exercise-ae-13-modeling-loans",
    "title": "Linear regression with a multiple predictors II",
    "section": "Application exercise: ae-13-modeling-loans",
    "text": "Application exercise: ae-13-modeling-loans\n\n\nGo to your project called ae.\nIf there are any uncommitted files, commit them, and push.\nWork on ae-13-modeling-loans.qmd.\n\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/03-visualizing-data.html#while-you-wait",
    "href": "slides/03-visualizing-data.html#while-you-wait",
    "title": "Visualizing various types of data",
    "section": "While you wait‚Ä¶",
    "text": "While you wait‚Ä¶\nQuestions from the prepare materials?"
  },
  {
    "objectID": "slides/03-visualizing-data.html#questions-from-last-time",
    "href": "slides/03-visualizing-data.html#questions-from-last-time",
    "title": "Visualizing various types of data",
    "section": "Questions from last time",
    "text": "Questions from last time\n\n‚Ä¶"
  },
  {
    "objectID": "slides/03-visualizing-data.html#announcements",
    "href": "slides/03-visualizing-data.html#announcements",
    "title": "Visualizing various types of data",
    "section": "Announcements",
    "text": "Announcements\n\n‚Ä¶"
  },
  {
    "objectID": "slides/03-visualizing-data.html#violin-plots",
    "href": "slides/03-visualizing-data.html#violin-plots",
    "title": "Visualizing various types of data",
    "section": "Violin plots",
    "text": "Violin plots\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = species,\n    y = body_mass_g\n    )\n  ) +\n  geom_violin()\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#multiple-geoms",
    "href": "slides/03-visualizing-data.html#multiple-geoms",
    "title": "Visualizing various types of data",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = species,\n    y = body_mass_g\n    )\n  ) +\n  geom_violin() +\n  geom_point()\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#multiple-geoms-1",
    "href": "slides/03-visualizing-data.html#multiple-geoms-1",
    "title": "Visualizing various types of data",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = species,\n    y = body_mass_g\n    )\n  ) +\n  geom_violin() +\n  geom_jitter()\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#multiple-geoms-aesthetics",
    "href": "slides/03-visualizing-data.html#multiple-geoms-aesthetics",
    "title": "Visualizing various types of data",
    "section": "Multiple geoms + aesthetics",
    "text": "Multiple geoms + aesthetics\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = species,\n    y = body_mass_g,\n    color = species\n    )\n  ) +\n  geom_violin() +\n  geom_jitter()\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#multiple-geoms-aesthetics-1",
    "href": "slides/03-visualizing-data.html#multiple-geoms-aesthetics-1",
    "title": "Visualizing various types of data",
    "section": "Multiple geoms + aesthetics",
    "text": "Multiple geoms + aesthetics\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = species,\n    y = body_mass_g,\n    color = species\n    )\n  ) +\n  geom_violin() +\n  geom_jitter() +\n  theme(\n    legend.position = \"none\"\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#multiple-geoms-aesthetics-2",
    "href": "slides/03-visualizing-data.html#multiple-geoms-aesthetics-2",
    "title": "Visualizing various types of data",
    "section": "Multiple geoms + aesthetics",
    "text": "Multiple geoms + aesthetics\n::: columns ::: {.column width=‚Äú50%‚Äù}\n\nggplot(\n  penguins,\n  aes(\n    x = species,\n    y = body_mass_g,\n    color = species\n    )\n  ) +\n  geom_violin() +\n  geom_jitter() +\n  theme(\n    legend.position = \"none\"\n  ) +\n  scale_color_colorblind()\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n:::\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n:::‚Äî title: ‚ÄúVisualizing various types of data‚Äù subtitle: ‚ÄúLecture 3‚Äù date: ‚ÄúJanuary 23, 2024‚Äù format: revealjs"
  },
  {
    "objectID": "slides/03-visualizing-data.html#while-you-wait-1",
    "href": "slides/03-visualizing-data.html#while-you-wait-1",
    "title": "Visualizing various types of data",
    "section": "While you wait‚Ä¶",
    "text": "While you wait‚Ä¶\nQuestions from the prepare materials?"
  },
  {
    "objectID": "slides/03-visualizing-data.html#questions-from-last-time-1",
    "href": "slides/03-visualizing-data.html#questions-from-last-time-1",
    "title": "Visualizing various types of data",
    "section": "Questions from last time",
    "text": "Questions from last time\n\nIs there any code in the videos that is not in the readings? Yes and no. There is no substantial functionality introduced in the videos that is not also in the readings, however the examples in the videos are different than the ones in the reading.\nWhat are all of the geoms we need to know? You don‚Äôt need to ‚Äúmemorize‚Äù or even ‚Äúknow‚Äù all o the geoms available in the ggplot2 package, but you can find a list of them on the ggplot2 cheat sheet or on the reference page.\nCould you please clarify what situations it would be appropriate to use each geom function? Today‚Äôs topic! And think about it as ‚Äúwhat plot should I make for which type of variable‚Äù."
  },
  {
    "objectID": "slides/03-visualizing-data.html#announcements-1",
    "href": "slides/03-visualizing-data.html#announcements-1",
    "title": "Visualizing various types of data",
    "section": "Announcements",
    "text": "Announcements\n\nAEs this week should be submitted by midnight on Sunday. To ‚Äúsubmit‚Äù, commit and push at least once to your ae repo for each application exercise this week.\nIf you email me, please put STA 199 in the subject."
  },
  {
    "objectID": "slides/03-visualizing-data.html#ae-02-bechdel-dataviz",
    "href": "slides/03-visualizing-data.html#ae-02-bechdel-dataviz",
    "title": "Visualizing various types of data",
    "section": "ae-02-bechdel-dataviz",
    "text": "ae-02-bechdel-dataviz\n\n\nIf you were in class last Thursday:\nand followed along with the application exercise‚Ä¶\nGo to the project navigator in RStudio (top right corner of your RStudio window) and open the project called ae. If there are any uncommitted files, commit them so you can start with a clean slate.\n\nIf you missed class last Thursday:\nor didn‚Äôt follow along with the application exercise‚Ä¶\nGo to the course GitHub org and find your ae repo. Clone the repo in your container, open the Quarto document called ae-02-bechdel."
  },
  {
    "objectID": "slides/03-visualizing-data.html#recap-of-ae",
    "href": "slides/03-visualizing-data.html#recap-of-ae",
    "title": "Visualizing various types of data",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nConstruct plots with ggplot().\nLayers of ggplots are separated by +s.\nThe formula is (almost) always as follows:\n\n\nggplot(DATA, aes(x = X-VAR, y = Y-VAR, ...)) +\n  geom_XXX()\n\n\nAesthetic attributes of a geometries (color, size, transparency, etc.) can be mapped to variables in the data or set by the user, e.g.¬†color = binary vs.¬†color = \"pink\".\nUse facet_wrap() when faceting (creating small multiples) by one variable and facet_grid() when faceting by two variables."
  },
  {
    "objectID": "slides/03-visualizing-data.html#identifying-variable-types",
    "href": "slides/03-visualizing-data.html#identifying-variable-types",
    "title": "Visualizing various types of data",
    "section": "Identifying variable types",
    "text": "Identifying variable types\n\nQuestionVote\n\n\n\nIdentify the type of each of the following variables.\n\nFavorite food\nNumber of classes you‚Äôre taking this semester\nZip code\nAge"
  },
  {
    "objectID": "slides/03-visualizing-data.html#the-way-data-is-displayed-matters",
    "href": "slides/03-visualizing-data.html#the-way-data-is-displayed-matters",
    "title": "Visualizing various types of data",
    "section": "The way data is displayed matters",
    "text": "The way data is displayed matters\n\nWhat do these three plots show?\n\n\n\n\n\n\n\n\nSource: #barbarplots"
  },
  {
    "objectID": "slides/03-visualizing-data.html#visualizing-penguins",
    "href": "slides/03-visualizing-data.html#visualizing-penguins",
    "title": "Visualizing various types of data",
    "section": "Visualizing penguins",
    "text": "Visualizing penguins\n\n\n\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(ggthemes)\n\npenguins\n\n# A tibble: 344 √ó 8\n   species island   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex    year\n   &lt;fct&gt;   &lt;fct&gt;             &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt; &lt;fct&gt; &lt;int&gt;\n 1 Adelie  Torgers‚Ä¶           39.1          18.7               181        3750 male   2007\n 2 Adelie  Torgers‚Ä¶           39.5          17.4               186        3800 fema‚Ä¶  2007\n 3 Adelie  Torgers‚Ä¶           40.3          18                 195        3250 fema‚Ä¶  2007\n 4 Adelie  Torgers‚Ä¶           NA            NA                  NA          NA &lt;NA&gt;   2007\n 5 Adelie  Torgers‚Ä¶           36.7          19.3               193        3450 fema‚Ä¶  2007\n 6 Adelie  Torgers‚Ä¶           39.3          20.6               190        3650 male   2007\n 7 Adelie  Torgers‚Ä¶           38.9          17.8               181        3625 fema‚Ä¶  2007\n 8 Adelie  Torgers‚Ä¶           39.2          19.6               195        4675 male   2007\n 9 Adelie  Torgers‚Ä¶           34.1          18.1               193        3475 &lt;NA&gt;   2007\n10 Adelie  Torgers‚Ä¶           42            20.2               190        4250 &lt;NA&gt;   2007\n# ‚Ñπ 334 more rows\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtwork by @allison_horst."
  },
  {
    "objectID": "slides/03-visualizing-data.html#univariate-analysis-1",
    "href": "slides/03-visualizing-data.html#univariate-analysis-1",
    "title": "Visualizing various types of data",
    "section": "Univariate analysis",
    "text": "Univariate analysis\nAnalyzing a single variable:\n\nNumerical: histogram, box plot, density plot, etc.\nCategorical: bar plot, pie chart, etc."
  },
  {
    "objectID": "slides/03-visualizing-data.html#histogram---step-1",
    "href": "slides/03-visualizing-data.html#histogram---step-1",
    "title": "Visualizing various types of data",
    "section": "Histogram - Step 1",
    "text": "Histogram - Step 1\n\n\n\nggplot(\n  penguins\n  )"
  },
  {
    "objectID": "slides/03-visualizing-data.html#histogram---step-2",
    "href": "slides/03-visualizing-data.html#histogram---step-2",
    "title": "Visualizing various types of data",
    "section": "Histogram - Step 2",
    "text": "Histogram - Step 2\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  )"
  },
  {
    "objectID": "slides/03-visualizing-data.html#histogram---step-3",
    "href": "slides/03-visualizing-data.html#histogram---step-3",
    "title": "Visualizing various types of data",
    "section": "Histogram - Step 3",
    "text": "Histogram - Step 3\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  ) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#histogram---step-4",
    "href": "slides/03-visualizing-data.html#histogram---step-4",
    "title": "Visualizing various types of data",
    "section": "Histogram - Step 4",
    "text": "Histogram - Step 4\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  ) +\n  geom_histogram(\n    binwidth = 250\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#histogram---step-5",
    "href": "slides/03-visualizing-data.html#histogram---step-5",
    "title": "Visualizing various types of data",
    "section": "Histogram - Step 5",
    "text": "Histogram - Step 5\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  ) +\n  geom_histogram(\n    binwidth = 250\n  ) +\n  labs(\n    title = \"Weights of penguins\",\n    x = \"Weight (grams)\",\n    y = \"Count\"\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#boxplot---step-1",
    "href": "slides/03-visualizing-data.html#boxplot---step-1",
    "title": "Visualizing various types of data",
    "section": "Boxplot - Step 1",
    "text": "Boxplot - Step 1\n\n\n\nggplot(\n  penguins\n  )"
  },
  {
    "objectID": "slides/03-visualizing-data.html#boxplot---step-2",
    "href": "slides/03-visualizing-data.html#boxplot---step-2",
    "title": "Visualizing various types of data",
    "section": "Boxplot - Step 2",
    "text": "Boxplot - Step 2\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  )"
  },
  {
    "objectID": "slides/03-visualizing-data.html#boxplot---step-3",
    "href": "slides/03-visualizing-data.html#boxplot---step-3",
    "title": "Visualizing various types of data",
    "section": "Boxplot - Step 3",
    "text": "Boxplot - Step 3\n\n\n\nggplot(\n  penguins,\n  aes(y = body_mass_g)\n  ) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#boxplot---step-4",
    "href": "slides/03-visualizing-data.html#boxplot---step-4",
    "title": "Visualizing various types of data",
    "section": "Boxplot - Step 4",
    "text": "Boxplot - Step 4\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  ) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#boxplot---step-5",
    "href": "slides/03-visualizing-data.html#boxplot---step-5",
    "title": "Visualizing various types of data",
    "section": "Boxplot - Step 5",
    "text": "Boxplot - Step 5\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  ) +\n  geom_boxplot() +\n  labs(\n    x = \"Weight (grams)\",\n    y = NULL\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#density-plot---step-1",
    "href": "slides/03-visualizing-data.html#density-plot---step-1",
    "title": "Visualizing various types of data",
    "section": "Density plot - Step 1",
    "text": "Density plot - Step 1\n\n\n\nggplot(\n  penguins\n  )"
  },
  {
    "objectID": "slides/03-visualizing-data.html#density-plot---step-2",
    "href": "slides/03-visualizing-data.html#density-plot---step-2",
    "title": "Visualizing various types of data",
    "section": "Density plot - Step 2",
    "text": "Density plot - Step 2\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  )"
  },
  {
    "objectID": "slides/03-visualizing-data.html#density-plot---step-3",
    "href": "slides/03-visualizing-data.html#density-plot---step-3",
    "title": "Visualizing various types of data",
    "section": "Density plot - Step 3",
    "text": "Density plot - Step 3\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  ) +\n  geom_density()\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#density-plot---step-4",
    "href": "slides/03-visualizing-data.html#density-plot---step-4",
    "title": "Visualizing various types of data",
    "section": "Density plot - Step 4",
    "text": "Density plot - Step 4\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  ) +\n  geom_density(\n    fill = \"darkslategray1\"\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#density-plot---step-5",
    "href": "slides/03-visualizing-data.html#density-plot---step-5",
    "title": "Visualizing various types of data",
    "section": "Density plot - Step 5",
    "text": "Density plot - Step 5\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  ) +\n  geom_density(\n    fill = \"darkslategray1\",\n    linewidth = 2\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#density-plot---step-6",
    "href": "slides/03-visualizing-data.html#density-plot---step-6",
    "title": "Visualizing various types of data",
    "section": "Density plot - Step 6",
    "text": "Density plot - Step 6\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  ) +\n  geom_density(\n    fill = \"darkslategray1\",\n    linewidth = 2,\n    color = \"darkorchid3\"\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#density-plot---step-7",
    "href": "slides/03-visualizing-data.html#density-plot---step-7",
    "title": "Visualizing various types of data",
    "section": "Density plot - Step 7",
    "text": "Density plot - Step 7\n\n\n\nggplot(\n  penguins,\n  aes(x = body_mass_g)\n  ) +\n  geom_density(\n    fill = \"darkslategray1\",\n    linewidth = 2,\n    color = \"darkorchid3\",\n    alpha = 0.5\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#weights-of-penguins",
    "href": "slides/03-visualizing-data.html#weights-of-penguins",
    "title": "Visualizing various types of data",
    "section": "Weights of penguins",
    "text": "Weights of penguins\n\nQuestionVote\n\n\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\n\n\n\n\n\nTRUE / FALSE\n\nThe distribution of penguin weights in this sample is left skewed.\nThe distribution of penguin weights in this sample is unimodal."
  },
  {
    "objectID": "slides/03-visualizing-data.html#bivariate-analysis-1",
    "href": "slides/03-visualizing-data.html#bivariate-analysis-1",
    "title": "Visualizing various types of data",
    "section": "Bivariate analysis",
    "text": "Bivariate analysis\nAnalyzing the relationship between two variables:\n\nNumerical + numerical: scatterplot\nNumerical + categorical: side-by-side box plots, violin plots, etc.\nCategorical + categorical: stacked bar plots\nUsing an aesthetic (e.g., fill, color, shape, etc.) or facets to represent the second variable in any plot"
  },
  {
    "objectID": "slides/03-visualizing-data.html#side-by-side-box-plots",
    "href": "slides/03-visualizing-data.html#side-by-side-box-plots",
    "title": "Visualizing various types of data",
    "section": "Side-by-side box plots",
    "text": "Side-by-side box plots\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = body_mass_g,\n    y = species\n    )\n  ) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#density-plots",
    "href": "slides/03-visualizing-data.html#density-plots",
    "title": "Visualizing various types of data",
    "section": "Density plots",
    "text": "Density plots\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = body_mass_g,\n    color = species\n    )\n  ) +\n  geom_density()\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#density-plots-1",
    "href": "slides/03-visualizing-data.html#density-plots-1",
    "title": "Visualizing various types of data",
    "section": "Density plots",
    "text": "Density plots\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = body_mass_g,\n    color = species,\n    fill = species\n    )\n  ) +\n  geom_density()\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#density-plots-2",
    "href": "slides/03-visualizing-data.html#density-plots-2",
    "title": "Visualizing various types of data",
    "section": "Density plots",
    "text": "Density plots\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = body_mass_g,\n    color = species,\n    fill = species\n    )\n  ) +\n  geom_density(\n    alpha = 0.5\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`)."
  },
  {
    "objectID": "slides/03-visualizing-data.html#density-plots-3",
    "href": "slides/03-visualizing-data.html#density-plots-3",
    "title": "Visualizing various types of data",
    "section": "Density plots",
    "text": "Density plots\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = body_mass_g,\n    color = species,\n    fill = species\n    )\n  ) +\n  geom_density(\n    alpha = 0.5\n  ) +\n  theme(\n    legend.position = \"bottom\"\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüîó sta199-s24.github.io"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#while-you-wait",
    "href": "slides/02-grammar-of-graphics.html#while-you-wait",
    "title": "Grammar of graphics",
    "section": "While you wait‚Ä¶",
    "text": "While you wait‚Ä¶\nQuestions from the prepare materials?"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#announcements",
    "href": "slides/02-grammar-of-graphics.html#announcements",
    "title": "Grammar of graphics",
    "section": "Announcements",
    "text": "Announcements\n\nLab 1 on Monday ‚Äì go to your assigned lab\nCatch up with the prepare materials"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#from-the-survey",
    "href": "slides/02-grammar-of-graphics.html#from-the-survey",
    "title": "Grammar of graphics",
    "section": "From the survey",
    "text": "From the survey\n\nAlmost half of the class mentioned being nervous about coding ‚Äì you‚Äôre not alone! üíô\nA good number of students mentioned being nervous about being new to stats + data science ‚Äì you‚Äôre also not alone! üíú\nVisibility of text on slides: Cranked up font size! üíõ\nAbout exams: No coding on the in class (time-limited) exam + there will be practice exams\nAbout teams: Peer evaluations + milestones throughout semester\nGrading criteria: Scale of 0-4 for each exercise on lab + more details in lab instructions\nHardware: Code running on university containers"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#git-and-github",
    "href": "slides/02-grammar-of-graphics.html#git-and-github",
    "title": "Grammar of graphics",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\n\n\n\n\n\n\n\nGit is a version control system ‚Äì like ‚ÄúTrack Changes‚Äù features from Microsoft Word, on steroids\nIt‚Äôs not the only version control system, but it‚Äôs a very popular one\n\n\n\n\n\n\n\n\nGitHub is the home for your Git-based projects on the internet ‚Äì like DropBox but much, much better\nWe will use GitHub as a platform for web hosting and collaboration (and as our course management system!)"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#versioning---done-badly",
    "href": "slides/02-grammar-of-graphics.html#versioning---done-badly",
    "title": "Grammar of graphics",
    "section": "Versioning - done badly",
    "text": "Versioning - done badly"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#versioning---done-better",
    "href": "slides/02-grammar-of-graphics.html#versioning---done-better",
    "title": "Grammar of graphics",
    "section": "Versioning - done better",
    "text": "Versioning - done better"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#versioning---done-even-better",
    "href": "slides/02-grammar-of-graphics.html#versioning---done-even-better",
    "title": "Grammar of graphics",
    "section": "Versioning - done even better",
    "text": "Versioning - done even better\nwith human readable messages"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#how-will-we-use-git-and-github",
    "href": "slides/02-grammar-of-graphics.html#how-will-we-use-git-and-github",
    "title": "Grammar of graphics",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#how-will-we-use-git-and-github-1",
    "href": "slides/02-grammar-of-graphics.html#how-will-we-use-git-and-github-1",
    "title": "Grammar of graphics",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#how-will-we-use-git-and-github-2",
    "href": "slides/02-grammar-of-graphics.html#how-will-we-use-git-and-github-2",
    "title": "Grammar of graphics",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#how-will-we-use-git-and-github-3",
    "href": "slides/02-grammar-of-graphics.html#how-will-we-use-git-and-github-3",
    "title": "Grammar of graphics",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#git-and-github-tips",
    "href": "slides/02-grammar-of-graphics.html#git-and-github-tips",
    "title": "Grammar of graphics",
    "section": "Git and GitHub tips",
    "text": "Git and GitHub tips\n\n\nThere are millions of git commands ‚Äì ok, that‚Äôs an exaggeration, but there are a lot of them ‚Äì and very few people know them all. 99% of the time you will use git to add, commit, push, and pull.\nWe will be doing Git things and interfacing with GitHub through RStudio, but if you google for help you might come across methods for doing these things in the command line ‚Äì skip that and move on to the next resource unless you feel comfortable trying it out.\nThere is a great resource for working with git and R: happygitwithr.com. Some of the content in there is beyond the scope of this course, but it‚Äôs a good place to look for help."
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#tour-git-github",
    "href": "slides/02-grammar-of-graphics.html#tour-git-github",
    "title": "Grammar of graphics",
    "section": "Tour: Git + GitHub",
    "text": "Tour: Git + GitHub\n\nJust one option for now:\nSit back and enjoy the show!"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#examining-data-visualization",
    "href": "slides/02-grammar-of-graphics.html#examining-data-visualization",
    "title": "Grammar of graphics",
    "section": "Examining data visualization",
    "text": "Examining data visualization\n\n\nDiscuss the following for the visualization.\n\n\n\n\n‚àí+\n04:00\n\n\n\n\n\n\n\nSource: Twitter"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#ae-02-bechdel-dataviz",
    "href": "slides/02-grammar-of-graphics.html#ae-02-bechdel-dataviz",
    "title": "Grammar of graphics",
    "section": "ae-02-bechdel-dataviz",
    "text": "ae-02-bechdel-dataviz\n\n\nGo to the course GitHub org and find your ae repo (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline (end of this week)"
  },
  {
    "objectID": "slides/02-grammar-of-graphics.html#recap-of-ae",
    "href": "slides/02-grammar-of-graphics.html#recap-of-ae",
    "title": "Grammar of graphics",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nConstruct plots with ggplot().\nLayers of ggplots are separated by +s.\nThe formula is (almost) always as follows:\n\n\nggplot(DATA, aes(x = X-VAR, y = Y-VAR, ...)) +\n  geom_XXX()\n\n\nAesthetic attributes of a geometries (color, size, transparency, etc.) can be mapped to variables in the data or set by the user, e.g.¬†color = binary vs.¬†color = \"pink\".\nUse facet_wrap() when faceting (creating small multiples) by one variable and facet_grid() when faceting by two variables.\n\n\n\n\n\nüîó sta199-s24.github.io"
  },
  {
    "objectID": "slides/10-importing-recoding-data.html#while-you-wait-for-class-to-begin",
    "href": "slides/10-importing-recoding-data.html#while-you-wait-for-class-to-begin",
    "title": "Importing and recoding data",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\nQuestions from prepare materials?"
  },
  {
    "objectID": "slides/10-importing-recoding-data.html#announcements",
    "href": "slides/10-importing-recoding-data.html#announcements",
    "title": "Importing and recoding data",
    "section": "Announcements",
    "text": "Announcements\n\nIf you missed lab yesterday, get in touch with your team ASAP! Read over the team contract they developed and sign it.\nStart thinking about the datasets you‚Äôll include in your proposal."
  },
  {
    "objectID": "slides/10-importing-recoding-data.html#project-workflow-preview",
    "href": "slides/10-importing-recoding-data.html#project-workflow-preview",
    "title": "Importing and recoding data",
    "section": "Project workflow preview",
    "text": "Project workflow preview\n\n\n\n\n\n\n\nand a brief demo!"
  },
  {
    "objectID": "slides/10-importing-recoding-data.html#project-grading",
    "href": "slides/10-importing-recoding-data.html#project-grading",
    "title": "Importing and recoding data",
    "section": "Project grading",
    "text": "Project grading\n\nOutlined at https://sta199-s24.github.io/project/description.html#grading.\nEach milestone has points associated with it.\nAdditionally there are points allocated to reproducibility and organization as well as teamwork (to be measured by within team peer evaluations three times throughout the semester).\nMost important thing you can do today for your project: Block off agreed times in your calendar!"
  },
  {
    "objectID": "slides/10-importing-recoding-data.html#reading-rectangular-data",
    "href": "slides/10-importing-recoding-data.html#reading-rectangular-data",
    "title": "Importing and recoding data",
    "section": "Reading rectangular data",
    "text": "Reading rectangular data\n\nUsing readr:\n\nMost commonly: read_csv()\nMaybe also: read_tsv(), read_delim(), etc.\n\nUsing readxl: read_excel()\nUsing googlesheets4: read_sheet() ‚Äì We haven‚Äôt covered this in the videos, but might be useful for your projects"
  },
  {
    "objectID": "slides/10-importing-recoding-data.html#age-gap-in-hollywood-relationships",
    "href": "slides/10-importing-recoding-data.html#age-gap-in-hollywood-relationships",
    "title": "Importing and recoding data",
    "section": "Age gap in Hollywood relationships",
    "text": "Age gap in Hollywood relationships\n\n\n\nWhat is the story in this visualization?"
  },
  {
    "objectID": "slides/10-importing-recoding-data.html#application-exercise-ae-08-data-import",
    "href": "slides/10-importing-recoding-data.html#application-exercise-ae-08-data-import",
    "title": "Importing and recoding data",
    "section": "Application exercise: ae-08-data-import",
    "text": "Application exercise: ae-08-data-import\n\n\nGo to the project navigator in RStudio (top right corner of your RStudio window) and open the project called ae.\nIf there are any uncommitted files, commit them, and then click Pull.\nOpen the file called ae-08-data-import.qmd and render it.\nWork on Part 1."
  },
  {
    "objectID": "slides/10-importing-recoding-data.html#sales-data",
    "href": "slides/10-importing-recoding-data.html#sales-data",
    "title": "Importing and recoding data",
    "section": "Sales data",
    "text": "Sales data\n\n\n\nAre these data tidy? Why or why not?"
  },
  {
    "objectID": "slides/10-importing-recoding-data.html#sales-data-1",
    "href": "slides/10-importing-recoding-data.html#sales-data-1",
    "title": "Importing and recoding data",
    "section": "Sales data",
    "text": "Sales data\n\nWhat ‚Äúdata moves‚Äù do we need to go from the original, non-tidy data to this, tidy one?"
  },
  {
    "objectID": "slides/10-importing-recoding-data.html#application-exercise-ae-08-data-import-1",
    "href": "slides/10-importing-recoding-data.html#application-exercise-ae-08-data-import-1",
    "title": "Importing and recoding data",
    "section": "Application exercise: ae-08-data-import",
    "text": "Application exercise: ae-08-data-import\n\n\nGo back to your project called ae.\nIf there are any uncommitted files, commit them, and push.\nWork on Part 2 in ae-08-data-import.qmd."
  },
  {
    "objectID": "slides/10-importing-recoding-data.html#exams",
    "href": "slides/10-importing-recoding-data.html#exams",
    "title": "Importing and recoding data",
    "section": "Exams",
    "text": "Exams\n\n\n\n\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/14-language-of-models.html#while-you-wait-for-class-to-begin",
    "href": "slides/14-language-of-models.html#while-you-wait-for-class-to-begin",
    "title": "The language of models",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\n\nAny questions from prepare materials?"
  },
  {
    "objectID": "slides/14-language-of-models.html#announcements",
    "href": "slides/14-language-of-models.html#announcements",
    "title": "The language of models",
    "section": "Announcements",
    "text": "Announcements\n\nTEAMMATES survey to provide feedback to your teammates deadline extended to tonight (Tuesday, 3/5) till midnight\nLab 5 due upon return from Spring Break, 8 am on Monday as usual ‚Äì help will be available on Ed over the break (though a bit more sporadically)\nMonday after Spring Break: All team members must be in lab to work on project proposal"
  },
  {
    "objectID": "slides/14-language-of-models.html#questions-from-last-time",
    "href": "slides/14-language-of-models.html#questions-from-last-time",
    "title": "The language of models",
    "section": "Questions from last time",
    "text": "Questions from last time\n\nAre there universal standards for ethical data scraping?\n\n\n\nHow will we be tested on data science ethics?"
  },
  {
    "objectID": "slides/14-language-of-models.html#goals",
    "href": "slides/14-language-of-models.html#goals",
    "title": "The language of models",
    "section": "Goals",
    "text": "Goals\n\nWhat is a model?\nWhy do we model?\nWhat is correlation?"
  },
  {
    "objectID": "slides/14-language-of-models.html#setup",
    "href": "slides/14-language-of-models.html#setup",
    "title": "The language of models",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(gt)"
  },
  {
    "objectID": "slides/14-language-of-models.html#lets-drive-a-tesla",
    "href": "slides/14-language-of-models.html#lets-drive-a-tesla",
    "title": "The language of models",
    "section": "Let‚Äôs drive a Tesla!",
    "text": "Let‚Äôs drive a Tesla!"
  },
  {
    "objectID": "slides/14-language-of-models.html#semi-or-garage",
    "href": "slides/14-language-of-models.html#semi-or-garage",
    "title": "The language of models",
    "section": "Semi or garage?",
    "text": "Semi or garage?\n\ni love how Tesla thinks the wall in my garage is a semi. üòÖ\n\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/14-language-of-models.html#semi-or-garage-1",
    "href": "slides/14-language-of-models.html#semi-or-garage-1",
    "title": "The language of models",
    "section": "Semi or garage?",
    "text": "Semi or garage?\n\nNew owner here. Just parked in my garage. Tesla thinks I crashed onto a semi.\n\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/14-language-of-models.html#car-or-trash",
    "href": "slides/14-language-of-models.html#car-or-trash",
    "title": "The language of models",
    "section": "Car or trash?",
    "text": "Car or trash?\n\nTesla calls Mercedes trash\n\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/14-language-of-models.html#leisure-commute-physical-activity-and-bp",
    "href": "slides/14-language-of-models.html#leisure-commute-physical-activity-and-bp",
    "title": "The language of models",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\n\nRelation Between Leisure Time, Commuting, and Occupational Physical Activity With Blood Pressure in 125,402 Adults: The Lifelines Cohort\nByambasukh, Oyuntugs, Harold Snieder, and Eva Corpeleijn. ‚ÄúRelation between leisure time, commuting, and occupational physical activity with blood pressure in 125 402 adults: the lifelines cohort.‚Äù Journal of the American Heart Association 9.4 (2020): e014313."
  },
  {
    "objectID": "slides/14-language-of-models.html#leisure-commute-physical-activity-and-bp-1",
    "href": "slides/14-language-of-models.html#leisure-commute-physical-activity-and-bp-1",
    "title": "The language of models",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\nBackground: Whether all domains of daily‚Äêlife moderate‚Äêto‚Äêvigorous physical activity (MVPA) are associated with lower blood pressure (BP) and how this association depends on age and body mass index remains unclear.\nMethods and Results: In the population‚Äêbased Lifelines cohort (N=125,402), MVPA was assessed by the Short Questionnaire to Assess Health‚ÄêEnhancing Physical Activity, a validated questionnaire in different domains such as commuting, leisure‚Äêtime, and occupational PA. BP was assessed using the last 3 of 10 measurements after 10¬†minutes‚Äô rest in the supine position. Hypertension was defined as systolic BP ‚â•140¬†mm¬†Hg and/or diastolic BP ‚â•90¬†mm¬†Hg and/or use of antihypertensives. In regression analysis, higher commuting and leisure‚Äêtime but not occupational MVPA related to lower BP and lower hypertension risk. Commuting‚Äêand‚Äêleisure‚Äêtime MVPA was associated with BP in a dose‚Äêdependent manner. Œ≤ Coefficients (95% CI) from linear regression analyses were ‚àí1.64 (‚àí2.03 to ‚àí1.24), ‚àí2.29 (‚àí2.68 to ‚àí1.90), and finally ‚àí2.90 (‚àí3.29 to ‚àí2.50) mm¬†Hg systolic BP for the low, middle, and highest tertile of MVPA compared with ‚ÄúNo MVPA‚Äù as the reference group after adjusting for age, sex, education, smoking and alcohol use. Further adjustment for body mass index attenuated the associations by 30% to 50%, but more MVPA remained significantly associated with lower BP and lower risk of hypertension. This association was age dependent. Œ≤ Coefficients (95% CI) for the highest tertiles of commuting‚Äêand‚Äêleisure‚Äêtime MVPA were ‚àí1.67 (‚àí2.20 to ‚àí1.15), ‚àí3.39 (‚àí3.94 to ‚àí2.82) and ‚àí4.64 (‚àí6.15 to ‚àí3.14) mm¬†Hg systolic BP in adults &lt;40, 40 to 60, and &gt;60¬†years, respectively.\nConclusions: Higher commuting and leisure‚Äêtime but not occupational MVPA were significantly associated with lower BP and lower hypertension risk at all ages, but these associations were stronger in older adults."
  },
  {
    "objectID": "slides/14-language-of-models.html#modeling-cars",
    "href": "slides/14-language-of-models.html#modeling-cars",
    "title": "The language of models",
    "section": "Modeling cars",
    "text": "Modeling cars\n\n\nWhat is the relationship between cars‚Äô weights and their mileage?\nWhat is your best guess for a car‚Äôs MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/14-language-of-models.html#modelling-cars",
    "href": "slides/14-language-of-models.html#modelling-cars",
    "title": "The language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nDescribe: What is the relationship between cars‚Äô weights and their mileage?"
  },
  {
    "objectID": "slides/14-language-of-models.html#modelling-cars-1",
    "href": "slides/14-language-of-models.html#modelling-cars-1",
    "title": "The language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nPredict: What is your best guess for a car‚Äôs MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/14-language-of-models.html#modelling",
    "href": "slides/14-language-of-models.html#modelling",
    "title": "The language of models",
    "section": "Modelling",
    "text": "Modelling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we will focus on linear models (but there are many many other types of models too!)"
  },
  {
    "objectID": "slides/14-language-of-models.html#modelling-vocabulary",
    "href": "slides/14-language-of-models.html#modelling-vocabulary",
    "title": "The language of models",
    "section": "Modelling vocabulary",
    "text": "Modelling vocabulary\n\nPredictor (explanatory variable)\nOutcome (response variable)\nRegression line\n\nSlope\nIntercept\n\nCorrelation"
  },
  {
    "objectID": "slides/14-language-of-models.html#predictor-explanatory-variable",
    "href": "slides/14-language-of-models.html#predictor-explanatory-variable",
    "title": "The language of models",
    "section": "Predictor (explanatory variable)",
    "text": "Predictor (explanatory variable)\n\n\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "slides/14-language-of-models.html#outcome-response-variable",
    "href": "slides/14-language-of-models.html#outcome-response-variable",
    "title": "The language of models",
    "section": "Outcome (response variable)",
    "text": "Outcome (response variable)\n\n\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "slides/14-language-of-models.html#regression-line",
    "href": "slides/14-language-of-models.html#regression-line",
    "title": "The language of models",
    "section": "Regression line",
    "text": "Regression line"
  },
  {
    "objectID": "slides/14-language-of-models.html#regression-line-slope",
    "href": "slides/14-language-of-models.html#regression-line-slope",
    "title": "The language of models",
    "section": "Regression line: slope",
    "text": "Regression line: slope"
  },
  {
    "objectID": "slides/14-language-of-models.html#regression-line-intercept",
    "href": "slides/14-language-of-models.html#regression-line-intercept",
    "title": "The language of models",
    "section": "Regression line: intercept",
    "text": "Regression line: intercept"
  },
  {
    "objectID": "slides/14-language-of-models.html#correlation",
    "href": "slides/14-language-of-models.html#correlation",
    "title": "The language of models",
    "section": "Correlation",
    "text": "Correlation"
  },
  {
    "objectID": "slides/14-language-of-models.html#correlation-1",
    "href": "slides/14-language-of-models.html#correlation-1",
    "title": "The language of models",
    "section": "Correlation",
    "text": "Correlation\n\nRanges between -1 and 1.\nSame sign as the slope."
  },
  {
    "objectID": "slides/14-language-of-models.html#visualizing-the-model",
    "href": "slides/14-language-of-models.html#visualizing-the-model",
    "title": "The language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "slides/14-language-of-models.html#application-exercise-ae-10-modeling-fish",
    "href": "slides/14-language-of-models.html#application-exercise-ae-10-modeling-fish",
    "title": "The language of models",
    "section": "Application exercise: ae-10-modeling-fish",
    "text": "Application exercise: ae-10-modeling-fish\n\n\nGo back to your project called ae.\nIf there are any uncommitted files, commit them, and push.\nWork on ae-10-modeling-fish.qmd.\n\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/08-data-types-classes.html#while-you-wait-for-class-to-begin",
    "href": "slides/08-data-types-classes.html#while-you-wait-for-class-to-begin",
    "title": "Data types and classes",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\n\nGo to your ae repo, click Pull to get today‚Äôs application exercise to get ready for later.\nQuestions from the prepare materials?"
  },
  {
    "objectID": "slides/08-data-types-classes.html#pivoting-data",
    "href": "slides/08-data-types-classes.html#pivoting-data",
    "title": "Data types and classes",
    "section": "Pivoting data",
    "text": "Pivoting data\nSuppose we have the following patient data:\n\npatients\n\n# A tibble: 3 √ó 4\n  patient_id pulse_1 pulse_2 pulse_3\n  &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 XYZ             70      85      73\n2 ABC             90      95     102\n3 DEF            100      80      70\n\n\nAnd we want to know:\n\nAverage pulse rate for each patient.\nTrends in pulse rates across measurements."
  },
  {
    "objectID": "slides/08-data-types-classes.html#pivoting-data-1",
    "href": "slides/08-data-types-classes.html#pivoting-data-1",
    "title": "Data types and classes",
    "section": "Pivoting data",
    "text": "Pivoting data\nSuppose we have the following patient data:\n\npatients\n\n# A tibble: 3 √ó 4\n  patient_id pulse_1 pulse_2 pulse_3\n  &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 XYZ             70      85      73\n2 ABC             90      95     102\n3 DEF            100      80      70\n\n\nAnd we want to know:\n\nAverage pulse rate for each patient.\nTrends in pulse rates across measurements.\n\nThese require a longer format of the data where all pulse rates are in a single column and another column identifies the measurement number."
  },
  {
    "objectID": "slides/08-data-types-classes.html#pivoting-data-2",
    "href": "slides/08-data-types-classes.html#pivoting-data-2",
    "title": "Data types and classes",
    "section": "Pivoting data",
    "text": "Pivoting data\n\npatients_longer &lt;- patients |&gt;\n  pivot_longer(\n    cols = !patient_id,\n    names_to = \"measurement\",\n    values_to = \"pulse_rate\"\n  )"
  },
  {
    "objectID": "slides/08-data-types-classes.html#summarizing-pivoted-data",
    "href": "slides/08-data-types-classes.html#summarizing-pivoted-data",
    "title": "Data types and classes",
    "section": "Summarizing pivoted data",
    "text": "Summarizing pivoted data\n\npatients_longer |&gt;\n  group_by(patient_id) |&gt;\n  summarize(mean_pulse = mean(pulse_rate))\n\n# A tibble: 3 √ó 2\n  patient_id mean_pulse\n  &lt;chr&gt;           &lt;dbl&gt;\n1 ABC              95.7\n2 DEF              83.3\n3 XYZ              76"
  },
  {
    "objectID": "slides/08-data-types-classes.html#visualizing-pivoted-data",
    "href": "slides/08-data-types-classes.html#visualizing-pivoted-data",
    "title": "Data types and classes",
    "section": "Visualizing pivoted data",
    "text": "Visualizing pivoted data\n\nggplot(\n  patients_longer, \n  aes(x = measurement, y = pulse_rate, group = patient_id, color = patient_id)\n  ) +\n  geom_line()"
  },
  {
    "objectID": "slides/08-data-types-classes.html#types-and-classes-1",
    "href": "slides/08-data-types-classes.html#types-and-classes-1",
    "title": "Data types and classes",
    "section": "Types and classes",
    "text": "Types and classes\n\nType is how an object is stored in memory, e.g.,\n\ndouble: a real number stored in double-precision floatint point format.\ninteger: an integer (positive or negative)\n\nClass is metadata about the object that can determine how common functions operate on that object, e.g.,\n\nfactor"
  },
  {
    "objectID": "slides/08-data-types-classes.html#types-of-vectors",
    "href": "slides/08-data-types-classes.html#types-of-vectors",
    "title": "Data types and classes",
    "section": "Types of vectors",
    "text": "Types of vectors\n\n\nYou‚Äôll commonly encounter:\n\nlogical\ninteger\ndouble\ncharacter\n\n\nYou‚Äôll less commonly encounter:\n\nlist\nNULL\ncomplex\nraw"
  },
  {
    "objectID": "slides/08-data-types-classes.html#types-of-functions",
    "href": "slides/08-data-types-classes.html#types-of-functions",
    "title": "Data types and classes",
    "section": "Types of functions",
    "text": "Types of functions\nYes, functions have types too, but you don‚Äôt need to worry about the differences in the context of doing data science.\n\ntypeof(mean) # regular function\n\n[1] \"closure\"\n\ntypeof(`$`) # internal function\n\n[1] \"special\"\n\ntypeof(sum) # primitive function\n\n[1] \"builtin\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#factors",
    "href": "slides/08-data-types-classes.html#factors",
    "title": "Data types and classes",
    "section": "Factors",
    "text": "Factors\nA factor is a vector that can contain only predefined values. It is used to store categorical data.\n\n\n\nx &lt;- factor(c(\"a\", \"b\", \"b\", \"a\"))\nx\n\n[1] a b b a\nLevels: a b\n\ntypeof(x)\n\n[1] \"integer\"\n\nattributes(x)\n\n$levels\n[1] \"a\" \"b\"\n\n$class\n[1] \"factor\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#other-classes",
    "href": "slides/08-data-types-classes.html#other-classes",
    "title": "Data types and classes",
    "section": "Other classes",
    "text": "Other classes\nJust a couple of examples‚Ä¶\n\n\nDate:\n\ntoday &lt;- Sys.Date()\ntoday\n\n[1] \"2024-02-29\"\n\ntypeof(today)\n\n[1] \"double\"\n\nattributes(today)\n\n$class\n[1] \"Date\"\n\n\n\nDate-time:\n\nnow &lt;- as.POSIXct(\"2024-02-08 11:45\", tz = \"EST\")\nnow\n\n[1] \"2024-02-08 11:45:00 EST\"\n\ntypeof(now)\n\n[1] \"double\"\n\nattributes(now)\n\n$class\n[1] \"POSIXct\" \"POSIXt\" \n\n$tzone\n[1] \"EST\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#ae-07-population-types",
    "href": "slides/08-data-types-classes.html#ae-07-population-types",
    "title": "Data types and classes",
    "section": "ae-07-population-types",
    "text": "ae-07-population-types\n\n\nGo to the project navigator in RStudio (top right corner of your RStudio window) and open the project called ae.\nIf there are any uncommitted files, commit them, and then click Pull.\nOpen the file called ae-07-population-types.qmd and render it.\n\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#announcements",
    "href": "slides/16-linear-model-multiple-predictors-I.html#announcements",
    "title": "Linear regression with a multiple predictors I",
    "section": "Announcements",
    "text": "Announcements\n\nProject milestone 2 - proposals due Mon, Mar 25\nExam 2:\n\nIn class: April 11\nTake home: April 11-15"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#pace---course",
    "href": "slides/16-linear-model-multiple-predictors-I.html#pace---course",
    "title": "Linear regression with a multiple predictors I",
    "section": "Pace - course",
    "text": "Pace - course"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#pace---lecture",
    "href": "slides/16-linear-model-multiple-predictors-I.html#pace---lecture",
    "title": "Linear regression with a multiple predictors I",
    "section": "Pace - lecture",
    "text": "Pace - lecture"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#engagement",
    "href": "slides/16-linear-model-multiple-predictors-I.html#engagement",
    "title": "Linear regression with a multiple predictors I",
    "section": "Engagement",
    "text": "Engagement"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#resources",
    "href": "slides/16-linear-model-multiple-predictors-I.html#resources",
    "title": "Linear regression with a multiple predictors I",
    "section": "Resources",
    "text": "Resources"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#learning",
    "href": "slides/16-linear-model-multiple-predictors-I.html#learning",
    "title": "Linear regression with a multiple predictors I",
    "section": "Learning",
    "text": "Learning"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#class-time",
    "href": "slides/16-linear-model-multiple-predictors-I.html#class-time",
    "title": "Linear regression with a multiple predictors I",
    "section": "Class time",
    "text": "Class time"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#difficulty",
    "href": "slides/16-linear-model-multiple-predictors-I.html#difficulty",
    "title": "Linear regression with a multiple predictors I",
    "section": "Difficulty",
    "text": "Difficulty"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#feedback",
    "href": "slides/16-linear-model-multiple-predictors-I.html#feedback",
    "title": "Linear regression with a multiple predictors I",
    "section": "Feedback",
    "text": "Feedback\n\nGenerally very positive feedback about TAs!\nEnjoy interactive lectures, want more time on AEs / live coding\nRubric for assessments / grading\nChallenging topic list"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#goals",
    "href": "slides/16-linear-model-multiple-predictors-I.html#goals",
    "title": "Linear regression with a multiple predictors I",
    "section": "Goals",
    "text": "Goals\n\nRecap modeling with a single predictor\nFit and interpret models with multiple predictors\nDistinguish between additive and interaction models"
  },
  {
    "objectID": "slides/16-linear-model-multiple-predictors-I.html#application-exercise-ae-12-modeling-penguins-multi",
    "href": "slides/16-linear-model-multiple-predictors-I.html#application-exercise-ae-12-modeling-penguins-multi",
    "title": "Linear regression with a multiple predictors I",
    "section": "Application exercise: ae-12-modeling-penguins-multi",
    "text": "Application exercise: ae-12-modeling-penguins-multi\n\n\nGo back to your project called ae.\nIf there are any uncommitted files, commit them, and push.\nWork on ae-12-modeling-penguins-multi.qmd.\n\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/13-ethics.html#while-you-wait-for-class-to-begin",
    "href": "slides/13-ethics.html#while-you-wait-for-class-to-begin",
    "title": "Data science ethics",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\n\nAny questions from prepare materials?"
  },
  {
    "objectID": "slides/13-ethics.html#announcements",
    "href": "slides/13-ethics.html#announcements",
    "title": "Data science ethics",
    "section": "Announcements",
    "text": "Announcements\n\nFill out TEAMMATES survey to provide feedback to your teammates bu Sunday night (and to let us know how things are going)\nSubmit AE 09 (the R script and the Quarto document) by Sunday night\nSubmit Lab 4 by Monday morning"
  },
  {
    "objectID": "slides/13-ethics.html#questions-from-last-time",
    "href": "slides/13-ethics.html#questions-from-last-time",
    "title": "Data science ethics",
    "section": "Questions from last time",
    "text": "Questions from last time\n\nHow do you do that keyboard shortcut where you like drag down text selecting?\n\n\n\nHow do you know when to clean extra space after text if you cannot specifically see the spaces?\n\n\n\n\nWill there be a curve for the test?"
  },
  {
    "objectID": "slides/13-ethics.html#guidelines-and-best-practices-for-using-chat-gpt",
    "href": "slides/13-ethics.html#guidelines-and-best-practices-for-using-chat-gpt",
    "title": "Data science ethics",
    "section": "Guidelines and best practices for using Chat GPT",
    "text": "Guidelines and best practices for using Chat GPT\n\nDo not just copy-paste the prompt ‚Äì for appropriate academic conduct, for your own learning, and for getting to better results faster\nEngineer the prompt until the response starts to look like code you‚Äôre learning in the course\nIf the response is not correct, ask for a correction\nIf the response doesn‚Äôt follow the guidelines, ask for a correction\nDo not just copy-paste code from Chat GPT responses, run it line-by-line and edit as needed\nWatch out for clear mistakes in the response: do not keep loading packages that are already loaded, use the base pipe |&gt;, use tidyverse-based code, etc."
  },
  {
    "objectID": "slides/13-ethics.html#today",
    "href": "slides/13-ethics.html#today",
    "title": "Data science ethics",
    "section": "Today",
    "text": "Today\nData science ethics:\n\nMisrepresentation\nData privacy\nAlgorithmic bias"
  },
  {
    "objectID": "slides/13-ethics.html#stand-your-ground",
    "href": "slides/13-ethics.html#stand-your-ground",
    "title": "Data science ethics",
    "section": "Stand your ground",
    "text": "Stand your ground\n\nIn 2005, the Florida legislature passed the controversial ‚ÄúStand Your Ground‚Äù law that broadened the situations in which citizens can use lethal force to protect themselves against perceived threats. Advocates believed that the new law would ultimately reduce crime; opponents feared an increase in the use of lethal force."
  },
  {
    "objectID": "slides/13-ethics.html#stand-your-ground-1",
    "href": "slides/13-ethics.html#stand-your-ground-1",
    "title": "Data science ethics",
    "section": "Stand your ground",
    "text": "Stand your ground\n\nQuestionSubmit\n\n\n\nWhat does the visualization, published by Reuters on February 16, 2014, say about the number of firearm murders in Florida over the years?\n\n\n\n\n\n\n\n\n\n‚àí+\n03:00"
  },
  {
    "objectID": "slides/13-ethics.html#your-data",
    "href": "slides/13-ethics.html#your-data",
    "title": "Data science ethics",
    "section": "‚ÄúYour‚Äù data",
    "text": "‚ÄúYour‚Äù data\n\nEvery time we use apps, websites, and devices, our data is being collected and used or sold to others.\nMore importantly, decisions are made by law enforcement, financial institutions, and governments based on data that directly affect the lives of people."
  },
  {
    "objectID": "slides/13-ethics.html#privacy-of-your-data",
    "href": "slides/13-ethics.html#privacy-of-your-data",
    "title": "Data science ethics",
    "section": "Privacy of your data",
    "text": "Privacy of your data\n\nWhat pieces of data have you left on the internet today? Think through everything you‚Äôve logged into, clicked on, checked in, either actively or automatically, that might be tracking you. Do you know where that data is stored? Who it can be accessed by? Whether it‚Äôs shared with others?"
  },
  {
    "objectID": "slides/13-ethics.html#sharing-your-data",
    "href": "slides/13-ethics.html#sharing-your-data",
    "title": "Data science ethics",
    "section": "Sharing your data",
    "text": "Sharing your data\n\nWhat are you OK with sharing?\n\n\n\n\n\nName\nAge\nEmail\nPhone Number\nList of every video you watch\nList of every video you comment on\n\n\n\n\n\nHow you type: speed, accuracy\nHow long you spend on different content\nList of all your private messages (date, time, person sent to)\nInfo about your photos (how it was taken, where it was taken (GPS), when it was taken)"
  },
  {
    "objectID": "slides/13-ethics.html#what-does-google-thinkknow-about-you",
    "href": "slides/13-ethics.html#what-does-google-thinkknow-about-you",
    "title": "Data science ethics",
    "section": "What does Google think/know about you?",
    "text": "What does Google think/know about you?\n\nHave you ever thought about why you‚Äôre seeing an ad on Google? Google it! Try to figure out if you have ad personalization on and how your ads are personalized.\n\n\n\n\n‚àí+\n03:00"
  },
  {
    "objectID": "slides/13-ethics.html#your-browing-history",
    "href": "slides/13-ethics.html#your-browing-history",
    "title": "Data science ethics",
    "section": "Your browing history",
    "text": "Your browing history\n\nWhich of the following are you OK with your browsing history to be used towards?\n\n\n\nFor serving you targeted ads\nTo score you as a candidate for a job\nTo predict your race/ethnicity for voting purposes"
  },
  {
    "objectID": "slides/13-ethics.html#who-else-gets-to-use-your-data",
    "href": "slides/13-ethics.html#who-else-gets-to-use-your-data",
    "title": "Data science ethics",
    "section": "Who else gets to use your data?",
    "text": "Who else gets to use your data?\n\nSuppose you create a profile on a social media site and share your personal information on your profile. Who else gets to use that data?\n\n\n\nCompanies the social media company has a connection to?\nCompanies the social media company sells your data to?\nResearchers?"
  },
  {
    "objectID": "slides/13-ethics.html#ok-cupid-data-breach",
    "href": "slides/13-ethics.html#ok-cupid-data-breach",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n\nIn 2016, researchers published data of 70,000 OkCupid users‚Äîincluding usernames, political leanings, drug usage, and intimate sexual details\nResearchers didn‚Äôt release the real names and pictures of OKCupid users, but their identities could easily be uncovered from the details provided, e.g.¬†usernames\n\n\n\n\n\nSome may object to the ethics of gathering and releasing this data. However, all the data found in the dataset are or were already publicly available, so releasing this dataset merely presents it in a more useful form.\nResearchers Emil Kirkegaard and Julius Daugbjerg Bjerrek√¶r"
  },
  {
    "objectID": "slides/13-ethics.html#gettysburg-address",
    "href": "slides/13-ethics.html#gettysburg-address",
    "title": "Data science ethics",
    "section": "Gettysburg address",
    "text": "Gettysburg address\n\n\n\nRandomly select 10 words from the Gettysburg Address and calculate the mean number of letters in these 10 words. Submit your answer at bit.ly/bit.ly/gburg-s24.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚àí+\n03:00"
  },
  {
    "objectID": "slides/13-ethics.html#your-responses",
    "href": "slides/13-ethics.html#your-responses",
    "title": "Data science ethics",
    "section": "Your responses",
    "text": "Your responses\n\n\n‚úî Reading from \"Gettysburg address - Spring 2024 (Responses)\".\n\n\n‚úî Range 'Form Responses 1'.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "slides/13-ethics.html#comparison-to-truth",
    "href": "slides/13-ethics.html#comparison-to-truth",
    "title": "Data science ethics",
    "section": "Comparison to ‚Äútruth‚Äù",
    "text": "Comparison to ‚Äútruth‚Äù\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "slides/13-ethics.html#garbage-in-garbage-out",
    "href": "slides/13-ethics.html#garbage-in-garbage-out",
    "title": "Data science ethics",
    "section": "Garbage in, garbage out",
    "text": "Garbage in, garbage out\n\nIn statistical modeling and inference we talk about ‚Äúgarbage in, garbage out‚Äù ‚Äì if you don‚Äôt have good (random, representative) data, results of your analysis will not be reliable or generalizable.\nCorollary: Bias in, bias out."
  },
  {
    "objectID": "slides/13-ethics.html#google-translate",
    "href": "slides/13-ethics.html#google-translate",
    "title": "Data science ethics",
    "section": "Google translate",
    "text": "Google translate\n\nWhat might be the reason for Google‚Äôs gendered translation? How do ethics play into this situation?\n\n\n\n\n\n\n\n\nSource: Engadget - Google is working to remove gender bias in its translations"
  },
  {
    "objectID": "slides/13-ethics.html#stochastic-parrots",
    "href": "slides/13-ethics.html#stochastic-parrots",
    "title": "Data science ethics",
    "section": "Stochastic parrots",
    "text": "Stochastic parrots\n\nExcerptQuestion\n\n\nOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ü¶ú (Bender et. al., 2021)\n\nThe past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.\n\n\n\n\n‚àí+\n05:00\n\n\n\n\n\n\nWhat is meant by ‚Äústochastic parrots‚Äù in the paper title?"
  },
  {
    "objectID": "slides/13-ethics.html#machine-bias",
    "href": "slides/13-ethics.html#machine-bias",
    "title": "Data science ethics",
    "section": "Machine Bias",
    "text": "Machine Bias\n2016 ProPublica article on algorithm used for rating a defendant‚Äôs risk of future crime:\n\n\n\nIn forecasting who would re-offend, the algorithm made mistakes with black and white defendants at roughly the same rate but in very different ways.\n\nThe formula was particularly likely to falsely flag black defendants as future criminals, wrongly labeling them this way at almost twice the rate as white defendants.\nWhite defendants were mislabeled as low risk more often than black defendants.\n\n\n\n\n\n\n\n\n\n\n\n\nSource: ProPublica"
  },
  {
    "objectID": "slides/13-ethics.html#risk-score-errors",
    "href": "slides/13-ethics.html#risk-score-errors",
    "title": "Data science ethics",
    "section": "Risk score errors",
    "text": "Risk score errors\n\n\n\nWhat is common among the defendants who were assigned a high/low risk score for reoffending?"
  },
  {
    "objectID": "slides/13-ethics.html#risk-scores",
    "href": "slides/13-ethics.html#risk-scores",
    "title": "Data science ethics",
    "section": "Risk scores",
    "text": "Risk scores\n\n\n\nHow can an algorithm that doesn‚Äôt use race as input data be racist?"
  },
  {
    "objectID": "slides/13-ethics.html#predicting-ethnicity",
    "href": "slides/13-ethics.html#predicting-ethnicity",
    "title": "Data science ethics",
    "section": "Predicting ethnicity",
    "text": "Predicting ethnicity\nImproving Ecological Inference by Predicting Individual Ethnicity from Voter Registration Record (Imran and Khan, 2016)\n\nIn both political behavior research and voting rights litigation, turnout and vote choice for different racial groups are often inferred using aggregate election results and racial composition. Over the past several decades, many statistical methods have been proposed to address this ecological inference problem. We propose an alternative method to reduce aggregation bias by predicting individual-level ethnicity from voter registration records. Building on the existing methodological literature, we use Bayes‚Äôs rule to combine the Census Bureau‚Äôs Surname List with various information from geocoded voter registration records. We evaluate the performance of the proposed methodology using approximately nine million voter registration records from Florida, where self-reported ethnicity is available. We find that it is possible to reduce the false positive rate among Black and Latino voters to 6% and 3%, respectively, while maintaining the true positive rate above 80%. Moreover, we use our predictions to estimate turnout by race and find that our estimates yields substantially less amounts of bias and root mean squared error than standard ecological inference estimates. We provide open-source software to implement the proposed methodology. The open-source software is available for implementing the proposed methodology."
  },
  {
    "objectID": "slides/13-ethics.html#wru-package",
    "href": "slides/13-ethics.html#wru-package",
    "title": "Data science ethics",
    "section": "wru package",
    "text": "wru package\nThe said ‚Äúsource software‚Äù is the wru package: https://github.com/kosukeimai/wru.\n\nDo you have any ethical concerns about installing this package?"
  },
  {
    "objectID": "slides/13-ethics.html#wru-package-1",
    "href": "slides/13-ethics.html#wru-package-1",
    "title": "Data science ethics",
    "section": "wru package",
    "text": "wru package\n\nWas the publication of this model ethical? Does the open-source nature of the code affect your answer? Is it ethical to use this software? Does your answer change depending on the intended use?\n\n\nlibrary(wru)\npredict_race(voter.file = voters, surname.only = TRUE) |&gt;\n  select(surname, contains(\"pred\"))\n\n      surname    pred.whi    pred.bla     pred.his    pred.asi    pred.oth\n1      Khanna 0.045110474 0.003067623 0.0068522723 0.860411906 0.084557725\n2        Imai 0.052645440 0.001334812 0.0558160072 0.719376581 0.170827160\n3      Rivera 0.043285692 0.008204605 0.9136195794 0.024316883 0.010573240\n4     Fifield 0.895405704 0.001911388 0.0337464844 0.011079323 0.057857101\n5        Zhou 0.006572555 0.001298962 0.0005388581 0.982365594 0.009224032\n6    Ratkovic 0.861236727 0.008212824 0.0095395642 0.011334635 0.109676251\n7     Johnson 0.543815322 0.344128607 0.0272403940 0.007405765 0.077409913\n8       Lopez 0.038939877 0.004920643 0.9318797791 0.012154125 0.012105576\n10 Wantchekon 0.330697188 0.194700665 0.4042849478 0.021379541 0.048937658\n9       Morse 0.866360147 0.044429853 0.0246568086 0.010219712 0.054333479"
  },
  {
    "objectID": "slides/13-ethics.html#wru-package-2",
    "href": "slides/13-ethics.html#wru-package-2",
    "title": "Data science ethics",
    "section": "wru package",
    "text": "wru package\n\nme &lt;- tibble(surname = \"Rundel\")\n\npredict_race(voter.file = me, surname.only = TRUE)\n\nPredicting race for 2020\n\n\nWarning: Unknown or uninitialised column: `state`.\n\n\nProceeding with last name predictions...\n\n\n‚Ñπ All local files already up-to-date!\n\n\n  surname  pred.whi pred.bla pred.his pred.asi   pred.oth\n1  Rundel 0.9177967        0        0        0 0.08220329\n\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#while-you-wait",
    "href": "slides/04-dataviz-overview.html#while-you-wait",
    "title": "Data visualization overview",
    "section": "While you wait‚Ä¶",
    "text": "While you wait‚Ä¶\nQuestions from the prepare materials?"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#announcements",
    "href": "slides/04-dataviz-overview.html#announcements",
    "title": "Data visualization overview",
    "section": "Announcements",
    "text": "Announcements\n\nLab 1 due Monday morning at 8 am.\n\nMy office hours today after class + 2-3 pm in Old Chem 213\nLots of TA office hours, including over the weekend\nSubmitting late and want to use your one-time waiver? Email our course coordinator Dr.¬†Mary Knox.\n\nAEs this week should be submitted by midnight on Sunday. To ‚Äúsubmit‚Äù, commit and push at least once to your ae repo for each application exercise this week.\nPilot: Ed Discussion threads for lecture, linked at the bottom of each slide."
  },
  {
    "objectID": "slides/04-dataviz-overview.html#questions-from-last-time",
    "href": "slides/04-dataviz-overview.html#questions-from-last-time",
    "title": "Data visualization overview",
    "section": "Questions from last time",
    "text": "Questions from last time\nMany of the questions in Lab 1 are subjective. How does that work?\n\nidentify at least one outlier"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#questions-from-last-time-1",
    "href": "slides/04-dataviz-overview.html#questions-from-last-time-1",
    "title": "Data visualization overview",
    "section": "Questions from last time",
    "text": "Questions from last time\nMany of the questions in Lab 1 are subjective. How does that work?\n\nidentify at least one outlier ‚úÖ"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#questions-from-last-time-2",
    "href": "slides/04-dataviz-overview.html#questions-from-last-time-2",
    "title": "Data visualization overview",
    "section": "Questions from last time",
    "text": "Questions from last time\nMany of the questions in Lab 1 are subjective. How does that work?\n\nidentify at least one outlier ‚ùå"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#questions-from-last-time-3",
    "href": "slides/04-dataviz-overview.html#questions-from-last-time-3",
    "title": "Data visualization overview",
    "section": "Questions from last time",
    "text": "Questions from last time\nWhat are some situations where waffle plots are better than pie charts?\nLet‚Äôs take a look at an example‚Ä¶"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#or",
    "href": "slides/04-dataviz-overview.html#or",
    "title": "Data visualization overview",
    "section": "ü•ß or üßá?",
    "text": "ü•ß or üßá?\n\nQuestionVote\n\n\nWhich of the following is a better representation for the number of counties in each midwestern state?"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#or-or",
    "href": "slides/04-dataviz-overview.html#or-or",
    "title": "Data visualization overview",
    "section": "ü•ß or üßá or ?",
    "text": "ü•ß or üßá or ?\n\nQuestionVote\n\n\nWhich of the following is a better representation for the number of counties in each midwestern state?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmidwest |&gt; \n  count(state, sort = TRUE)\n\n# A tibble: 5 √ó 2\n  state     n\n  &lt;chr&gt; &lt;int&gt;\n1 IL      102\n2 IN       92\n3 OH       88\n4 MI       83\n5 WI       72"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#packages",
    "href": "slides/04-dataviz-overview.html#packages",
    "title": "Data visualization overview",
    "section": "Packages",
    "text": "Packages\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#bivariate-analysis",
    "href": "slides/04-dataviz-overview.html#bivariate-analysis",
    "title": "Data visualization overview",
    "section": "Bivariate analysis",
    "text": "Bivariate analysis\n\nPlotCode\n\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Side-by-side box plots\nggplot(penguins, aes(x = body_mass_g, y = species, fill = species)) +\n  geom_boxplot(alpha = 0.5, show.legend = FALSE) +\n  scale_fill_colorblind() +\n  labs(\n    x = \"Body mass (grams)\", y = \"Species\",\n    title = \"Side-by-side box plots\"\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n# Density plots\nggplot(penguins, aes(x = body_mass_g, fill = species)) +\n  geom_density(alpha = 0.5) +\n  theme(legend.position = \"bottom\") +\n  scale_fill_colorblind() +\n  labs(\n    x = \"Body mass (grams)\", y = \"Density\",\n    fill = \"Species\", title = \"Density plots\"\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`)."
  },
  {
    "objectID": "slides/04-dataviz-overview.html#violin-plots",
    "href": "slides/04-dataviz-overview.html#violin-plots",
    "title": "Data visualization overview",
    "section": "Violin plots",
    "text": "Violin plots\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = species,\n    y = body_mass_g\n    )\n  ) +\n  geom_violin()\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`)."
  },
  {
    "objectID": "slides/04-dataviz-overview.html#multiple-geoms",
    "href": "slides/04-dataviz-overview.html#multiple-geoms",
    "title": "Data visualization overview",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = species,\n    y = body_mass_g\n    )\n  ) +\n  geom_violin() +\n  geom_point()\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "slides/04-dataviz-overview.html#multiple-geoms-1",
    "href": "slides/04-dataviz-overview.html#multiple-geoms-1",
    "title": "Data visualization overview",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = species,\n    y = body_mass_g\n    )\n  ) +\n  geom_violin() +\n  geom_jitter()\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "slides/04-dataviz-overview.html#multiple-geoms-aesthetics",
    "href": "slides/04-dataviz-overview.html#multiple-geoms-aesthetics",
    "title": "Data visualization overview",
    "section": "Multiple geoms + aesthetics",
    "text": "Multiple geoms + aesthetics\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = species,\n    y = body_mass_g,\n    color = species\n    )\n  ) +\n  geom_violin() +\n  geom_jitter()\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "slides/04-dataviz-overview.html#multiple-geoms-aesthetics-1",
    "href": "slides/04-dataviz-overview.html#multiple-geoms-aesthetics-1",
    "title": "Data visualization overview",
    "section": "Multiple geoms + aesthetics",
    "text": "Multiple geoms + aesthetics\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = species,\n    y = body_mass_g,\n    color = species\n    )\n  ) +\n  geom_violin() +\n  geom_jitter() +\n  theme(\n    legend.position = \"none\"\n  )\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "slides/04-dataviz-overview.html#multiple-geoms-aesthetics-2",
    "href": "slides/04-dataviz-overview.html#multiple-geoms-aesthetics-2",
    "title": "Data visualization overview",
    "section": "Multiple geoms + aesthetics",
    "text": "Multiple geoms + aesthetics\n\n\n\nggplot(\n  penguins,\n  aes(\n    x = species,\n    y = body_mass_g,\n    color = species\n    )\n  ) +\n  geom_violin() +\n  geom_jitter() +\n  theme(\n    legend.position = \"none\"\n  ) +\n  scale_color_colorblind()\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "slides/04-dataviz-overview.html#bechdel",
    "href": "slides/04-dataviz-overview.html#bechdel",
    "title": "Data visualization overview",
    "section": "Bechdel",
    "text": "Bechdel\nLoad the Bechdel test data with read_csv():\n\nbechdel &lt;- read_csv(\"https://sta199-s24.github.io/data/bechdel.csv\")\n\n\n\nView the column names() of the bechdel data:\n\nnames(bechdel)\n\n[1] \"title\"       \"year\"        \"gross_2013\"  \"budget_2013\" \"roi\"         \"binary\"     \n[7] \"clean_test\""
  },
  {
    "objectID": "slides/04-dataviz-overview.html#roi-by-test-result",
    "href": "slides/04-dataviz-overview.html#roi-by-test-result",
    "title": "Data visualization overview",
    "section": "ROI by test result",
    "text": "ROI by test result\n\nWhat about this plot makes it difficult to evaluate how ROI varies by Bechdel test result?\n\n\nggplot(bechdel, aes(x = roi, y = clean_test, color = binary)) +\n  geom_boxplot()\n\nWarning: Removed 15 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "slides/04-dataviz-overview.html#movies-with-high-roi",
    "href": "slides/04-dataviz-overview.html#movies-with-high-roi",
    "title": "Data visualization overview",
    "section": "Movies with high ROI",
    "text": "Movies with high ROI\n\nWhat are the movies with highest ROI?\n\n\nbechdel |&gt;\n  filter(roi &gt; 400) |&gt;\n  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n# A tibble: 3 √ó 6\n  title                     roi budget_2013 gross_2013  year clean_test\n  &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Paranormal Activity      671.      505595  339424558  2007 dubious   \n2 The Blair Witch Project  648.      839077  543776715  1999 ok        \n3 El Mariachi              583.       11622    6778946  1992 nowomen"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#roi-by-test-result-1",
    "href": "slides/04-dataviz-overview.html#roi-by-test-result-1",
    "title": "Data visualization overview",
    "section": "ROI by test result",
    "text": "ROI by test result\n\nZoom in: What about this plot makes it difficult to evaluate how ROI varies by Bechdel test result?\n\n\nggplot(bechdel, aes(x = roi, y = clean_test, color = binary)) +\n  geom_boxplot() +\n  coord_cartesian(xlim = c(0, 15))\n\nWarning: Removed 15 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "slides/04-dataviz-overview.html#sneak-preview",
    "href": "slides/04-dataviz-overview.html#sneak-preview",
    "title": "Data visualization overview",
    "section": "Sneak preview‚Ä¶",
    "text": "Sneak preview‚Ä¶\n \n\nto next week‚Äôs data wrangling pipelines‚Ä¶"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#median-roi",
    "href": "slides/04-dataviz-overview.html#median-roi",
    "title": "Data visualization overview",
    "section": "Median ROI",
    "text": "Median ROI\n\nbechdel |&gt;\n  summarize(median_roi = median(roi, na.rm = TRUE))\n\n# A tibble: 1 √ó 1\n  median_roi\n       &lt;dbl&gt;\n1       3.91"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#median-roi-by-test-result",
    "href": "slides/04-dataviz-overview.html#median-roi-by-test-result",
    "title": "Data visualization overview",
    "section": "Median ROI by test result",
    "text": "Median ROI by test result\n\nbechdel |&gt;\n  group_by(clean_test) |&gt;\n  summarize(median_roi = median(roi, na.rm = TRUE))\n\n# A tibble: 5 √ó 2\n  clean_test median_roi\n  &lt;chr&gt;           &lt;dbl&gt;\n1 dubious          3.80\n2 men              3.96\n3 notalk           3.69\n4 nowomen          3.27\n5 ok               4.21"
  },
  {
    "objectID": "slides/04-dataviz-overview.html#roi-by-test-result-zoom-in",
    "href": "slides/04-dataviz-overview.html#roi-by-test-result-zoom-in",
    "title": "Data visualization overview",
    "section": "ROI by test result ‚Äì zoom in",
    "text": "ROI by test result ‚Äì zoom in\n\nWhat does this plot say about return-on-investment on movies that pass the Bechdel test?\n\n\nggplot(bechdel, aes(x = roi, y = clean_test, color = binary)) +\n  geom_boxplot() +\n  coord_cartesian(xlim = c(0, 15)) +\n  geom_vline(xintercept = 4.21, linetype = \"dashed\")\n\nWarning: Removed 15 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "slides/04-dataviz-overview.html#ae-03-duke-forest",
    "href": "slides/04-dataviz-overview.html#ae-03-duke-forest",
    "title": "Data visualization overview",
    "section": "ae-03-duke-forest",
    "text": "ae-03-duke-forest\n\n\nIf you‚Äôve been here for a while:\nand following along with the application exercises‚Ä¶\nGo to the project navigator in RStudio (top right corner of your RStudio window) and open the project called ae. If there are any uncommitted files, commit them, and then click Pull.\n\nIf you‚Äôve new:\nor haven‚Äôt been following along with the application exercises‚Ä¶\nGo to the course GitHub org and find your ae repo. Clone the repo in your container, open the Quarto document called ae-03-duke-forest.\n\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "labs/lab-5.html",
    "href": "labs/lab-5.html",
    "title": "Lab 5 - Potpourri",
    "section": "",
    "text": "In this lab you‚Äôll review and get practice with a variety of concepts, methods, and tools you‚Äôve encountered thus far.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#question-1",
    "href": "labs/lab-5.html#question-1",
    "title": "Lab 5 - Potpourri",
    "section": "Question 1",
    "text": "Question 1\n\nAdd each of strings below to the code chunk provided in your document, render the document, and determine if the string is a proper code chunk label. If not, explain why and describe how you could fix it so the document renders.\n\nChunk label 1:\n\n#| label: a-label \n#| with-a-line-break\n\nChunk label 2:\n\n#| label: areaaaaaaaaaaaaaaaaaaaaaallllllllllllllllllyyyyylooooooooooooooooooonglabel \n\nChunk label 3:\n\n#| label: label with spaces\n\nChunk label 4:\n\n#| label: label-with-dashes\n\n\n\n\n\n\nTip\n\n\n\nTry each label option in the code chunk provided in your document. If it gives you an error (document doesn‚Äôt render), you know it‚Äôs not a proper chunk label.\n\n\nWhich of the chunk label options above is the best option? Explain your reasoning in 1-2 sentences.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#question-2",
    "href": "labs/lab-5.html#question-2",
    "title": "Lab 5 - Potpourri",
    "section": "Question 2",
    "text": "Question 2\nYou have the following code chunk:\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\nAdd the following code chunk options, one at a time, and set each to false and then to true. After each value, render your document and observe its effect. Ultimately, choose the values that are the most appropriate for this code chunk. Based on the behaviors you observe, describe what each code chunk option does.\n\necho\nwarning\neval",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#question-3",
    "href": "labs/lab-5.html#question-3",
    "title": "Lab 5 - Potpourri",
    "section": "Question 3",
    "text": "Question 3\n\nYou have the following code chunk again.\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\nAdd fig-width and fig-asp as code chunk options. Try setting fig-width to values between 1 and 10. Try setting fig-asp to values between 0.1 and 1. Re-render the document after each value and observe its effect. Ultimately, choose values that make the plot look visually pleasing in the rendered document. Based on the behavior you observe, describe what each chunk option does.\nYou have the following code chunk, but look carefully, it‚Äôs not exactly the same!\n\ngplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\nAdd error as a code chunk option and set it to false and then set it to true. After each value, render your document and observe its effect. Ultimately, choose the value that allows you to render your document without altering the code. Based on the behavior you observe, describe what this code chunk option does.\n\n\n\n\n\n\n\nTip\n\n\n\nReading the documentation might also be hepful.\n\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#question-4",
    "href": "labs/lab-5.html#question-4",
    "title": "Lab 5 - Potpourri",
    "section": "Question 4",
    "text": "Question 4\nThe following chart was shared by @GraphCrimes on X/Twitter on September 3, 2022.\n\n\n\n\n\n\nWhat is misleading about this graph?\nSuppose you wanted to recreate this plot, with improvements to avoid its misleading pitfalls from part (a). You would obviously need the data from the survey in order to be able to do that. How many observations would this data have? How many variables (at least) should it have, and what should those variables be?\nLoad the data for this survey from data/survation.csv. Confirm that the data match the percentages from the visualization. That is, calculate the percentages of public sector, private sector, don‚Äôt know for each of the services and check that they match the percentages from the plot.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#question-5",
    "href": "labs/lab-5.html#question-5",
    "title": "Lab 5 - Potpourri",
    "section": "Question 5",
    "text": "Question 5\nCreate an improved version of the visualization. Your improved visualization:\n\nshould also be a stacked bar chart with services on the y-axis, presented in the same order as the original plot, and services to create the segments of the plot, and presented in the same order as the original plot\nshould have the same legend location\nshould have the same title and caption\ndoes not need to have a bolded title or a gray background\n\nHow does the improved visualization look different than the original? Does it send a different message at a first glance?\n\n\n\n\n\n\nTip\n\n\n\nUse \\n to add a line break to your title. And note that since the title is very long, it might run off the page in your code. That‚Äôs ok!\nAdditionally, the colors used in the plot are gray, #FF3205, and #006697.\n\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#question-6",
    "href": "labs/lab-5.html#question-6",
    "title": "Lab 5 - Potpourri",
    "section": "Question 6",
    "text": "Question 6\nIn a single pipeline, calculate the mean of x, mean of y, standard deviation of x, standard deviation of y, and the correlation between x and y for each level of the dataset variable. Then, in 1-2 sentences, comment on how these summary statistics compare across groups (datasets).\n\n\n\n\n\n\nTip\n\n\n\nThere are 13 groups but tibbles only print out 10 rows by default. Add print(n = 13) as the last step of your pipeline to display all rows.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#question-7",
    "href": "labs/lab-5.html#question-7",
    "title": "Lab 5 - Potpourri",
    "section": "Question 7",
    "text": "Question 7\nCreate a scatterplot of y versus x and color and facet it by dataset. Then, in 1-2 sentences, how these plots compare across groups (datasets). How does your response in this question compare to your response to the previous question and what does this say about using visualizations and summary statistics when getting to know a dataset?\n\n\n\n\n\n\nTip\n\n\n\nWhen you both color and facet by the same variable, you‚Äôll end up with a redundant legend. Turn off the legend by adding show.legend = FALSE to the geom creating the legend.\n\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#question-8",
    "href": "labs/lab-5.html#question-8",
    "title": "Lab 5 - Potpourri",
    "section": "Question 8",
    "text": "Question 8\n\nFill in the code below to create a two-way table that summarizes these data.\n\nsurvey_counts &lt;- tibble( \n  age = c(),\n  vote = c(),\n  n = c()\n  )\n\nsurvey_counts |&gt;\n  pivot_wider( \n    names_from = ___,\n    values_from = ___\n  ) |&gt;\n  kable()\n\n\nFor parts b-d below, use a your response single pipeline starting with survey_counts, calculate the desired proportions, and make sure the result is an ungrouped data frame with a column for relevant counts, a column for relevant proportions, and a column for the groups you‚Äôre interested in.\n\nCalculate the proportions of 18-49 year olds and 50+ year olds in this sample.\nCalculate the proportions of those who want to vote for Donald Trump, Joe Biden, and those who are undecided in this sample.\nCalculate the proportions of individuals in this sample who are planning to vote for each of the candidates or are undecided among those who are 18-49 years old as well as among those who are 50+ years old.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#question-9",
    "href": "labs/lab-5.html#question-9",
    "title": "Lab 5 - Potpourri",
    "section": "Question 9",
    "text": "Question 9\n\nRe-create the following visualization that displays relationship between age and vote.\n\n\n\n\n\n\n\nTip\n\n\n\nThe colors used in the plot are \"#E81B23\", \"#0015BC\", and \"gray\". The theme is theme_minimal().\n\n\nBased on your calculations so far, as well as your visualization, write 1-3 sentences that describe the relationship, in this sample, between age and plans for presidential vote.\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#question-10",
    "href": "labs/lab-5.html#question-10",
    "title": "Lab 5 - Potpourri",
    "section": "Question 10",
    "text": "Question 10\nTo complete this exercise you will first need to watch the documentary Coded Bias. To do so, you either need to be on the Duke network or connected to the Duke VPN. Then go to https://find.library.duke.edu/catalog/DUKE009834953 and click on ‚ÄúView Online‚Äù. Once you watch the video, write a reflection in 2-5 bullet points highlighting at least one thing that you already knew about (from the course prep materials) and at least one thing you learned from the movie as well as any other aspects of the documentary that you found interesting / enlightening.\n\n\n\n\n\n\nImportant\n\n\n\nThis question requires no code, only narrative. Remember that, based on the syllabus, you may not use generative AI tools (e.g., Chat GPT) to write narrative on assignments.\n\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#submission",
    "href": "labs/lab-5.html#submission",
    "title": "Lab 5 - Potpourri",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered ‚Äúon time‚Äù.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark all the pages associated with question. All the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#grading",
    "href": "labs/lab-5.html#grading",
    "title": "Lab 5 - Potpourri",
    "section": "Grading",
    "text": "Grading\nThe lab is graded out of a total of 50 points.\nYou can earn up to 5 points on each question:\n\n5: Response shows excellent understanding and addresses all or almost all of the rubric items.\n4: Response shows good understanding and addresses most of the rubric items.\n3: Response shows understanding and addresses a majority of the rubric items.\n2: Response shows effort and misses many of the rubric items.\n1: Response does not show sufficient effort or understanding and/or is largely incomplete.\n0: No attempt.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#footnotes",
    "href": "labs/lab-5.html#footnotes",
    "title": "Lab 5 - Potpourri",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFull survey results can be found at https://www.surveyusa.com/client/PollReport.aspx?g=300d50f5-303b-4652-b59e-6fbf1b87e24a.‚Ü©Ô∏é",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-7-draft.html",
    "href": "labs/lab-7-draft.html",
    "title": "Lab 7 - Modeling II",
    "section": "",
    "text": "In this lab you‚Äôll continue your practice of statistical modeling and then venture on to quantifying uncertainty.\n\n\nIn this lab we will work with the tidyverse and tidymodels packages.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\n\n\nYour plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nIn addition, the code should all the code should be be able to be read (not run off the page) when you render to PDF. Make sure that is the case, and add line breaks where the code is running off the page.\n\n\n\n\n\n\nImportant\n\n\n\nRender your document. If your code is running off the page for a given question such that we can‚Äôt see your entire code, we will not evaluate any of the code for that question. The question will automatically receive a 0. This is something you can and should verify before you turn in your work.\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment.\nAdditionally, if you‚Äôre using functions that are not introduced in the course materials, you must cite your sources.\n\n\n\n\n\n\nImportant\n\n\n\nFailure to cite outside resources used, including Large Language Models like Chat GPT, is a violation of the Duke Community Standard and will be treated as such."
  },
  {
    "objectID": "labs/lab-7-draft.html#packages",
    "href": "labs/lab-7-draft.html#packages",
    "title": "Lab 7 - Modeling II",
    "section": "",
    "text": "In this lab we will work with the tidyverse and tidymodels packages.\n\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "labs/lab-7-draft.html#guidelines",
    "href": "labs/lab-7-draft.html#guidelines",
    "title": "Lab 7 - Modeling II",
    "section": "",
    "text": "Your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nIn addition, the code should all the code should be be able to be read (not run off the page) when you render to PDF. Make sure that is the case, and add line breaks where the code is running off the page.\n\n\n\n\n\n\nImportant\n\n\n\nRender your document. If your code is running off the page for a given question such that we can‚Äôt see your entire code, we will not evaluate any of the code for that question. The question will automatically receive a 0. This is something you can and should verify before you turn in your work.\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment.\nAdditionally, if you‚Äôre using functions that are not introduced in the course materials, you must cite your sources.\n\n\n\n\n\n\nImportant\n\n\n\nFailure to cite outside resources used, including Large Language Models like Chat GPT, is a violation of the Duke Community Standard and will be treated as such."
  },
  {
    "objectID": "labs/lab-7-draft.html#question-1",
    "href": "labs/lab-7-draft.html#question-1",
    "title": "Lab 7 - Modeling II",
    "section": "Question 1",
    "text": "Question 1\na. Fit a logistic regression model predicting spam from exclaim_mess (the number of exclamation points in the email message). Then, display the tidy output of the model.\nb. Using this model and an R function like predict() or augment(), predict the probability the email is spam if it contains 10 exclamation points."
  },
  {
    "objectID": "labs/lab-7-draft.html#question-2",
    "href": "labs/lab-7-draft.html#question-2",
    "title": "Lab 7 - Modeling II",
    "section": "Question 2",
    "text": "Question 2\na. Fit another logistic regression model predicting spam from exclaim_mess, winner (indicating whether ‚Äúwinner‚Äù appeared in the email), and urgent_subj (whether the word ‚Äúurgent‚Äù is in the subject of the email). Then, display the tidy output of the model.\nb. Using this model, predict spam / not spam for all emails in the openintro dataset with augment(). Store the resulting data frame with an appropriate name.\nc. Using your data frame from the previous part, determine, in a single pipeline, and using count(), the numbers of emails:\n\nthat are labelled as spam that are actually spam\nthat are not labelled as spam that are actually spam\nthat are labelled as spam that are actually not spam\nthat are not labelled as spam that are actually not spam\n\nStore the resulting data frame with an appropriate name.\nd. In a single pipeline, and using mutate(), calculate the false positive and false negative rates."
  },
  {
    "objectID": "labs/lab-7-draft.html#question-3",
    "href": "labs/lab-7-draft.html#question-3",
    "title": "Lab 7 - Modeling II",
    "section": "Question 3",
    "text": "Question 3\na. Fit another logistic regression model predicting spam from exclaim_mess and another variable you think would be a good predictor. Provide a 1-sentence justification for why you chose this variable. Display the tidy output of the model.\nb. Using this model, predict spam / not spam for all emails in the openintro dataset with augment(). Store the resulting data frame with an appropriate name.\nc. Using your data frame from the previous part, determine, in a single pipeline, and using count(), the numbers of emails:\n\nthat are labelled as spam that are actually spam\nthat are not labelled as spam that are actually spam\nthat are labelled as spam that are actually not spam\nthat are not labelled as spam that are actually not spam\n\nStore the resulting data frame with an appropriate name.\nd. In a single pipeline, and using mutate(), calculate the false positive and false negative rates.\ne. Based on the false positive and false negatives rates of this model, comment, in 1-2 sentences, on which model is preferable and why."
  },
  {
    "objectID": "labs/lab-7-draft.html#question-4",
    "href": "labs/lab-7-draft.html#question-4",
    "title": "Lab 7 - Modeling II",
    "section": "Question 4",
    "text": "Question 4\nExplore attributes of bookings and summarize your findings in 5 bullet points. You must provide a visualization or summary supporting each finding.\n\n\n\n\n\n\nNote\n\n\n\nThis is not meant to be an exhaustive exploration. We anticipate a wide variety of answers to this question."
  },
  {
    "objectID": "labs/lab-7-draft.html#question-5",
    "href": "labs/lab-7-draft.html#question-5",
    "title": "Lab 7 - Modeling II",
    "section": "Question 5",
    "text": "Question 5\nUsing these data, we will try to answer the following question:\n\nDo we expect reservations earlier in the month or later in the month to be cancelled?\n\n\nExploration: In a single pipeline, calculate the mean arrival date (arrival_date_day_of_month) for both booking that were cancelled and that were not cancelled.\nJustification: In your own words, explain why we can not fit a linear model to model the relationship between if a hotel reservation was cancelled and the day of month for the booking.\nModel fitting and interpretation:\n\nFit the appropriate model and display a tidy summary of the model output.\nInterpret the slope coefficient in context of the data and the research question.\n\nEstimated model: Write out the estimated model using proper notation.\nPredicted: Calculate the probability that the hotel reservation is cancelled if it the arrival date date is on the 26th of the month. Based on this probability, would you predict this booking would be cancelled or not cancelled. Explain your reasoning for your classification."
  },
  {
    "objectID": "labs/lab-7-draft.html#question-6",
    "href": "labs/lab-7-draft.html#question-6",
    "title": "Lab 7 - Modeling II",
    "section": "Question 6",
    "text": "Question 6\nYou have two options for this exercise. Clearly indicate which option you choose.\nOption 1: Listen to a podcast or watch a video about statistics and data science. The podcast or video must be at least 30 minutes to count towards the statistics experience. A few suggestions are below:\n\nposit::conf 2023 talks\nrstudio::conf 2022 talks\nrstudio::global 2021 talks\nrstudio::conf 2020 talks\nStats + Stories Podcast\nCasual Inference Podcast\nNot So Standard Deviations\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask your professor if you are unsure whether a particular podcast or video will count towards the statistics experience.\nOption 2: Talk with someone who uses statistics in their daily work. This could include a professor, professional in industry, graduate student, etc."
  },
  {
    "objectID": "labs/lab-7-draft.html#question-7",
    "href": "labs/lab-7-draft.html#question-7",
    "title": "Lab 7 - Modeling II",
    "section": "Question 7",
    "text": "Question 7\nYour task is to make the following plot as ugly and as ineffective as possible. Change colors, axes, fonts, theme, or anything else you can think of in the code chunk below. You can also search online for other themes, fonts, etc. that you want to tweak. Try to make it as ugly as possible, the sky is the limit!\nIn 2-3 sentences, explain why the plot you created is ugly (to you, at least) and ineffective.\n\nggplot(\n  penguins, \n  aes(x = flipper_length_mm, y = bill_length_mm, color = species)\n  ) + \n  geom_point()"
  },
  {
    "objectID": "labs/lab-7-draft.html#question-8",
    "href": "labs/lab-7-draft.html#question-8",
    "title": "Lab 7 - Modeling II",
    "section": "Question 8",
    "text": "Question 8\nIn 2016, the GSS added a new question on harassment at work. The question is phrased as the following.\nOver the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?\nAnswers to this question are stored in the harass5 variable in our data set.\n\nCreate a subset of the data that only contains Yes and No answers for the harassment question. How many responsdents chose each of these answers?\nDescribe how bootstrapping can be used to estimate the proportion of all Americans who have been harassed by their superiors or co-workers at their job.\nCalculate a 95% bootstrap confidence interval for the proportion of Americans who have been harassed by their superiors or co-workers at their job. Use 1000 iterations when creating your bootstrap distribution. Interpret this interval in context of the data."
  },
  {
    "objectID": "labs/lab-7-draft.html#question-9",
    "href": "labs/lab-7-draft.html#question-9",
    "title": "Lab 7 - Modeling II",
    "section": "Question 9",
    "text": "Question 9\n\n\n\n\n\n\nImportant\n\n\n\nThis question is graded out of 10 points.\n\n\nTake a data science assessment at https://duke.qualtrics.com/jfe/form/SV_bPZS3LIKoYA0fL8. Your assessment will be graded out of 10 points, and those points will be added to your score for the remaining points on this lab. There are no additional penalties for wrong answers, so please answer all questions.\nOptionally, you can participate in the research study this assessment is a part of. I will not find out whether you participate in the study or not, your scores will be passed on to me by the research administrator regardless of your study participation."
  },
  {
    "objectID": "labs/lab-1.html",
    "href": "labs/lab-1.html",
    "title": "Lab 1 - Data visualization",
    "section": "",
    "text": "This lab will introduce you to the course computing workflow. The main goal is to reinforce our demo of R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\n\n\n\n\n\n\nNote\n\n\n\nR is the name of the programming language itself and RStudio is a convenient interface, commonly referred to as an integrated development environment or an IDE, for short.\n\n\nAn additional goal is to reinforce Git and GitHub, the version control, web hosting, and collaboration systems that we will be using throughout the course.\n\n\n\n\n\n\nNote\n\n\n\nGit is a version control system (like ‚ÄúTrack Changes‚Äù features from Microsoft Word but more powerful) and GitHub is the home for your Git-based projects on the internet (like DropBox but much better).\n\n\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\n\n\n\n\n\n\nWarning\n\n\n\nThis lab assumes that you have already completed Lab 0. If you have not, please go back and do that first before proceeding.\n\n\n\n\nBy the end of the lab, you will‚Ä¶\n\nBe familiar with the workflow using R, RStudio, Git, and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using Git and GitHub\nBe able to create data visualizations using ggplot2\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\n\n\n\nGo to the course organization at github.com/sta199-s24 organization on GitHub. Click on the repo with the prefix lab-1. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you‚Äôll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ‚ûõ New Project ‚ûõVersion Control ‚ûõ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-1.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\n\n\n\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file.\n\n\n\n\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for ‚ÄúYAML Ain‚Äôt Markup Language‚Äù. It is a human friendly data representation for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document. Examine the rendered document.\n\n\n\n\n\nNow, go to the Git pane in your RStudio instance. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\nIf you‚Äôre happy with these changes, we‚Äôll prepare the changes to be pushed to your remote repository. First, stage your changes by checking the appropriate box on the files you want to prepare. Next, write a meaningful commit message (for instance, ‚Äúupdated author name‚Äù) in the Commit message box. Finally, click Commit. Note that every commit needs to have a commit message associated with it.\nYou don‚Äôt have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration.\nIn the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\nNow let‚Äôs make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you‚Äôre good to go!\n\n\n\nNow that you have made an update and committed this change, it‚Äôs time to push these changes to your repo on GitHub.\nIn order to push your changes to GitHub, you must have staged your commit to be pushed. click on Push.\n\n\n\n\nIn this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a ‚Äútidy‚Äù way.\n\nlibrary(tidyverse)\n\nRender the document which loads this package with the library() function.\n\n\n\n\n\n\nNote\n\n\n\nThe rendered document will include a message about which packages the tidyverse package is loading along with it. It‚Äôs just R being informative, a message does not indicate anything is wrong (it‚Äôs not a warning or an error).\n\n\nThe tidyverse is a meta-package. When you load it you get nine packages loaded for you:\n\ndplyr: for data wrangling\nforcats: for dealing with factors\nggplot2: for data visualization\nlubridate: for dealing with dates\npurrr: for iteration with functional programming\nreadr: for reading and writing data\nstringr: for string manipulation\ntibble: for modern, tidy data frames\ntidyr: for data tidying and rectangling\n\nThe message that‚Äôs printed when you load the package tells you which versions of these packages are loaded as well as any conflicts they may have introduced, e.g., the filter() function from dplyr has now masked (overwritten) the filter() function available in base R (and that‚Äôs ok, we‚Äôll use dplyr::filter() anyway).\nYou can now Render your template document and see the results.\n\n\n\nAs we‚Äôve discussed in lecture, your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nIn addition, the code should all the code should be be able to be read (not run off the page) when you render to PDF. Make sure that is the case, and add line breaks where the code is running off the page.1\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#learning-objectives",
    "href": "labs/lab-1.html#learning-objectives",
    "title": "Lab 1 - Data visualization",
    "section": "",
    "text": "By the end of the lab, you will‚Ä¶\n\nBe familiar with the workflow using R, RStudio, Git, and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using Git and GitHub\nBe able to create data visualizations using ggplot2",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#getting-started",
    "href": "labs/lab-1.html#getting-started",
    "title": "Lab 1 - Data visualization",
    "section": "",
    "text": "Go to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\n\n\n\nGo to the course organization at github.com/sta199-s24 organization on GitHub. Click on the repo with the prefix lab-1. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you‚Äôll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ‚ûõ New Project ‚ûõVersion Control ‚ûõ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-1.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\n\n\n\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file.\n\n\n\n\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for ‚ÄúYAML Ain‚Äôt Markup Language‚Äù. It is a human friendly data representation for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document. Examine the rendered document.\n\n\n\n\n\nNow, go to the Git pane in your RStudio instance. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\nIf you‚Äôre happy with these changes, we‚Äôll prepare the changes to be pushed to your remote repository. First, stage your changes by checking the appropriate box on the files you want to prepare. Next, write a meaningful commit message (for instance, ‚Äúupdated author name‚Äù) in the Commit message box. Finally, click Commit. Note that every commit needs to have a commit message associated with it.\nYou don‚Äôt have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration.\nIn the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\nNow let‚Äôs make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you‚Äôre good to go!\n\n\n\nNow that you have made an update and committed this change, it‚Äôs time to push these changes to your repo on GitHub.\nIn order to push your changes to GitHub, you must have staged your commit to be pushed. click on Push.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#packages",
    "href": "labs/lab-1.html#packages",
    "title": "Lab 1 - Data visualization",
    "section": "",
    "text": "In this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a ‚Äútidy‚Äù way.\n\nlibrary(tidyverse)\n\nRender the document which loads this package with the library() function.\n\n\n\n\n\n\nNote\n\n\n\nThe rendered document will include a message about which packages the tidyverse package is loading along with it. It‚Äôs just R being informative, a message does not indicate anything is wrong (it‚Äôs not a warning or an error).\n\n\nThe tidyverse is a meta-package. When you load it you get nine packages loaded for you:\n\ndplyr: for data wrangling\nforcats: for dealing with factors\nggplot2: for data visualization\nlubridate: for dealing with dates\npurrr: for iteration with functional programming\nreadr: for reading and writing data\nstringr: for string manipulation\ntibble: for modern, tidy data frames\ntidyr: for data tidying and rectangling\n\nThe message that‚Äôs printed when you load the package tells you which versions of these packages are loaded as well as any conflicts they may have introduced, e.g., the filter() function from dplyr has now masked (overwritten) the filter() function available in base R (and that‚Äôs ok, we‚Äôll use dplyr::filter() anyway).\nYou can now Render your template document and see the results.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#guidelines",
    "href": "labs/lab-1.html#guidelines",
    "title": "Lab 1 - Data visualization",
    "section": "",
    "text": "As we‚Äôve discussed in lecture, your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nIn addition, the code should all the code should be be able to be read (not run off the page) when you render to PDF. Make sure that is the case, and add line breaks where the code is running off the page.1\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#part-1",
    "href": "labs/lab-1.html#part-1",
    "title": "Lab 1 - Data visualization",
    "section": "Part 1",
    "text": "Part 1\nLet‚Äôs take a trip to the Midwest!\nWe will use the midwest data frame for this lab. It is part of the ggplot2 R package, so the midwest data set is automatically loaded when you load the tidyverse package.\nThe data contains demographic characteristics of counties in the Midwest region of the United States.\nBecause the data set is part of the ggplot2 package, you can read documentation for the data set, including variable definitions by typing ?midwest in the Console or searching for midwest in the Help pane.\n\nQuestion 1\nVisualize the distribution of population density of counties using a histogram with geom_histogram() with four separate binwidths: a binwidth of 100, a binwidth of 1,000, a binwidth of 10,000, and a binwidth of 100,000. For example, you can create the first plot with:\n\nggplot(midwest, aes(x = popdensity)) +\n  geom_histogram(binwidth = 100) +\n  labs(\n    x = \"Population density\",\n    y = \"Count\",\n    title = \"Population density of midwesten counties\",\n    subtitle = \"Binwidth = 100\"\n  )\n\nYou will need to make four different histograms. Make sure to set informative titles and axis labels for each of your plots. Then, comment on which binwidth is most appropriate for these data and why.\n\nRender, commit, and push your changes to GitHub with the commit message ‚ÄúAdded answer for Question 1‚Äù.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\n\n\nQuestion 2\nVisualize the distribution of population density of counties again, this time using a boxplot with geom_boxplot(). Make sure to set informative titles and axis labels for your plot. Then, using information as needed from the box plot as well as the histogram from Question 1, describe the distribution of population density of counties and comment on any potential outliers, making sure to identify at least one county that is a clear outlier by name in your narrative and commenting on whether it makes sense to you that this county is an outlier. You can use the data viewer to identify the outliers interactively, you do not have to write code to identify them.\n\nRender, commit, and push your changes to GitHub with the commit message ‚ÄúAdded answer for Question 2‚Äù.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\n\n\nQuestion 3\nCreate a scatterplot of the percentage below poverty (percbelowpoverty on the y-axis) versus percentage of people with a college degree (percollege on the x-axis), where the color and shape of points are determined by state. Make sure to set informative titles, axis, and legend labels for your plot. First, describe the overall relationship between percentage of people with a college degree and percentage below poverty in Midwestern states, making sure to identify at least one county that is a clear outlier by name in your narrative. You can use the data viewer to identify the outliers interactively, you do not have to write code to identify them. Then, comment on whether you can identify how this relationship varies across states.\n\nRender, commit, and push your changes to GitHub with the commit message ‚ÄúAdded answer for Question 3‚Äù.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\n\n\nQuestion 4\nNow, let‚Äôs examine the relationship between the same two variables, once again using different colors and shapes to represent each state, and using a separate plot for each state, i.e., with faceting with facet_wrap(). In addition to points (geom_point()), represent the data with a smooth curve fit to the data with geom_smooth(), with the argument se = FALSE. Make sure to set informative titles, axis, and legend labels for your plot. Which plot do you prefer - this plot or the plot in Question 3? Briefly explain your choice.\n\n\n\n\n\n\nNote\n\n\n\nse = FALSE removes the confidence bands around the line. These bands show the uncertainty around the smooth curve. We‚Äôll discuss uncertainty around estimates later in the course and bring these bands back then.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message ‚ÄúAdded answer for Question 4‚Äù.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\n\n\nQuestion 5\nDo some states have counties that tend to be geographically larger than others?\nTo explore this question, create side-by-side boxplots of area (area) of a county based on state (state). How do typical county area sizes compare across states? How do variabilities of county sizes compare across states? Which state has the single largest county? Identify the name of this county. You can use the data viewer to identify it interactively, you do not have to write code.\n\nNow is another good time to render, commit, and push your changes to GitHub with a meaningful commit message.\nOnce again, make sure to commit and push all changed files so that your Git pane is empty afterwards.\n\n\n\nQuestion 6\nDo some states have a higher percentage of their counties located in a metropolitan area?\nCreate a segmented bar chart with one bar per state and the bar filled with colors according to the value of metro ‚Äì one color indicating Yes and the other color indicating No for whether a county is considered to be a metro area. The y-axis of the segmented barplot should range from 0 to 1, indicating proportions. Compare the percentage of counties in metro areas across the states based on this plot. Make sure to supplement your narrative with rough estimates of these percentages.\n\n\n\n\n\n\nHint\n\n\n\nFor this question, you should begin with the data wrangling pipeline below. We will learn more about data wrangling in the coming weeks, so this is a mini-preview. This pipeline creates a new variable called metro based on the value of the existing variable called inmetro. If the value of inmetro is equal to 1 (inmetro == 1), it sets the value of metro to \"Yes\", and if not, it sets the value of metro to \"No\". The resulting data frame is assigned back to midwest, overwriting the existing midwest data frame with a version that includes the new metro variable.\n\nmidwest &lt;- midwest |&gt;\n  mutate(metro = if_else(inmetro == 1, \"Yes\", \"No\"))\n\n\n\n\nNow is another good time to render, commit, and push your changes to GitHub with a meaningful commit message.\nAnd once again, make sure to commit and push all changed files so that your Git pane is empty afterward. We keep repeating this because it‚Äôs important and because we see students forget to do this. So take a moment to make sure you‚Äôre following along with the version control instructions.\n\n\n\nQuestion 7\nRecreate the plot below, and then give it a title. Then, identify at least one county that is a clear outlier in Wisconsin (WI) by name. You can use the data viewer to identify them interactively, you do not have to write code. Comment on the population composition of this county by investigating the percentage of other races living there.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\nThe ggplot2 reference for themes will be helpful in determining the theme.\nThe size of the points is 2.\nThe transparency (alpha) of the points is 0.5.\nYou can put line breaks in labels with \\n.\n\n\n\n\nRender, commit, and push your final changes to GitHub with a meaningful commit message.\nMake sure to commit and push all changed files so that your Git pane is empty afterwards.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#part-2",
    "href": "labs/lab-1.html#part-2",
    "title": "Lab 1 - Data visualization",
    "section": "Part 2",
    "text": "Part 2\nEnough about the Midwest!\nIn this part we will use a new, more recent, and potentially more relevant dataset on counties in North Carolina.\nThis dataset is stored in a file called nc-county.csv in the data folder of your project/repository.\nYou can read this file into R with the following code:\n\nnc_county &lt;- read_csv(\"data/nc-county.csv\")\n\nThis will read the CSV (comma separated values) file from the data folder and store the dataset as a data frame called nc_county in R.\nThe variables in the dataset and their descriptions are as follows:\n\ncounty: Name of county.\nstate_abb: State abbreviation (NC).\nstate_name: State name (North Carolina).\nland_area_m2: Land area of county in meters-squared, based on the 2020 census.\nland_area_mi2: Land area of county in miles-squared, based on the 2020 census.\npopulation: Population of county, based on the 2020 census.\ndensity: Population density calculated as population divided by land area in miles-squared.\n\nIn addition to being more recent and more relevant, this dataset is also more complete in the sense that we know the units of population density: people per mile-squared!\n\nQuestion 8\nFirst, guess what the relationship between population density and land area might be ‚Äì positive? negative? no relationship?\nThen, make a scatter plot of population density (density on the y-axis) vs.¬†land area in miles-squared (land_area_mi2 on the x-axis). Make sure to set an informative title and axis labels for your plot. Describe the relationship. Was your guess correct?\n\n\nQuestion 9\nNow make a scatter plot of population density (density on the y-axis) vs.¬†land area in meters-squared (land_area_m2 on the x-axis). Make sure to set an informative title and axis labels for your plot. Comment on how this scatterplot compares to the one in Exercise 8 ‚Äî is the relationship displayed same or different. Explain why.\n\n\nQuestion 10\nDid you select your pages on Gradescope? You don‚Äôt need to write an answer for this question, if you select your pages when you upload your lab to Gradescope, you‚Äôll get full points on this question. Otherwise, you‚Äôll get a 0 on this question.2",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#submission",
    "href": "labs/lab-1.html#submission",
    "title": "Lab 1 - Data visualization",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered ‚Äúon time‚Äù.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark all the pages associated with question. All the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#grading",
    "href": "labs/lab-1.html#grading",
    "title": "Lab 1 - Data visualization",
    "section": "Grading",
    "text": "Grading\nThe lab is graded out of a total of 50 points.\nOn Questions 1 through 9, you can earn up to 5 points on each question:\n\n5: Response shows excellent understanding and addresses all or almost all of the rubric items.\n4: Response shows good understanding and addresses most of the rubric items.\n3: Response shows understanding and addresses a majority of the rubric items.\n2: Response shows effort and misses many of the rubric items.\n1: Response does not show sufficient effort or understanding and/or is largely incomplete.\n0: No attempt.\n\nOn Question 10, you can earn either 0 or 5 points for selecting questions and pages on Gradescope:\n\n5: Selected questions and pages on Gradescope.\n0: Did not select some or all questions and pages on Gradescope.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#footnotes",
    "href": "labs/lab-1.html#footnotes",
    "title": "Lab 1 - Data visualization",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRemember, haikus not novellas when writing code!‚Ü©Ô∏é\nWe‚Äôre assigning points to this seemingly trivial task because not selecting your pages and questions will greatly slow down the grading. So we want to make sure you‚Äôre properly motivated to complete this task!‚Ü©Ô∏é",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-6.html",
    "href": "labs/lab-6.html",
    "title": "Lab 6 - Modeling I",
    "section": "",
    "text": "In this lab you‚Äôll start your practice of statistical modeling. You‚Äôll fit models, interpret model output, and make decisions about your data and research question based on the model results.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#question-1",
    "href": "labs/lab-6.html#question-1",
    "title": "Lab 6 - Modeling I",
    "section": "Question 1",
    "text": "Question 1\nWe are interested in the impact of smoking during pregnancy. Since it is not possible to run a randomized controlled experiment to investigate this impact, we will instead use a data set has been of interest to medical researchers who are studying the relation between habits and practices of expectant mothers and the birth of their children. This is a random sample of 1,000 cases from a data set released in 2014 by the state of North Carolina. The data set is called births14, and it is included in the openintro package you loaded at the beginning of the assignment.\n\nCreate a version of the births14 data set dropping observations where there are NAs for habit. You can call this version births14_habitgiven.\nPlotting the data is a useful first step because it helps us quickly visualize trends, identify strong associations, and develop research questions. Create an appropriate plot displaying the relationship between weight and habit. In 2-3 sentences, discuss the relationships observed.\nNow, fit a linear model that predicts weight from habit. Provide the tidy summary output below.\nWrite the estimated least squares regression line below using proper notation.\n\n\n\n\n\n\nTip\n\n\n\nIf you need to type an equation using proper notation, type your answers in-between $$ and $$. You may use \\hat{example} to put a hat on a character.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#question-2",
    "href": "labs/lab-6.html#question-2",
    "title": "Lab 6 - Modeling I",
    "section": "Question 2",
    "text": "Question 2\n\nAnother researcher is interested in assessing the relationship between babies‚Äô weights and mothers‚Äô ages. Fit another linear model to investigate this relationship. Provide the summary output below.\nIn 2-3 sentences, explain how the regression line to model these data is fit, i.e., based on what criteria R determines the regression line.\nInterpret the intercept in the context of the data and the research question. Is the intercept meaningful in this context? Why or why not?\nInterpret the slope in the context of the data and the research question.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#question-3",
    "href": "labs/lab-6.html#question-3",
    "title": "Lab 6 - Modeling I",
    "section": "Question 3",
    "text": "Question 3\nLet‚Äôs start by reading in the parasites data and examining the relationship between divergence_time and parsim.\n\nLoad the data and save the data frame as parasites.\nBased on the goals of the analysis, what is the response variable?\nVisualize the relationship between the two variables.\nUse the visualization to describe the relationship between the two variables.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#question-4",
    "href": "labs/lab-6.html#question-4",
    "title": "Lab 6 - Modeling I",
    "section": "Question 4",
    "text": "Question 4\nNext, model this relationship.\n\nFit the model and write the estimated regression equation.\nInterpret the slope and the intercept in the context of the data.\nRecreate the visualization from Question 3, this time adding a regression line to the visualization.\nWhat do you notice about the prediction (regression) line that may be strange, particularly for very large divergence times?",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#question-5",
    "href": "labs/lab-6.html#question-5",
    "title": "Lab 6 - Modeling I",
    "section": "Question 5",
    "text": "Question 5\nSince parsim takes values between 0 and 1, we want to transform this variable so that it can range between (‚àí‚àû,+‚àû). This will be better suited for fitting a regression model (and interpreting predicted values!)\n\nUsing mutate, create a new variable transformed_parsim that is calculated as log(parsim/(1-parsim)). Add this variable to your data frame.\n\n\n\n\n\n\nNote\n\n\n\nlog() in R represents the nautral log.\n\n\nThen, visualize the relationship between divergence_time and transformed_parsim. Add a regression line to your visualization.\nWrite a 1-2 sentence description of what you observe in the visualization.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#question-6",
    "href": "labs/lab-6.html#question-6",
    "title": "Lab 6 - Modeling I",
    "section": "Question 6",
    "text": "Question 6\nWhich variable is the strongest individual predictor of parasite similarity between species?\nTo answer this question, begin by fitting a linear regression model to each pair of variables. Do not report the model outputs in a tidy format but save each one as dt_model, dist_model, BM_model, and prec_model, respectively.\n\ndivergence_time and transformed_parsim\ndistance and transformed_parsim\nBMdiff and transformed_parsim\nprecdiff and transformed_parsim\n\n\nReport the slopes for each of these models. Use proper notation.\nTo answer the question of interest, would it be useful to compare the slopes in each model to choose the variable that is the strongest predictor of parasite similarity? Why or why not?",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#question-7",
    "href": "labs/lab-6.html#question-7",
    "title": "Lab 6 - Modeling I",
    "section": "Question 7",
    "text": "Question 7\nNow, what if we calculated \\(R^2\\) to help answer our question? To compare the explanatory power of each individual predictor, we will look at \\(R^2\\) between the models. \\(R^2\\) is a measure of how much of the variability in the response variable is explained by the model.\nAs you may have guessed from the name \\(R^2\\) can be calculated by squaring the correlation when we have a simple linear regression model. The correlation r takes values -1 to 1, therefore, \\(R^2\\) takes values 0 to 1. Intuitively, if r=1 or ‚àí1, then \\(R^2\\)=1, indicating the model is a perfect fit for the data. If r‚âà0 then \\(R^2\\)‚âà0, indicating the model is a very bad fit for the data.\nYou can calculate \\(R^2\\) using the glance function. For example, you can calculate \\(R^2\\) for dt_model using the code glance(dt_model)$r.squared.\n\nCalculate and report \\(R^2\\) for each model fit in the previous exercise.\nTo answer our question of interest, would it be useful to compare the \\(R^2\\) in each model to choose the variable that is the strongest predictor of parasite similarity? Why or why not?",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#question-8",
    "href": "labs/lab-6.html#question-8",
    "title": "Lab 6 - Modeling I",
    "section": "Question 8",
    "text": "Question 8\n\nData: For our analysis, we will only be working with data from 2007. Below, filter the data set so only values from the year 2007 are shown. Save this data set as gapminder_07 and use it for the remainder of this exercise and the following.\nVisualization: We are interested in learning more about GDP, and we‚Äôll start with exploring the relationship between life expectancy and GDP. Create two visualizations:\n\nScatter plot of gdpPercap vs.¬†lifeExp.\nScatter plot of gdpPercap_log vs.¬†lifeExp, where gdpPercap_log is a new variable you add to the data set by taking the natural log of gdpPercap.\n\nFirst describe the relationship between each pair of the variables. Then, comment on which relationship would be better modeled using a linear model, and explain your reasoning.\nModel fitting:\n\nFit a linear model predicting log gross domestic product from life expectancy. Display the tidy summary.\n\nModel evaluation:\n\nCalculate the R-squared of the model using two methods and confirm that the values match: first method is using glance() and the other method is based on the value of the correlation coefficient between the two variables.\nInterpret R-squared in the context of the data and the research question.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#question-9",
    "href": "labs/lab-6.html#question-9",
    "title": "Lab 6 - Modeling I",
    "section": "Question 9",
    "text": "Question 9\nNext, we want to examine if the relationship between GDP and life expectancy that we observed in the previous exercise holds across all continents in our data. We‚Äôll continue to work with logged GDP (gdpPercap_log) and data from 2007.\n\nJustification: Create a scatter plot of gdpPercap_log vs.¬†lifeExp, where the points are colored by continent. Do you think the trend between gdpPercap_log and lifeExp is different for different continents? Justify your answer with specific features of the plot.\nModel fitting and interpretation:\n\nRegardless of your answer in part (a), fit an additive model (main effects) that predicts gdpPercap_log from life expectancy and continent (with Africas as the baseline level). Display a tidy summary of the model output.\nInterpret the intercept of the model, making sure that your interpretation is in the units of the original data (not on log scale).\nInterpret the slope of the model, making sure that your interpretation is in the units of the original data (not on log scale).\n\nPrediction: Predict the GDP of a country in Asia where the average life expectancy is 70 years old.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#question-10",
    "href": "labs/lab-6.html#question-10",
    "title": "Lab 6 - Modeling I",
    "section": "Question 10",
    "text": "Question 10\nCommunication is a critical yet often overlooked part of data science. When we engage with our audience and capture their interest, we can ultimately better communicate what we are trying to share.\nPlease watch the following video: Hans Rosling: 200 years in 4 minutes.\nThen, write a paragraph (4-5 sentences) addressing the following:\n\nWhat did you enjoy about the presentation of data? What did you find interesting\nWere there any aspects of the presentation that were hard to follow? If so, what?\nWhat are your general take-aways from this presentation?\nWhat are your general take-aways from how this presentation was given?",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#submission",
    "href": "labs/lab-6.html#submission",
    "title": "Lab 6 - Modeling I",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered ‚Äúon time‚Äù.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark all the pages associated with question. All the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#grading",
    "href": "labs/lab-6.html#grading",
    "title": "Lab 6 - Modeling I",
    "section": "Grading",
    "text": "Grading\nThe lab is graded out of a total of 50 points.\nYou can earn up to 5 points on each question:\n\n5: Response shows excellent understanding and addresses all or almost all of the rubric items.\n4: Response shows good understanding and addresses most of the rubric items.\n3: Response shows understanding and addresses a majority of the rubric items.\n2: Response shows effort and misses many of the rubric items.\n1: Response does not show sufficient effort or understanding and/or is largely incomplete.\n0: No attempt.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "Intro to data science and statistical thinking. Learn to explore, visualize, and analyze data to understand natural phenomena, investigate patterns, model outcomes, and make predictions, and do so in a reproducible and shareable manner. Gain experience in data wrangling and munging, exploratory data analysis, predictive modeling, and data visualization, and effective communication of results. Work on problems and case studies inspired by and based on real-world questions and data. The course will focus on the R statistical computing language. No statistical or computing background is necessary. Not open to students who have taken a 100-level Statistical Science course, Statistical Science 210, or a Statistical Science course numbered 300 or above.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#class-meetings",
    "href": "course-overview.html#class-meetings",
    "title": "Course overview",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nBiological Sciences 111\nTue & Thur 11:45 am - 1:00 pm\n\n\nLab 01\nPerkins LINK 071 (Classroom 5)\nMon 8:30 - 9:45 am\n\n\nLab 02\nPerkins LINK 071 (Classroom 5)\nMon 10:05 - 11:20 am\n\n\nLab 03\nPerkins LINK 071 (Classroom 5)\nMon 11:45 am - 1:00 pm\n\n\nLab 04\nPerkins LINK 087 (Classroom 3)\nMon 1:25 - 2:40 pm\n\n\nLab 05\nPerkins LINK 087 (Classroom 3)\nMon 3:05 - 4:20 pm\n\n\nLab 06\nPerkins LINK 087 (Classroom 3)\nMon 4:40 - 5:55 pm\n\n\nLab 07\nOld Chemistry 003\nMon 4:40 - 5:55 pm\n\n\nLab 11\nPerkins LINK 071 (Classroom 5)\nMon 1:25 - 2:40 pm",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "exam-review/exam-1-review-A.html",
    "href": "exam-review/exam-1-review-A.html",
    "title": "Exam 1 Review",
    "section": "",
    "text": "b, c, f, g -\n\nThe blizzard_salary dataset has 409 rows.\nThe percent_incr variable is numerical and continuous.\nThe salary_type variable is categorical.\n\nFigure 1 - A shared x-axis makes it easier to compare summary statistics for the variable on the x-axis.\nc - It‚Äôs a value higher than the median for hourly but lower than the mean for salaried.\nb - There is more variability around the mean compared to the hourly distribution.\na, b, e - Pie charts and waffle charts are for visualizing distributions of categorical data only. Scatterplots are for visualizing the relationship between two numerical variables.\nc - mutate() is used to create or modify a variable.\na - \"Poor\", \"Successful\", \"High\", \"Top\"\nb - Option 2. The plot in Option 1 shows the number of employees with a given performance rating for each salary type while the plot in Option 2 gives the proportion of employees with a given performance rating for each salary type. In order to assess the relationship between these variables (e.g., how much more likely is a Top rating among Salaried vs.¬†Hourly workers), we need the proportions, not the counts.\nThere may be some NAs in these two variables that are not visible in the plot.\nThe proportions under Hourly would go in the Hourly bar, and those under Salaried would go in the Salaried bar.\nc - filter(salary_type != \"Hourly\" & performance_rating == \"Poor\") - There are 5 observations for ‚Äúnot Hourly‚Äù ‚Äúand‚Äù Poor.\na - arrange() - The result is arranged in increasing order of annual_salary, which is the default for arrange().\nc, d, e, f.\nPart 1: The following should be fixed:\n\nThere should be a | after # before label\nThere should be a : after label, not =\nThere shouldn‚Äôt be a space in the chunk label, it should be plot-blizzard\nThere should be spaces after commas in the code\nThere should be spaces on both sides of = in the code\nThere should be a space before +\ngeom_boxplot() should be on the next line and indented\nThere should be a + at the end of the geom_boxplot() line\nlabs() should be indented\n\nPart 2: The warning is caused by NA in the data. It means that 39 observations were NAs and are not plotted/represented on the plot.\nPart 1:\n\nRender: Run all of the code and render all of the text in the document and produce an output.\nCommit: Take a snapshot of your changes in Git with an appropriate message.\nPush: Send your changes off to GitHub.\n\nPart 2: c - Rendering or committing isn‚Äôt sufficient to send your changes to your GitHub repository, a push is needed. A pull is also not needed to view the changes in the browser."
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export‚Ä¶ If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you‚Äôve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder).",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#how-do-i-export-my-assignment-pdf-from-rstudio-to-upload-to-gradescope",
    "href": "course-faq.html#how-do-i-export-my-assignment-pdf-from-rstudio-to-upload-to-gradescope",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export‚Ä¶ If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you‚Äôve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder).",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you‚Äôll upload your PDF and them mark the page(s) where each question can be found. It‚Äôs OK if a question spans multiple pages, just mark them all. It‚Äôs also OK if a page includes multiple questions.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "href": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "title": "FAQ",
    "section": "Can I use a local install of R and RStudio instead of using the RStudio containers?",
    "text": "Can I use a local install of R and RStudio instead of using the RStudio containers?\nThe short answer is, I‚Äôd rather you didn‚Äôt, to save yourself some headache. But, the long answer is, sure! But you will need to install a specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we‚Äôre using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you‚Äôre working in the containers we have provided for you. If you‚Äôre working on your local setup, we can‚Äôt guarantee being able to resolve your issues, though we‚Äôre happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.3.2: https://cran.r-project.org/\nDownload and install RStudio: https://posit.co/download/rstudio-desktop/\nInstall Quarto 1.4: https://quarto.org/docs/download/prerelease.html\nInstall Git: https://happygitwithr.com/install-git.html\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I‚Äôd like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html",
    "href": "ae/ae-02-bechdel-dataviz.html",
    "title": "AE 02: Bechdel + data visualization",
    "section": "",
    "text": "In this mini analysis we work with the data used in the FiveThirtyEight story titled ‚ÄúThe Dollar-And-Cents Case Against Hollywood‚Äôs Exclusion of Women‚Äù.\nThis analysis is about the Bechdel test, a measure of the representation of women in fiction."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#getting-started",
    "href": "ae/ae-02-bechdel-dataviz.html#getting-started",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Getting started",
    "text": "Getting started\n\nPackages\nWe start with loading the packages we‚Äôll use: tidyverse for majority of the analysis and scales for pretty plot labels later on.\n\nlibrary(tidyverse)\nlibrary(scales)\n\n\n\nData\nThe data are stored as a CSV (comma separated values) file in the data folder of your repository. Let‚Äôs read it from there and save it as an object called bechdel.\n\nbechdel &lt;- read_csv(\"https://sta199-s24.github.io/data/bechdel.csv\")\n\n\n\nGet to know the data\nWe can use the glimpse function to get an overview (or ‚Äúglimpse‚Äù) of the data.\n\n# add code here\n\n\nWhat does each observation (row) in the data set represent?\n\nEach observation represents a ___.\n\nHow many observations (rows) are in the data set?\n\nThere are 1615 movies in the dataset.\n\nHow many variables (columns) are in the data set?\n\nThere are ___ columns in the dataset.\n\n\nVariables of interest\nThe variables we‚Äôll focus on are the following:\n\nbudget_2013: Budget in 2013 inflation adjusted dollars.\ngross_2013: Gross (US and international combined) in 2013 inflation adjusted dollars.\nroi: Return on investment, calculated as the ratio of the gross to budget.\nclean_test: Bechdel test result:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don‚Äôt talk to each other\nnowomen = fewer than two women\n\nbinary: Bechdel Test PASS vs FAIL binary\n\nWe will also use the year of release in data prep and title of movie to take a deeper look at some outliers.\nThere are a few other variables in the dataset, but we won‚Äôt be using them in this analysis."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#visualizing-data-with-ggplot2",
    "href": "ae/ae-02-bechdel-dataviz.html#visualizing-data-with-ggplot2",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Visualizing data with ggplot2",
    "text": "Visualizing data with ggplot2\nggplot2 is the package and ggplot() is the function in this package that is used to create a plot.\n\nggplot() creates the initial base coordinate system, and we will add layers to that base. We first specify the data set we will use with data = bechdel.\n\n\nggplot(data = bechdel)\n\n\n\n\n\n\n\n\n\nThe mapping argument is paired with an aesthetic (aes()), which tells us how the variables in our data set should be mapped to the visual properties of the graph.\n\n\nggplot(\n  data = bechdel, \n  mapping = aes(x = budget_2013, y = gross_2013)\n)\n\n\n\n\n\n\n\n\nAs we previously mentioned, we often omit the names of the first two arguments in R functions. So you‚Äôll often see this written as:\n\nggplot(bechdel, aes(x = budget_2013, y = gross_2013))\n\n\n\n\n\n\n\n\nNote that the result is exactly the same.\n\nThe geom_xx function specifies the type of plot we want to use to represent the data. In the code below, we use geom_point which creates a plot where each observation is represented by a point.\n\n\nggplot(bechdel, aes(x = budget_2013, y = gross_2013)) +\n  geom_point()\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nNote that this results in a warning as well. What does the warning mean?"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#gross-revenue-vs.-budget",
    "href": "ae/ae-02-bechdel-dataviz.html#gross-revenue-vs.-budget",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Gross revenue vs.¬†budget",
    "text": "Gross revenue vs.¬†budget\n\nStep 1 - Your turn\nModify the following plot to change the color of all points to a different color.\n\n\n\n\n\n\nTip\n\n\n\nSee http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf for many color options you can use by name in R or use the hex code for a color of your choice.\n\n\n\nggplot(bechdel, aes(x = budget_2013, y = gross_2013)) +\n  geom_point(color = \"deepskyblue3\") \n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nStep 2 - Your turn\nAdd labels for the title and x and y axes.\n\nggplot(bechdel, aes(x = budget_2013, y = gross_2013))+\n  geom_point(color = \"deepskyblue3\") + \n  labs(\n    x = \"___\", \n    y = \"___\", \n    title = \"___\"\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nStep 3 - Your turn\nAn aesthetic is a visual property of one of the objects in your plot. Commonly used aesthetic options are:\n\ncolor\nfill\nshape\nsize\nalpha (transparency)\n\nModify the plot below, so the color of the points is based on the variable binary.\n\nggplot(bechdel, aes(x = budget_2013, y = gross_2013)) +\n  geom_point() + \n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by ___\"\n  )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nStep 4 - Your turn\nExpand on your plot from the previous step to make the size of your points based on roi.\n\n# add code here\n\n\n\nStep 5 - Your turn\nExpand on your plot from the previous step to make the transparency (alpha) of the points 0.5.\n\n# add code here\n\n\n\nStep 6 - Your turn\nExpand on your plot from the previous step by using facet_wrap to display the association between budget and gross for different values of clean_test.\n\n# add code here\n\n\n\nStep 7 - Demo\nImprove your plot from the previous step by making the x and y scales more legible.\n\n\n\n\n\n\nTip\n\n\n\nMake use of the scales package, specifically the scale_x_continuous() and scale_y_continuous() functions.\n\n\n\n# add code here\n\n\n\nStep 8 - Your turn\nExpand on your plot from the previous step by using facet_grid to display the association between budget and gross for different combinations of clean_test and binary. Comment on whether this was a useful update.\n\n# add code here\n\nAdd comment here‚Ä¶\n\n\nStep 9 - Demo\nWhat other improvements could we make to this plot?\n\n# add code here\n\n\n\nRender, commit, and push\n\nIf you made any changes since the last render, render again to get the final version of the AE.\nCheck the box next to each document in the Git tab (this is called ‚Äústaging‚Äù the changes). Commit the changes you made using a simple and informative message.\nUse the green arrow to push your changes to your repo on GitHub.\nCheck your repo on GitHub and see the updated files. Once your updated files are in your repo on GitHub, you‚Äôre good to go!"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#return-on-investment",
    "href": "ae/ae-02-bechdel-dataviz.html#return-on-investment",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Return-on-investment",
    "text": "Return-on-investment\nFinally, let‚Äôs take a look at return-on-investment (ROI).\n\nStep 1 - Your turn\nCreate side-by-side box plots of roi by clean_test where the boxes are colored by binary.\n\n# add code here\n\nWhat are those movies with very high returns on investment?\n\nbechdel |&gt;\n  filter(roi &gt; 400) |&gt;\n  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n# A tibble: 3 √ó 6\n  title                     roi budget_2013 gross_2013  year clean_test\n  &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Paranormal Activity      671.      505595  339424558  2007 dubious   \n2 The Blair Witch Project  648.      839077  543776715  1999 ok        \n3 El Mariachi              583.       11622    6778946  1992 nowomen   \n\n\n\n\nStep 2 - Demo\nExpand on your plot from the previous step to zoom in on movies with roi &lt; ___ to get a better view of how the medians across the categories compare.\n\n# add code here\n\nWhat does this plot say about return-on-investment on movies that pass the Bechdel test?\n\n\nRender, commit, and push\n\nIf you made any changes since the last render, render again to get the final version of the AE.\nCheck the box next to each document in the Git tab (this is called ‚Äústaging‚Äù the changes). Commit the changes you made using a simple and informative message.\nUse the green arrow to push your changes to your repo on GitHub.\nCheck your repo on GitHub and see the updated files. Once your updated files are in your repo on GitHub, you‚Äôre good to go!"
  },
  {
    "objectID": "ae/ae-14-spam-filter-A.html",
    "href": "ae/ae-14-spam-filter-A.html",
    "title": "Building a spam filter",
    "section": "",
    "text": "In this application exercise, we will\nTo illustrate logistic regression, we will build a spam filter from email data.\nThe data come from incoming emails in David Diez‚Äôs (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012. All personally identifiable information has been removed.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nglimpse(email)\n\nRows: 3,921\nColumns: 21\n$ spam         &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ to_multiple  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ from         &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n$ cc           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, ‚Ä¶\n$ sent_email   &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, ‚Ä¶\n$ time         &lt;dttm&gt; 2012-01-01 01:16:41, 2012-01-01 02:03:59, 2012-01-01 11:‚Ä¶\n$ image        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ attach       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ dollar       &lt;dbl&gt; 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, ‚Ä¶\n$ winner       &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, n‚Ä¶\n$ inherit      &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ viagra       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ password     &lt;dbl&gt; 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ‚Ä¶\n$ num_char     &lt;dbl&gt; 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.837, 7.421‚Ä¶\n$ line_breaks  &lt;int&gt; 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 25, 79, 191‚Ä¶\n$ format       &lt;fct&gt; 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, ‚Ä¶\n$ re_subj      &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, ‚Ä¶\n$ exclaim_subj &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ‚Ä¶\n$ urgent_subj  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ exclaim_mess &lt;dbl&gt; 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0‚Ä¶\n$ number       &lt;fct&gt; big, small, small, small, none, none, big, small, small, ‚Ä¶\nThe variables we‚Äôll use in this analysis are\nGoal: Use the number of exclamation points in an email to predict whether or not it is spam."
  },
  {
    "objectID": "ae/ae-14-spam-filter-A.html#exercise-1",
    "href": "ae/ae-14-spam-filter-A.html#exercise-1",
    "title": "Building a spam filter",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nDemo: Fit the logistic regression model using the number of exclamation points to predict the probability an email is spam.\n\n\nlog_fit &lt;- logistic_reg() |&gt;\n  fit(spam ~ exclaim_mess, data = email)\n\ntidy(log_fit)\n\n# A tibble: 2 √ó 5\n  term          estimate std.error statistic p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  -2.27      0.0553     -41.1     0    \n2 exclaim_mess  0.000272  0.000949     0.287   0.774\n\n\n\nYour turn: How does the code above differ from previous code we‚Äôve used to fit regression models? Compare your summary output to the estimated model below.\n\n\\[\\log\\Big(\\frac{p}{1-p}\\Big) = -2.27 - 0.000272 \\times exclaim\\_mess\\]\nWe use logistic instead of linear regression."
  },
  {
    "objectID": "ae/ae-14-spam-filter-A.html#exercise-2",
    "href": "ae/ae-14-spam-filter-A.html#exercise-2",
    "title": "Building a spam filter",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhat is the probability the email is spam if it contains 10 exclamation points? Answer the question using the predict() function.\nWe can use the predict function in R to produce the probability as well.\n\nep_10 &lt;- tibble(exclaim_mess = 10)\npredict(log_fit, ep_10, type = \"prob\")\n\n# A tibble: 1 √ó 2\n  .pred_0 .pred_1\n    &lt;dbl&gt;   &lt;dbl&gt;\n1   0.906  0.0937"
  },
  {
    "objectID": "ae/ae-14-spam-filter-A.html#exercise-3",
    "href": "ae/ae-14-spam-filter-A.html#exercise-3",
    "title": "Building a spam filter",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe have the probability an email is spam, but ultimately we want to use the probability to classify an email as spam or not spam. Therefore, we need to set a decision-making threshold, such that an email is classified as spam if the predicted probability is greater than the threshold and not spam otherwise.\nSuppose you are a data scientist working on a spam filter. You must determine how high the predicted probability must be before you think it would be reasonable to call it spam and put it in the junk folder (which the user is unlikely to check).\nYour turn: What are some trade offs you would consider as you set the decision-making threshold? Discuss with your neighbor.\nAnswers will vary.\n\naugment(log_fit, email) |&gt;\n  select(spam, exclaim_mess, .pred_class) |&gt;\n  ggplot(aes(x = exclaim_mess, y = spam, color = .pred_class)) +\n  geom_jitter(alpha = 0.5)"
  },
  {
    "objectID": "ae/ae-14-spam-filter-A.html#exercise-4",
    "href": "ae/ae-14-spam-filter-A.html#exercise-4",
    "title": "Building a spam filter",
    "section": "Exercise 4",
    "text": "Exercise 4\nFit a model with all variables in the dataset as predictors and recreate the visualization above for this model.\n\nlog_fit2 &lt;- logistic_reg() |&gt;\n  fit(spam ~ ., data = email)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nlog_aug2 &lt;- augment(log_fit2, email)\n\nggplot(log_aug2, aes(x = exclaim_mess, y = spam, color = .pred_class)) +\n  geom_jitter(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nlog_aug2 |&gt;\n  count(spam, .pred_class) |&gt;\n  group_by(spam) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 4 √ó 4\n# Groups:   spam [2]\n  spam  .pred_class     n       p\n  &lt;fct&gt; &lt;fct&gt;       &lt;int&gt;   &lt;dbl&gt;\n1 0     0            3521 0.991  \n2 0     1              33 0.00929\n3 1     0             299 0.815  \n4 1     1              68 0.185"
  },
  {
    "objectID": "ae/ae-08-data-import.html",
    "href": "ae/ae-08-data-import.html",
    "title": "AE 08: Data import",
    "section": "",
    "text": "We will use the following two packages in this application exercise.\n\ntidyverse: For data import, wrangling, and visualization.\nreadxl: For importing data from Excel.\n\n\nlibrary(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "ae/ae-08-data-import.html#packages",
    "href": "ae/ae-08-data-import.html#packages",
    "title": "AE 08: Data import",
    "section": "",
    "text": "We will use the following two packages in this application exercise.\n\ntidyverse: For data import, wrangling, and visualization.\nreadxl: For importing data from Excel.\n\n\nlibrary(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "ae/ae-12-modeling-penguins-multi-A.html",
    "href": "ae/ae-12-modeling-penguins-multi-A.html",
    "title": "AE 12: Modeling penguins with multiple predictors",
    "section": "",
    "text": "In this application exercise we will be studying penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\nPlease read the following context and take a glimpse at the data set before we get started.\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\nOur goal is to understand better how various body measurements and attributes of penguins relate to their body mass."
  },
  {
    "objectID": "ae/ae-12-modeling-penguins-multi-A.html#additive-vs.-interaction-models",
    "href": "ae/ae-12-modeling-penguins-multi-A.html#additive-vs.-interaction-models",
    "title": "AE 12: Modeling penguins with multiple predictors",
    "section": "Additive vs.¬†interaction models",
    "text": "Additive vs.¬†interaction models\n\nYour turn: Run the two chunks of code below and create two separate plots. How are the two plots different than each other? Which plot does the model we fit above represent?\n\n# Plot A\nggplot(\n  penguins, \n  aes(x = flipper_length_mm, y = body_mass_g, color = island)\n  ) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Plot A - Interaction model\") +\n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n# Plot B\nbm_fl_island_aug &lt;- augment(bm_fl_island_fit, new_data = penguins)\nggplot(\n  bm_fl_island_aug, \n  aes(x = flipper_length_mm, y = body_mass_g, color = island)\n  ) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(aes(y = .pred), method = \"lm\") +\n  labs(title = \"Plot B - Additive model\") +\n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\nRemoved 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nPlot B represent the model we fit.\n\nYour turn: Interpret the slope coefficient for flipper length in the context of the data and the research question.\n\nFor every 1 millimeter the flipper is longer, we expect body mass to be higher, on average, by 44.5 grams, holding all else (the island) constant. In other words, this is true for penguins in a given island, regardless of the island.\n\nDemo: Predict the body mass of a Dream island penguin with a flipper length of 200 mm.\n\n\npenguin_200_Dream &lt;- tibble(\n  flipper_length_mm = 200,\n  island = \"Dream\"\n)\n\npredict(bm_fl_island_fit, new_data = penguin_200_Dream)\n\n# A tibble: 1 √ó 1\n  .pred\n  &lt;dbl&gt;\n1 4021.\n\n\n\nReview: Look back at Plot B. What assumption does the additive model make about the slopes between flipper length and body mass for each of the three islands?\n\nThe additive model assumes the same slope between body mass and flipper length for all three islands.\n\nDemo: Now fit the interaction model represented in Plot A and write the estimated regression model.\n\n\nbm_fl_island_int_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ flipper_length_mm * island, data = penguins)\n\ntidy(bm_fl_island_int_fit)\n\n# A tibble: 6 √ó 5\n  term                              estimate std.error statistic  p.value\n  &lt;chr&gt;                                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                        -5464.     431.      -12.7  2.51e-30\n2 flipper_length_mm                     48.5      2.05     23.7  1.66e-73\n3 islandDream                         3551.     969.        3.66 2.89e- 4\n4 islandTorgersen                     3218.    1680.        1.92 5.62e- 2\n5 flipper_length_mm:islandDream        -19.4      4.94     -3.93 1.03e- 4\n6 flipper_length_mm:islandTorgersen    -17.4      8.73     -1.99 4.69e- 2\n\n\n\\[\n\\widehat{body~mass} = -5464 \\\\\n+ 48.5 \\times flipper~length \\\\\n+ 3551 \\times Dream + 3218 \\times Torgersen \\\\\n- 19.4 \\times flipper~length*Dream - 17.4 \\times flipper~length*Torgersen\n\\]\n\nReview: What does modeling body mass with an interaction effect get us that without doing so does not?\n\nThe interaction effect allows us to model the rate of change in estimated body mass as flipper length increases as different in the three islands.\n\nYour turn: Predict the body mass of a Dream island penguin with a flipper length of 200 mm.\n\n\npredict(bm_fl_island_int_fit, new_data = penguin_200_Dream)\n\n# A tibble: 1 √ó 1\n  .pred\n  &lt;dbl&gt;\n1 3915."
  },
  {
    "objectID": "ae/ae-12-modeling-penguins-multi-A.html#choosing-a-model",
    "href": "ae/ae-12-modeling-penguins-multi-A.html#choosing-a-model",
    "title": "AE 12: Modeling penguins with multiple predictors",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam‚Äôs Razor - Don‚Äôt overcomplicate the situation! We prefer the simplest best model.\n\nglance(bm_fl_island_fit)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.774         0.772  383.      386. 7.60e-109     3 -2517. 5045. 5064.\n# ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nglance(bm_fl_island_int_fit)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.786         0.783  374.      246. 4.55e-110     5 -2508. 5031. 5057.\n# ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables)."
  },
  {
    "objectID": "ae/ae-05-majors-tidying-A.html",
    "href": "ae/ae-05-majors-tidying-A.html",
    "title": "AE 05: Tidying StatSci Majors",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it‚Äôs not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-05-majors-tidying-A.html#goal",
    "href": "ae/ae-05-majors-tidying-A.html#goal",
    "title": "AE 05: Tidying StatSci Majors",
    "section": "Goal",
    "text": "Goal\nOur ultimate goal in this application exercise is to make the following data visualization."
  },
  {
    "objectID": "ae/ae-05-majors-tidying-A.html#data",
    "href": "ae/ae-05-majors-tidying-A.html#data",
    "title": "AE 05: Tidying StatSci Majors",
    "section": "Data",
    "text": "Data\nThe data come from the Office of the University Registrar. They make the data available as a table that you can download as a PDF, but I‚Äôve put the data exported in a CSV file for you. Let‚Äôs load that in.\n\nlibrary(tidyverse)\n\nstatsci &lt;- read_csv(\"https://sta199-s24.github.io/data/statsci.csv\")\n\nAnd let‚Äôs take a look at the data.\n\nstatsci\n\n# A tibble: 4 √ó 14\n  degree   `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019` `2020`\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Statist‚Ä¶     NA      1     NA     NA      4      4      1     NA     NA      1\n2 Statist‚Ä¶      2      2      4      1      3      6      3      4      4      1\n3 Statist‚Ä¶      2      6      1     NA      5      6      6      8      8     17\n4 Statist‚Ä¶      5      9      4     13     10     17     24     21     26     27\n# ‚Ñπ 3 more variables: `2021` &lt;dbl&gt;, `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt;"
  },
  {
    "objectID": "ae/ae-05-majors-tidying-A.html#pivoting",
    "href": "ae/ae-05-majors-tidying-A.html#pivoting",
    "title": "AE 05: Tidying StatSci Majors",
    "section": "Pivoting",
    "text": "Pivoting\n\nDemo: Pivot the statsci data frame longer such that each row represents a degree type / year combination and year and number of graduates for that year are columns in the data frame.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    values_to = \"n\"\n  )\n\n# A tibble: 52 √ó 3\n   degree                    year      n\n   &lt;chr&gt;                     &lt;chr&gt; &lt;dbl&gt;\n 1 Statistical Science (AB2) 2011     NA\n 2 Statistical Science (AB2) 2012      1\n 3 Statistical Science (AB2) 2013     NA\n 4 Statistical Science (AB2) 2014     NA\n 5 Statistical Science (AB2) 2015      4\n 6 Statistical Science (AB2) 2016      4\n 7 Statistical Science (AB2) 2017      1\n 8 Statistical Science (AB2) 2018     NA\n 9 Statistical Science (AB2) 2019     NA\n10 Statistical Science (AB2) 2020      1\n# ‚Ñπ 42 more rows\n\n\n\nQuestion: What is the type of the year variable? Why? What should it be?\n\nIt‚Äôs a character (chr) variable since the information came from the columns of the original data frame and R cannot know that these character strings represent years. The variable type should be numeric.\n\nDemo: Start over with pivoting, and this time also make sure year is a numerical variable in the resulting data frame.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  )\n\n# A tibble: 52 √ó 3\n   degree                     year     n\n   &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science (AB2)  2011    NA\n 2 Statistical Science (AB2)  2012     1\n 3 Statistical Science (AB2)  2013    NA\n 4 Statistical Science (AB2)  2014    NA\n 5 Statistical Science (AB2)  2015     4\n 6 Statistical Science (AB2)  2016     4\n 7 Statistical Science (AB2)  2017     1\n 8 Statistical Science (AB2)  2018    NA\n 9 Statistical Science (AB2)  2019    NA\n10 Statistical Science (AB2)  2020     1\n# ‚Ñπ 42 more rows\n\n\n\nQuestion: What does an NA mean in this context? Hint: The data come from the university registrar, and they have records on every single graduates, there shouldn‚Äôt be anything ‚Äúunknown‚Äù to them about who graduated when.\n\nNAs should actually be 0s.\n\nDemo: Add on to your pipeline that you started with pivoting and convert NAs in n to 0s.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n))\n\n# A tibble: 52 √ó 3\n   degree                     year     n\n   &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science (AB2)  2011     0\n 2 Statistical Science (AB2)  2012     1\n 3 Statistical Science (AB2)  2013     0\n 4 Statistical Science (AB2)  2014     0\n 5 Statistical Science (AB2)  2015     4\n 6 Statistical Science (AB2)  2016     4\n 7 Statistical Science (AB2)  2017     1\n 8 Statistical Science (AB2)  2018     0\n 9 Statistical Science (AB2)  2019     0\n10 Statistical Science (AB2)  2020     1\n# ‚Ñπ 42 more rows\n\n\n\nDemo: In our plot the degree types are BS, BS2, AB, and AB2. This information is in our dataset, in the degree column, but this column also has additional characters we don‚Äôt need. Create a new column called degree_type with levels BS, BS2, AB, and AB2 (in this order) based on degree. Do this by adding on to your pipeline from earlier.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    )\n\n# A tibble: 52 √ó 4\n   major               degree_type  year     n\n   &lt;chr&gt;               &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science AB2          2011     0\n 2 Statistical Science AB2          2012     1\n 3 Statistical Science AB2          2013     0\n 4 Statistical Science AB2          2014     0\n 5 Statistical Science AB2          2015     4\n 6 Statistical Science AB2          2016     4\n 7 Statistical Science AB2          2017     1\n 8 Statistical Science AB2          2018     0\n 9 Statistical Science AB2          2019     0\n10 Statistical Science AB2          2020     1\n# ‚Ñπ 42 more rows\n\n\n\nYour turn (5 minutes): Now we start making our plot, but let‚Äôs not get too fancy right away. Create the following plot, which will serve as the ‚Äúfirst draft‚Äù on the way to our Goal. Do this by adding on to your pipeline from earlier.\n\n\n\n\n\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |&gt;\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\n\n\nYour turn (4 minutes): What aspects of the plot need to be updated to go from the draft you created above to the Goal plot at the beginning of this application exercise.\n\nx-axis scale: need to go from 2011 to 2023 in increments of 2 years\nline colors\naxis labels: title, subtitle, x, y, caption\ntheme\nlegend position and border\n\nDemo: Update x-axis scale such that the years displayed go from 2011 to 2023 in increments of 2 years. Do this by adding on to your pipeline from earlier.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |&gt;\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2023, 2))\n\n\n\n\n\n\n\n\n\nDemo: Update line colors using the following level / color assignments. Once again, do this by adding on to your pipeline from earlier.\n\n‚ÄúBS‚Äù = ‚Äúcadetblue4‚Äù\n‚ÄúBS2‚Äù = ‚Äúcadetblue3‚Äù\n‚ÄúAB‚Äù = ‚Äúlightgoldenrod4‚Äù\n‚ÄúAB2‚Äù = ‚Äúlightgoldenrod3‚Äù\n\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |&gt;\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2023, 2)) +\n  scale_color_manual(\n    values = c(\"BS\" = \"cadetblue4\", \n               \"BS2\" = \"cadetblue3\", \n               \"AB\" = \"lightgoldenrod4\", \n               \"AB2\" = \"lightgoldenrod3\"))\n\n\n\n\n\n\n\n\n\nYour turn (4 minutes): Update the plot labels (title, subtitle, x, y, and caption) and use theme_minimal(). Once again, do this by adding on to your pipeline from earlier.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |&gt;\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2023, 2)) +\n  scale_color_manual(\n    values = c(\"BS\" = \"cadetblue4\",\n               \"BS2\" = \"cadetblue3\",\n               \"AB\" = \"lightgoldenrod4\",\n               \"AB2\" = \"lightgoldenrod3\")) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2023\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nDemo: Finally, adding to your pipeline you‚Äôve developed so far, move the legend into the plot, make its background white, and its border gray. Set fig-width: 7 and fig-height: 5 for your plot in the chunk options.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |&gt;\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2023, 2)) +\n  scale_color_manual(\n    values = c(\"BS\" = \"cadetblue4\",\n               \"BS2\" = \"cadetblue3\",\n               \"AB\" = \"lightgoldenrod4\",\n               \"AB2\" = \"lightgoldenrod3\")) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2023\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = c(0.2, 0.8),\n    legend.background = element_rect(fill = \"white\", color = \"gray\")\n    )"
  },
  {
    "objectID": "ae/ae-11-modeling-penguins.html",
    "href": "ae/ae-11-modeling-penguins.html",
    "title": "AE 11: Modelling penguins",
    "section": "",
    "text": "In this application exercise we will be studying penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\n\nPlease read the following context and take a glimpse at the data set before we get started.\n\nThis data set comprising various measurements of three different penguin species, namely Adelie, Gentoo, and Chinstrap. The rigorous study was conducted in the islands of the Palmer Archipelago, Antarctica. These data were collected from 2007 to 2009 by Dr.¬†Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data set is called penguins.\n\n\n# add code here\n\nOur goal is to understand better how various body measurements and attributes of penguins relate to their body mass. First, we are going to investigate the relationship between a penguins‚Äô flipper lengths and their body masses.\n\nQuestion: Based on our research focus, which variable is the response variable?\n\nAdd response here\n\nDemo: Visualize the relationship between flipper length and body mass of penguins.\n\n\n# add code here \n\n\nCorrelation\n\nYour turn (5 minutes):\n\nWhat is correlation? What values can correlation take?\nStrength and direction of a linear relationship. It‚Äôs bounded by -1 and 1.\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\n\nDemo: What is the correlation between flipper length and body mass of penguins?\n\n\n# add code here\n\n\n\nDefining, fitting, and summarizing a model\n\nDemo: Write the population model below that explains the relationship between body mass and flipper length.\n\n\\[\nadd~math~text~here\n\\]\n\nDemo: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\n# add code here\n\n\\[\nadd~math~text~here\n\\]\n\nYour turn: Interpret the slope and the intercept in the context of the data.\n\nIntercept: Add your response here\nSlopes: Add your response here\n\nYour turn: Recreate the visualization from above, this time adding a regression line to the visualization geom_smooth(method = \"lm\").\n\n\n# add code here\n\n\nWhat is the estimated body mass for a penguin with a flipper length of 210?\n\n\n# add code here\n\n\nWhat is the estimated body mass for a penguin with a flipper length of 100?\n\n\n# add code here\n\n\n\nAnother model\n\nDemo: A different researcher wants to look at body weight of penguins based on the island they were recorded on. How are the variables involved in this analysis different?\n\nAdd response here\n\nDemo: Make an appropriate visualization to investigate this relationship below. Additionally, calculate the mean body mass by island.\n\n\n# add code here\n\n\n# add code here\n\n\nDemo: Change the geom of your previous plot to geom_point(). Use this plot to think about how R models these data.\n\n\n# add code here\n\n\nYour turn: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\n# add code here\n\nAdd math text here\n\nDemo: Interpret each coefficient in context of the problem.\n\nIntercept: Add your response here\nSlopes: Add your response here\n\nDemo: What is the estimated body weight of a penguin on Biscoe island? What are the estimated body weights of penguins on Dream and Torgersen islands?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-14-spam-filter.html",
    "href": "ae/ae-14-spam-filter.html",
    "title": "Building a spam filter",
    "section": "",
    "text": "In this application exercise, we will\nTo illustrate logistic regression, we will build a spam filter from email data.\nThe data come from incoming emails in David Diez‚Äôs (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012. All personally identifiable information has been removed.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nglimpse(email)\n\nRows: 3,921\nColumns: 21\n$ spam         &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ to_multiple  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ from         &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n$ cc           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, ‚Ä¶\n$ sent_email   &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, ‚Ä¶\n$ time         &lt;dttm&gt; 2012-01-01 01:16:41, 2012-01-01 02:03:59, 2012-01-01 11:‚Ä¶\n$ image        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ attach       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ dollar       &lt;dbl&gt; 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, ‚Ä¶\n$ winner       &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, n‚Ä¶\n$ inherit      &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ viagra       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ password     &lt;dbl&gt; 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ‚Ä¶\n$ num_char     &lt;dbl&gt; 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.837, 7.421‚Ä¶\n$ line_breaks  &lt;int&gt; 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 25, 79, 191‚Ä¶\n$ format       &lt;fct&gt; 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, ‚Ä¶\n$ re_subj      &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, ‚Ä¶\n$ exclaim_subj &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ‚Ä¶\n$ urgent_subj  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ exclaim_mess &lt;dbl&gt; 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0‚Ä¶\n$ number       &lt;fct&gt; big, small, small, small, none, none, big, small, small, ‚Ä¶\nThe variables we‚Äôll use in this analysis are\nGoal: Use the number of exclamation points in an email to predict whether or not it is spam."
  },
  {
    "objectID": "ae/ae-14-spam-filter.html#exercise-1",
    "href": "ae/ae-14-spam-filter.html#exercise-1",
    "title": "Building a spam filter",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nDemo: Fit the logistic regression model using the number of exclamation points to predict the probability an email is spam.\n\n\nlog_fit &lt;- logistic_reg() |&gt;\n  fit(spam ~ exclaim_mess, data = email)\n\ntidy(log_fit)\n\n# A tibble: 2 √ó 5\n  term          estimate std.error statistic p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  -2.27      0.0553     -41.1     0    \n2 exclaim_mess  0.000272  0.000949     0.287   0.774\n\n\n\nYour turn: How does the code above differ from previous code we‚Äôve used to fit regression models? Compare your summary output to the estimated model below.\n\n\\[\\log\\Big(\\frac{p}{1-p}\\Big) = -2.27 - 0.000272 \\times exclaim\\_mess\\]\nAdd response here."
  },
  {
    "objectID": "ae/ae-14-spam-filter.html#exercise-2",
    "href": "ae/ae-14-spam-filter.html#exercise-2",
    "title": "Building a spam filter",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhat is the probability the email is spam if it contains 10 exclamation points? Answer the question using the predict() function.\nWe can use the predict function in R to produce the probability as well.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-14-spam-filter.html#exercise-3",
    "href": "ae/ae-14-spam-filter.html#exercise-3",
    "title": "Building a spam filter",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe have the probability an email is spam, but ultimately we want to use the probability to classify an email as spam or not spam. Therefore, we need to set a decision-making threshold, such that an email is classified as spam if the predicted probability is greater than the threshold and not spam otherwise.\nSuppose you are a data scientist working on a spam filter. You must determine how high the predicted probability must be before you think it would be reasonable to call it spam and put it in the junk folder (which the user is unlikely to check).\nYour turn: What are some trade offs you would consider as you set the decision-making threshold? Discuss with your neighbor.\nAdd response here.\n\nlog_aug &lt;- augment(log_fit, email)\n\nggplot(log_aug, aes(x = exclaim_mess, y = spam, color = .pred_class)) +\n  geom_jitter(alpha = 0.5)"
  },
  {
    "objectID": "ae/ae-14-spam-filter.html#exercise-4",
    "href": "ae/ae-14-spam-filter.html#exercise-4",
    "title": "Building a spam filter",
    "section": "Exercise 4",
    "text": "Exercise 4\nFit a model with all variables in the dataset as predictors and receate the visualization above for this model.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-11-modeling-penguins-A.html",
    "href": "ae/ae-11-modeling-penguins-A.html",
    "title": "AE 11: Modelling penguins",
    "section": "",
    "text": "In this application exercise we will be studying penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\n\nPlease read the following context and take a glimpse at the data set before we get started.\n\nThis data set comprising various measurements of three different penguin species, namely Adelie, Gentoo, and Chinstrap. The rigorous study was conducted in the islands of the Palmer Archipelago, Antarctica. These data were collected from 2007 to 2009 by Dr.¬†Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data set is called penguins.\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nOur goal is to understand better how various body measurements and attributes of penguins relate to their body mass. First, we are going to investigate the relationship between a penguins‚Äô flipper lengths and their body masses.\n\nQuestion: Based on our research focus, which variable is the response variable?\n\nBody mass.\n\nDemo: Visualize the relationship between flipper length and body mass of penguins.\n\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nCorrelation\n\nYour turn (5 minutes):\n\nWhat is correlation? What values can correlation take?\nStrength and direction of a linear relationship. It‚Äôs bounded by -1 and 1.\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\n\nDemo: What is the correlation between flipper length and body mass of penguins?\n\n\n# option 1\npenguins |&gt;\n  summarize(r = cor(flipper_length_mm, body_mass_g, use = \"complete.obs\"))\n\n# A tibble: 1 √ó 1\n      r\n  &lt;dbl&gt;\n1 0.871\n\n# option 2\npenguins |&gt;\n  drop_na(flipper_length_mm, body_mass_g) |&gt;\n  summarize(r = cor(flipper_length_mm, body_mass_g))\n\n# A tibble: 1 √ó 1\n      r\n  &lt;dbl&gt;\n1 0.871\n\n\n\n\nDefining, fitting, and summarizing a model\n\nDemo: Write the population model below that explains the relationship between body mass and flipper length.\n\n\\[\nbody~mass = \\beta_0 + \\beta_1 \\times flipper~length + \\epsilon\n\\]\n\nDemo: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\nbm_fl_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\ntidy(bm_fl_fit)\n\n# A tibble: 2 √ó 5\n  term              estimate std.error statistic   p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        -5781.     306.       -18.9 5.59e- 55\n2 flipper_length_mm     49.7      1.52      32.7 4.37e-107\n\n\n\\[\n\\widehat{body~mass} = -5781 + 49.7 \\times flipper~length\n\\]\n\nYour turn: Interpret the slope and the intercept in the context of the data.\n\nIntercept: Penguins with 0 flipper length are expected, on average, to weigh 5,781 grams.\nSlopes: For each additional millimeter of a penguin;s flipper length, the weight of their penguin is expected to be higher, on average, by 49.7 grams.\n\nYour turn: Recreate the visualization from above, this time adding a regression line to the visualization geom_smooth(method = \"lm\").\n\n\nggplot(penguins,\n       aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nYour turn: What is the estimated body mass for a penguin with a flipper length of 210?\n\n\nbm_fl_fit |&gt;\n  predict(new_data = tibble(flipper_length_mm = 210))\n\n# A tibble: 1 √ó 1\n  .pred\n  &lt;dbl&gt;\n1 4653.\n\n\n\nDemo: What is the estimated body mass for a penguin with a flipper length of 100?\n\nBut we shouldn‚Äôt do this prediction based on this model since 100 mm is outside of the range of the data (extrapolation).\n\nbm_fl_fit |&gt;\n  predict(new_data = tibble(flipper_length_mm = 100))\n\n# A tibble: 1 √ó 1\n  .pred\n  &lt;dbl&gt;\n1 -812.\n\n\n\n\nAnother model\n\nDemo: A different researcher wants to look at body weight of penguins based on the island they were recorded on. How are the variables involved in this analysis different?\n\nPredictor is categorical.\n\nDemo: Make an appropriate visualization to investigate this relationship below. Additionally, calculate the mean body mass by island.\n\n\nggplot(penguins, aes(x = island, y = body_mass_g)) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\npenguins |&gt;\n  group_by(island) |&gt;\n  summarize(mean_bm = mean(body_mass_g, na.rm = TRUE))\n\n# A tibble: 3 √ó 2\n  island    mean_bm\n  &lt;fct&gt;       &lt;dbl&gt;\n1 Biscoe      4716.\n2 Dream       3713.\n3 Torgersen   3706.\n\n\n\nDemo: Change the geom of your previous plot to geom_point(). Use this plot to think about how R models these data.\n\n\nggplot(penguins, aes(x = island, y = body_mass_g)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nYour turn: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\nbm_island_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ island, data = penguins)\n\ntidy(bm_island_fit)\n\n# A tibble: 3 √ó 5\n  term            estimate std.error statistic   p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        4716.      48.5      97.3 8.93e-250\n2 islandDream       -1003.      74.2     -13.5 1.42e- 33\n3 islandTorgersen   -1010.     100.      -10.1 4.66e- 21\n\n\n\nDemo: Interpret each coefficient in context of the problem.\n\nIntercept: Penguins from Biscoe island are expected to weigh, on average, 4,716 grams.\nSlopes:\n\nPenguins from Dream island are expected to weigh, on average, 1,003 grams less than those from Biscoe island.\nPenguins from Torgersen island are expected to weigh, on average, 1,010 grams less than those from Biscoe island.\n\n\nDemo: What is the estimated body weight of a penguin on Biscoe island? What are the estimated body weights of penguins on Dream and Torgersen islands?\n\n\nbm_island_fit |&gt;\n  predict(new_data = tibble(island = c(\"Biscoe\", \"Dream\", \"Torgersen\")))\n\n# A tibble: 3 √ó 1\n  .pred\n  &lt;dbl&gt;\n1 4716.\n2 3713.\n3 3706."
  },
  {
    "objectID": "ae/ae-06-population-joining.html",
    "href": "ae/ae-06-population-joining.html",
    "title": "AE 06: Joining country populations with continents",
    "section": "",
    "text": "Our ultimate goal in this application exercise is to create a bar plot of total populations of continents, where the input data are:\n\nCountries and populations\nCountries and continents\n\n\nlibrary(tidyverse) # for data wrangling and visualization\nlibrary(scales)    # for pretty axis breaks"
  },
  {
    "objectID": "ae/ae-06-population-joining.html#goal",
    "href": "ae/ae-06-population-joining.html#goal",
    "title": "AE 06: Joining country populations with continents",
    "section": "",
    "text": "Our ultimate goal in this application exercise is to create a bar plot of total populations of continents, where the input data are:\n\nCountries and populations\nCountries and continents\n\n\nlibrary(tidyverse) # for data wrangling and visualization\nlibrary(scales)    # for pretty axis breaks"
  },
  {
    "objectID": "ae/ae-06-population-joining.html#data",
    "href": "ae/ae-06-population-joining.html#data",
    "title": "AE 06: Joining country populations with continents",
    "section": "Data",
    "text": "Data\n\nCountries and populations\nThese data come from The World Bank and reflect population counts as of 2022.\n\npopulation &lt;- read_csv(\"https://sta199-s24.github.io/data/world-pop-2022.csv\")\n\nLet‚Äôs take a look at the data.\n\npopulation\n\n# A tibble: 217 √ó 3\n   country              year population\n   &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;\n 1 Afghanistan          2022    41129. \n 2 Albania              2022     2778. \n 3 Algeria              2022    44903. \n 4 American Samoa       2022       44.3\n 5 Andorra              2022       79.8\n 6 Angola               2022    35589. \n 7 Antigua and Barbuda  2022       93.8\n 8 Argentina            2022    46235. \n 9 Armenia              2022     2780. \n10 Aruba                2022      106. \n# ‚Ñπ 207 more rows\n\n\n\n\nContinents\nThese data come from Our World in Data.\n\ncontinents &lt;- read_csv(\"https://sta199-s24.github.io/data/continents.csv\")\n\nLet‚Äôs take a look at the data.\n\ncontinents\n\n# A tibble: 285 √ó 4\n   entity                code      year continent    \n   &lt;chr&gt;                 &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;        \n 1 Abkhazia              OWID_ABK  2015 Asia         \n 2 Afghanistan           AFG       2015 Asia         \n 3 Akrotiri and Dhekelia OWID_AKD  2015 Asia         \n 4 Aland Islands         ALA       2015 Europe       \n 5 Albania               ALB       2015 Europe       \n 6 Algeria               DZA       2015 Africa       \n 7 American Samoa        ASM       2015 Oceania      \n 8 Andorra               AND       2015 Europe       \n 9 Angola                AGO       2015 Africa       \n10 Anguilla              AIA       2015 North America\n# ‚Ñπ 275 more rows"
  },
  {
    "objectID": "ae/ae-06-population-joining.html#exercises",
    "href": "ae/ae-06-population-joining.html#exercises",
    "title": "AE 06: Joining country populations with continents",
    "section": "Exercises",
    "text": "Exercises\n\nThink out loud:\n\nWhich variable(s) will we use to join the population and continents data frames?\n\nAdd response here.\n\nWe want to create a new data frame that keeps all rows and columns from population and brings in the corresponding information from continents. Which join function should we use?\n\nAdd response here.\nDemo: Join the two data frames and name assign the joined data frame to a new data frame population_continents.\n\n\n# add code here\n\n\nDemo: Take a look at the newly created population_continent data frame. There are some countries that were not in continents. First, identify which countries these are (they will have NA values for continent).\n\n\n# add code here\n\n\nDemo: All of these countries are actually in the continents data frame, but under different names. So, let‚Äôs clean that data first by updating the country names in the population data frame in a way they will match the continents data frame, and then joining them, using a case_when() statement in mutate(). At the end, check that all countries now have continent information.\n\n\n# add code here\n\n\nThink out loud: Which continent do you think has the highest population? Which do you think has the second highest? The lowest?\n\nAdd your response here.\n\nDemo: Create a new data frame called population_summary that contains a row for each continent and a column for the total population for that continent, in descending order of population. Note that the function for calculating totals in R is sum().\n\n\n# add code here\n\n\nYour turn: Make a bar plot with total population on the y-axis and continent on the x-axis, where the height of each bar represents the total population in that continent.\n\n\n# add code here\n\n\nYour turn: Recreate the following plot, which is commonly referred to as a lollipop plot. Hint: Start with the points, then try adding the segments, then add axis labels and caption, and finally, as a stretch goal, update the x scale (which will require a function we haven‚Äôt introduced in lectures or labs yet!).\n\n\n\n# add code here\n\n\nThink out loud: What additional improvements would you like to make to this plot.\n\nAdd your response here."
  },
  {
    "objectID": "ae/ae-09-chronicle-scrape-A.html",
    "href": "ae/ae-09-chronicle-scrape-A.html",
    "title": "AE 09: Opinion articles in The Chronicle",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it‚Äôs not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-09-chronicle-scrape-A.html#part-1---data-scraping",
    "href": "ae/ae-09-chronicle-scrape-A.html#part-1---data-scraping",
    "title": "AE 09: Opinion articles in The Chronicle",
    "section": "Part 1 - Data scraping",
    "text": "Part 1 - Data scraping\nSee chronicle-scrape.R for suggested scraping code."
  },
  {
    "objectID": "ae/ae-09-chronicle-scrape-A.html#part-2---data-analysis",
    "href": "ae/ae-09-chronicle-scrape-A.html#part-2---data-analysis",
    "title": "AE 09: Opinion articles in The Chronicle",
    "section": "Part 2 - Data analysis",
    "text": "Part 2 - Data analysis\nLet‚Äôs start by loading the packages we will need:\n\nlibrary(tidyverse)\n\n\nYour turn (1 minute): Load the data you saved into the data folder and name it chronicle.\n\n\nchronicle &lt;- read_csv(\"data/chronicle.csv\")\n\n\nYour turn (3 minutes): Who are the most prolific authors of the 100 most recent opinion articles in The Chronicle?\n\n\nchronicle |&gt;\n  count(author, sort = TRUE)\n\n# A tibble: 204 √ó 2\n   author                        n\n   &lt;chr&gt;                     &lt;int&gt;\n 1 Luke A. Powery               30\n 2 Heidi Smith                  27\n 3 Advikaa Anand                22\n 4 Monday Monday                17\n 5 Monika Narain                16\n 6 Community Editorial Board    12\n 7 Linda Cao                    12\n 8 Sonia Green                  12\n 9 Valerie Tan                  11\n10 Nathan Luzum                 10\n# ‚Ñπ 194 more rows\n\n\n\nDemo: Draw a line plot of the number of opinion articles published per day in The Chronicle.\n\n\nchronicle |&gt;\n  count(date) |&gt;\n  ggplot(aes(x = date, y = n, group = 1)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\nDemo: What percent of the most recent 100 opinion articles in The Chronicle mention ‚Äúclimate‚Äù in their title?\n\n\nchronicle |&gt;\n  mutate(\n    title = str_to_lower(title),\n    climate = if_else(str_detect(title, \"climate\"), \"mentioned\", \"not mentioned\")\n    ) |&gt;\n  count(climate) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 2 √ó 3\n  climate           n  prop\n  &lt;chr&gt;         &lt;int&gt; &lt;dbl&gt;\n1 mentioned        10  0.02\n2 not mentioned   490  0.98\n\n\n\nYour turn (5 minutes): What percent of the most recent 100 opinion articles in The Chronicle mention ‚Äúclimate‚Äù in their title or abstract?\n\n\nchronicle |&gt;\n  mutate(\n    title = str_to_lower(title),\n    abstract = str_to_lower(abstract),\n    climate = if_else(\n      str_detect(title, \"climate\") | str_detect(abstract, \"climate\"), \n      \"mentioned\", \n      \"not mentioned\"\n      )\n    ) |&gt;\n  count(climate) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 3 √ó 3\n  climate           n  prop\n  &lt;chr&gt;         &lt;int&gt; &lt;dbl&gt;\n1 mentioned        14 0.028\n2 not mentioned   482 0.964\n3 &lt;NA&gt;              4 0.008\n\n\n\nTime permitting: Come up with another question and try to answer it using the data.\n\n\n# add code here\n\n\nTime permitting:"
  },
  {
    "objectID": "ae/ae-01-meet-the-penguins.html",
    "href": "ae/ae-01-meet-the-penguins.html",
    "title": "AE 01: Meet the penguins",
    "section": "",
    "text": "For this application exercise, we‚Äôll use the tidyverse and palmerpenguins packages.\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.4.4     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\nThe dataset we will visualize is called penguins. Let‚Äôs glimpse() at it.\n\nYour turn: Replace #add code here with the code for ‚Äúglimpse‚Äùing at the data penguins data frame ‚Äì glimpse(penguins). Render the document and view the output.\n\n\n# add code here\n\n\nDemo: First, replace the blank below with the number of rows in the penguins data frame based on the output of the chunk below. Then, replace it with ‚Äúinline code‚Äù and render again.\n\n\nnrow(penguins)\n\n[1] 344\n\n\nThere are ___ penguins in the penguins data frame.\n\nx &lt;- 2\nx * 3\n\n[1] 6"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz-A.html",
    "href": "ae/ae-02-bechdel-dataviz-A.html",
    "title": "AE 02: Bechdel + data visualization",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it‚Äôs not designed to be an exhaustive key.\nIn this mini analysis we work with the data used in the FiveThirtyEight story titled ‚ÄúThe Dollar-And-Cents Case Against Hollywood‚Äôs Exclusion of Women‚Äù.\nThis analysis is about the Bechdel test, a measure of the representation of women in fiction."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz-A.html#getting-started",
    "href": "ae/ae-02-bechdel-dataviz-A.html#getting-started",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Getting started",
    "text": "Getting started\n\nPackages\nWe start with loading the packages we‚Äôll use: tidyverse for majority of the analysis and scales for pretty plot labels later on.\n\nlibrary(tidyverse)\nlibrary(scales)\n\n\n\nData\nThe data are stored as a CSV (comma separated values) file in the data folder of your repository. Let‚Äôs read it from there and save it as an object called bechdel.\n\nbechdel &lt;- read_csv(\"https://sta199-s24.github.io/data/bechdel.csv\")\n\n\n\nGet to know the data\nWe can use the glimpse function to get an overview (or ‚Äúglimpse‚Äù) of the data.\n\nglimpse(bechdel)\n\nRows: 1,615\nColumns: 7\n$ title       &lt;chr&gt; \"21 & Over\", \"Dredd 3D\", \"12 Years a Slave\", \"2 Guns\", \"42‚Ä¶\n$ year        &lt;dbl&gt; 2013, 2012, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013‚Ä¶\n$ gross_2013  &lt;dbl&gt; 67878146, 55078343, 211714070, 208105475, 190040426, 18416‚Ä¶\n$ budget_2013 &lt;dbl&gt; 13000000, 45658735, 20000000, 61000000, 40000000, 22500000‚Ä¶\n$ roi         &lt;dbl&gt; 5.221396, 1.206305, 10.585703, 3.411565, 4.751011, 0.81851‚Ä¶\n$ binary      &lt;chr&gt; \"FAIL\", \"PASS\", \"FAIL\", \"FAIL\", \"FAIL\", \"FAIL\", \"FAIL\", \"P‚Ä¶\n$ clean_test  &lt;chr&gt; \"notalk\", \"ok\", \"notalk\", \"notalk\", \"men\", \"men\", \"notalk\"‚Ä¶\n\n\n\nWhat does each observation (row) in the data set represent?\n\nEach observation represents a movie.\n\nHow many observations (rows) are in the data set?\n\nThere are 1615 movies in the dataset.\n\nHow many variables (columns) are in the data set?\n\nThere are 7 columns in the dataset.\n\n\nVariables of interest\nThe variables we‚Äôll focus on are the following:\n\nbudget_2013: Budget in 2013 inflation adjusted dollars.\ngross_2013: Gross (US and international combined) in 2013 inflation adjusted dollars.\nroi: Return on investment, calculated as the ratio of the gross to budget.\nclean_test: Bechdel test result:\n\nok = passes test\ndubious\nmen = women only talk about men\nnotalk = women don‚Äôt talk to each other\nnowomen = fewer than two women\n\nbinary: Bechdel Test PASS vs FAIL binary\n\nWe will also use the year of release in data prep and title of movie to take a deeper look at some outliers.\nThere are a few other variables in the dataset, but we won‚Äôt be using them in this analysis."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz-A.html#visualizing-data-with-ggplot2",
    "href": "ae/ae-02-bechdel-dataviz-A.html#visualizing-data-with-ggplot2",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Visualizing data with ggplot2",
    "text": "Visualizing data with ggplot2\nggplot2 is the package and ggplot() is the function in this package that is used to create a plot.\n\nggplot() creates the initial base coordinate system, and we will add layers to that base. We first specify the data set we will use with data = bechdel.\n\n\nggplot(data = bechdel)\n\n\n\n\n\n\n\n\n\nThe mapping argument is paired with an aesthetic (aes()), which tells us how the variables in our data set should be mapped to the visual properties of the graph.\n\n\nggplot(data = bechdel, \n       mapping = aes(x = budget_2013, y = gross_2013))\n\n\n\n\n\n\n\n\nAs we previously mentioned, we often omit the names of the first two arguments in R functions. So you‚Äôll often see this written as:\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013))\n\n\n\n\n\n\n\n\nNote that the result is exactly the same.\n\nThe geom_xx function specifies the type of plot we want to use to represent the data. In the code below, we use geom_point which creates a plot where each observation is represented by a point.\n\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013)) +\n  geom_point()\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nNote that this results in a warning as well. What does the warning mean?"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz-A.html#gross-revenue-vs.-budget",
    "href": "ae/ae-02-bechdel-dataviz-A.html#gross-revenue-vs.-budget",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Gross revenue vs.¬†budget",
    "text": "Gross revenue vs.¬†budget\n\nStep 1 - Your turn\nModify the following plot to change the color of all points to a different color.\n\n\n\n\n\n\nTip\n\n\n\nSee http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf for many color options you can use by name in R or use the hex code for a color of your choice.\n\n\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013)) +\n  geom_point(color = \"coral\") \n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nStep 2 - Your turn\nAdd labels for the title and x and y axes.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013))+\n  geom_point(color = \"deepskyblue3\") + \n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nStep 3 - Your turn\nAn aesthetic is a visual property of one of the objects in your plot. Commonly used aesthetic options are:\n\ncolor\nfill\nshape\nsize\nalpha (transparency)\n\nModify the plot below, so the color of the points is based on the variable binary.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013, color = binary)) +\n  geom_point() + \n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by Bechdel test result\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nStep 4 - Your turn\nExpand on your plot from the previous step to make the size of your points based on roi.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013,\n           color = binary, size = roi)) +\n  geom_point() + \n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by Bechdel test result\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nStep 5 - Your turn\nExpand on your plot from the previous step to make the transparency (alpha) of the points 0.5.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013,\n           color = binary, size = roi)) +\n  geom_point(alpha = 0.5) + \n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by Bechdel test result\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nStep 6 - Your turn\nExpand on your plot from the previous step by using facet_wrap to display the association between budget and gross for different values of clean_test.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013,\n           color = binary, size = roi)) +\n  geom_point(alpha = 0.5) + \n  facet_wrap(~clean_test) +\n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by Bechdel test result\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nStep 7 - Demo\nImprove your plot from the previous step by making the x and y scales more legible.\n\n\n\n\n\n\nTip\n\n\n\nMake use of the scales package, specifically the scale_x_continuous() and scale_y_continuous() functions.\n\n\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013,\n           color = binary, size = roi)) +\n  geom_point(alpha = 0.5) + \n  facet_wrap(~clean_test) +\n  scale_x_continuous(labels = label_dollar(scale = 1/1000000)) +\n  scale_y_continuous(labels = label_dollar(scale = 1/1000000)) +\n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by Bechdel test result\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nStep 8 - Your turn\nExpand on your plot from the previous step by using facet_grid to display the association between budget and gross for different combinations of clean_test and binary. Comment on whether this was a useful update.\n\nggplot(bechdel, \n       aes(x = budget_2013, y = gross_2013,\n           color = binary, size = roi)) +\n  geom_point(alpha = 0.5) + \n  facet_grid(binary~clean_test) +\n  scale_x_continuous(labels = label_dollar(scale = 1/1000000)) +\n  scale_y_continuous(labels = label_dollar(scale = 1/1000000)) +\n  labs(\n    x = \"Budget (in 2013 $)\", \n    y = \"Gross revenue (in 2013 $)\", \n    title = \"Gross revenue vs. budget, by Bechdel test result\"\n    )\n\nWarning: Removed 15 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nThis was not a useful update as one of the levels of clean_test maps directly to one of the levels of binary.\n\n\nStep 9 - Demo\nWhat other improvements could we make to this plot?\n\n# Answers may vary\n\n\n\nRender, commit, and push\n\nIf you made any changes since the last render, render again to get the final version of the AE.\nCheck the box next to each document in the Git tab (this is called ‚Äústaging‚Äù the changes). Commit the changes you made using a simple and informative message.\nUse the green arrow to push your changes to your repo on GitHub.\nCheck your repo on GitHub and see the updated files. Once your updated files are in your repo on GitHub, you‚Äôre good to go!"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz-A.html#return-on-investment",
    "href": "ae/ae-02-bechdel-dataviz-A.html#return-on-investment",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Return-on-investment",
    "text": "Return-on-investment\nFinally, let‚Äôs take a look at return-on-investment (ROI).\n\nStep 1 - Your turn\nCreate side-by-side box plots of roi by clean_test where the boxes are colored by binary.\n\nggplot(bechdel, \n       aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"Return-on-investment (gross / budget)\",\n    color = \"Bechdel\\nresult\"\n    )\n\nWarning: Removed 15 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nWhat are those movies with very high returns on investment?\n\nbechdel |&gt;\n  filter(roi &gt; 400) |&gt;\n  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n# A tibble: 3 √ó 6\n  title                     roi budget_2013 gross_2013  year clean_test\n  &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Paranormal Activity      671.      505595  339424558  2007 dubious   \n2 The Blair Witch Project  648.      839077  543776715  1999 ok        \n3 El Mariachi              583.       11622    6778946  1992 nowomen   \n\n\n\n\nStep 2 - Demo\nExpand on your plot from the previous step to zoom in on movies with roi &lt; ___ to get a better view of how the medians across the categories compare.\n\nggplot(bechdel, \n       aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"Return-on-investment (gross / budget)\",\n    color = \"Bechdel\\nresult\"\n    ) +\n  coord_cartesian(ylim = c(0, 18))\n\nWarning: Removed 15 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nWhat does this plot say about return-on-investment on movies that pass the Bechdel test?"
  },
  {
    "objectID": "ae/ae-03-duke-forest.html",
    "href": "ae/ae-03-duke-forest.html",
    "title": "AE 03: Duke Forest + data visualization",
    "section": "",
    "text": "library(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "ae/ae-03-duke-forest.html#exercise-1",
    "href": "ae/ae-03-duke-forest.html#exercise-1",
    "title": "AE 03: Duke Forest + data visualization",
    "section": "Exercise 1",
    "text": "Exercise 1\nSuppose you‚Äôre helping some family friends who are looking to buy a house in Duke Forest. As they browse Zillow listings, they realize some houses have garages and others don‚Äôt, and they wonder: Does having a garage make a difference?\nLuckily, you can help them answer this question with data visualization!\n\nMake histograms of the prices of houses in Duke Forest based on whether they have a garage.\n\nIn order to do this, you will first need to create a new variable called garage (with levels \"Garage\" and \"No garage\").\nBelow is the code for creating this new variable. Here, we mutate() the duke_forest data frame to add a new variable called garage which takes the value \"Garage\" if the text string \"Garage\" is detected in the parking variable and takes the test string \"No garage\" if not.\n\n\n\nduke_forest |&gt;\n  mutate(garage = if_else(str_detect(parking, \"Garage\"),   \"Garage\", \"No garage\"))\n\n\nThen, facet by garage and use different colors for the two facets.\nChoose an appropriate binwidth and decide whether a legend is needed, and turn it off if not.\nInclude informative title and axis labels.\nFinally, include a brief (2-3 sentence) narrative comparing the distributions of prices of Duke Forest houses that do and don‚Äôt have garages. Your narrative should touch on whether having a garage ‚Äúmakes a difference‚Äù in terms of the price of the house.\n\n\n# add code here\n\nAdd narrative here‚Ä¶\n\n\n\n\n\n\nImportant\n\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "ae/ae-03-duke-forest.html#exercise-2",
    "href": "ae/ae-03-duke-forest.html#exercise-2",
    "title": "AE 03: Duke Forest + data visualization",
    "section": "Exercise 2",
    "text": "Exercise 2\nIt‚Äôs expected that within any given marker larger houses will be priced higher. It‚Äôs also expected that the age of the house will have an effect on the price. However in some markets new houses might be more expensive while in others new construction might mean ‚Äúno character‚Äù and hence be less expensive. So your family friends ask: ‚ÄúIn Duke Forest, do houses that are bigger and more expensive tend to be newer ones than those that are smaller and cheaper?‚Äù\nOnce again, data visualization skills to the rescue!\n\nCreate a scatter plot to exploring the relationship between price and area, conditioning for year_built.\nUse geom_smooth() with the argument se = FALSE to add a smooth curve fit to the data and color the points by year_built.\nInclude informative title, axis, and legend labels.\nDiscuss each of the following claims (1-2 sentences per claim). Your discussion should touch on specific things you observe in your plot as evidence for or against the claims.\n\nClaim 1: Larger houses are priced higher.\nClaim 2: Newer houses are priced higher.\nClaim 3: Bigger and more expensive houses tend to be newer ones than smaller and cheaper ones.\n\n\n\n# add code here\n\nAdd narrative here‚Ä¶\n\n\n\n\n\n\nImportant\n\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "ae/ae-06-population-joining-A.html",
    "href": "ae/ae-06-population-joining-A.html",
    "title": "AE 06: Joining country populations with continents",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it‚Äôs not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-06-population-joining-A.html#goal",
    "href": "ae/ae-06-population-joining-A.html#goal",
    "title": "AE 06: Joining country populations with continents",
    "section": "Goal",
    "text": "Goal\nOur ultimate goal in this application exercise is to create a bar plot of total populations of continents, where the input data are:\n\nCountries and populations\nCountries and continents\n\n\nlibrary(tidyverse) # for data wrangling and visualization\nlibrary(scales)    # for pretty axis breaks"
  },
  {
    "objectID": "ae/ae-06-population-joining-A.html#data",
    "href": "ae/ae-06-population-joining-A.html#data",
    "title": "AE 06: Joining country populations with continents",
    "section": "Data",
    "text": "Data\n\nCountries and populations\nThese data come from The World Bank and reflect population counts as of 2022.\n\npopulation &lt;- read_csv(\"https://sta199-s24.github.io/data/world-pop-2022.csv\")\n\nLet‚Äôs take a look at the data.\n\npopulation\n\n# A tibble: 217 √ó 3\n   country              year population\n   &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;\n 1 Afghanistan          2022    41129. \n 2 Albania              2022     2778. \n 3 Algeria              2022    44903. \n 4 American Samoa       2022       44.3\n 5 Andorra              2022       79.8\n 6 Angola               2022    35589. \n 7 Antigua and Barbuda  2022       93.8\n 8 Argentina            2022    46235. \n 9 Armenia              2022     2780. \n10 Aruba                2022      106. \n# ‚Ñπ 207 more rows\n\n\n\n\nContinents\nThese data come from Our World in Data.\n\ncontinents &lt;- read_csv(\"https://sta199-s24.github.io/data/continents.csv\")\n\nLet‚Äôs take a look at the data.\n\ncontinents\n\n# A tibble: 285 √ó 4\n   entity                code      year continent    \n   &lt;chr&gt;                 &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;        \n 1 Abkhazia              OWID_ABK  2015 Asia         \n 2 Afghanistan           AFG       2015 Asia         \n 3 Akrotiri and Dhekelia OWID_AKD  2015 Asia         \n 4 Aland Islands         ALA       2015 Europe       \n 5 Albania               ALB       2015 Europe       \n 6 Algeria               DZA       2015 Africa       \n 7 American Samoa        ASM       2015 Oceania      \n 8 Andorra               AND       2015 Europe       \n 9 Angola                AGO       2015 Africa       \n10 Anguilla              AIA       2015 North America\n# ‚Ñπ 275 more rows"
  },
  {
    "objectID": "ae/ae-06-population-joining-A.html#exercises",
    "href": "ae/ae-06-population-joining-A.html#exercises",
    "title": "AE 06: Joining country populations with continents",
    "section": "Exercises",
    "text": "Exercises\n\nThink out loud:\n\nWhich variable(s) will we use to join the population and continents data frames?\n\ncountry from population and entity from continents\n\nWe want to create a new data frame that keeps all rows and columns from population and brings in the corresponding information from continents. Which join function should we use?\n\nleft_join() with population on the left.\nDemo: Join the two data frames and name assign the joined data frame to a new data frame population_continents.\n\n\npopulation_continent &lt;- population |&gt;\n  left_join(continents, by = join_by(country == entity))\n\n\nDemo: Take a look at the newly created population_continent data frame. There are some countries that were not in continents. First, identify which countries these are (they will have NA values for continent).\n\n\npopulation_continent |&gt;\n  filter(is.na(continent))\n\n# A tibble: 6 √ó 6\n  country                   year.x population code  year.y continent\n  &lt;chr&gt;                      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;    \n1 Congo, Dem. Rep.            2022     99010. &lt;NA&gt;      NA &lt;NA&gt;     \n2 Congo, Rep.                 2022      5970. &lt;NA&gt;      NA &lt;NA&gt;     \n3 Hong Kong SAR, China        2022      7346. &lt;NA&gt;      NA &lt;NA&gt;     \n4 Korea, Dem. People's Rep.   2022     26069. &lt;NA&gt;      NA &lt;NA&gt;     \n5 Korea, Rep.                 2022     51628. &lt;NA&gt;      NA &lt;NA&gt;     \n6 Kyrgyz Republic             2022      6975. &lt;NA&gt;      NA &lt;NA&gt;     \n\n\n\nDemo: All of these countries are actually in the continents data frame, but under different names. So, let‚Äôs clean that data first by updating the country names in the population data frame in a way they will match the continents data frame, and then joining them, using a case_when() statement in mutate(). At the end, check that all countries now have continent information.\n\n\npopulation_continent &lt;- population |&gt;\n  mutate(country = case_when(\n    country == \"Congo, Dem. Rep.\" ~ \"Democratic Republic of Congo\",\n    country == \"Congo, Rep.\" ~ \"Congo\",\n    country == \"Hong Kong SAR, China\" ~ \"Hong Kong\",\n    country == \"Korea, Dem. People's Rep.\" ~ \"North Korea\",\n    country == \"Korea, Rep.\" ~ \"South Korea\",\n    country == \"Kyrgyz Republic\" ~ \"Kyrgyzstan\",\n    .default = country\n    )\n  ) |&gt;\n  left_join(continents, by = join_by(country == entity))\n\npopulation_continent |&gt;\n  filter(is.na(continent))\n\n# A tibble: 0 √ó 6\n# ‚Ñπ 6 variables: country &lt;chr&gt;, year.x &lt;dbl&gt;, population &lt;dbl&gt;, code &lt;chr&gt;,\n#   year.y &lt;dbl&gt;, continent &lt;chr&gt;\n\n\n\nThink out loud: Which continent do you think has the highest population? Which do you think has the second highest? The lowest?\n\nAdd your response here.\n\nDemo: Create a new data frame called population_summary that contains a row for each continent and a column for the total population for that continent, in descending order of population. Note that the function for calculating totals in R is sum().\n\n\npopulation_summary &lt;- population_continent |&gt;\n  group_by(continent) |&gt;\n  summarize(total_pop = sum(population)) |&gt;\n  arrange(desc(total_pop))\n\n\nYour turn: Make a bar plot with total population on the y-axis and continent on the x-axis, where the height of each bar represents the total population in that continent.\n\n\nggplot(population_summary, aes(x = continent, y = total_pop)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\nYour turn: Recreate the following plot, which is commonly referred to as a lollipop plot. Hint: Start with the points, then try adding the segments, then add axis labels and caption, and finally, as a stretch goal, update the x scale (which will require a function we haven‚Äôt introduced in lectures or labs yet!).\n\n\n\nggplot(population_summary, aes()) +\n  geom_point(aes(x = total_pop, y = continent)) +\n  geom_segment(aes(y = continent, yend = continent, x = 0, xend = total_pop)) +\n  scale_x_continuous(labels = label_number(scale = 1/1000000, suffix = \" bil\")) +\n  theme_minimal() +\n  labs(\n    x = \"Total population\",\n    y = \"Continent\",\n    title = \"World population\",\n    subtitle = \"As of 2022\",\n    caption = \"Data sources: The World Bank and Our World in Data\"\n  )\n\n\n\n\n\n\n\n\n\nThink out loud: What additional improvements would you like to make to this plot.\n\nAnswers may vary. Ordering the continents in decreasing order of population."
  },
  {
    "objectID": "project/3-peer-review.html",
    "href": "project/3-peer-review.html",
    "title": "Peer review",
    "section": "",
    "text": "During the peer feedback process, you will be provided read-only access to your partner team‚Äôs GitHub repo. You will provide your feedback in the form of GitHub issues to your partner team‚Äôs GitHub repo.\n\nGoals\nThe goals of this milestone are as follows:\n\nReview others‚Äô project drafts as a team and provide feedback\nPost issues on GitHub using an issue template\nLearn from others‚Äô projects and improve your own project based on their strengths and weaknesses\n\n\n\nInstructions\nEach team will review two other teams‚Äô project. As a team you should spend ~30 minutes on each team‚Äôs project.\n\nFind the names of the teams whose projects you‚Äôre reviewing below. You should already have access to this team‚Äôs repo.\nEach team member should go to the repo of the team you‚Äôre reviewing.\nThen,\n\n1-2 team members clone the team‚Äôs project and renders it to check for reproducibility.\n1-2 team members open the team‚Äôs project in their browser and starts reading through the project draft.\n1 team member opens an issue on the team‚Äôs repo using the peer review template.\nAll team members discuss the project based on the prompts on the issue template and one team member records the feedback and submits the issue.\n\nTo open an issue in the repo you‚Äôre reviewing, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical reasoning aspect of the project, but do feel free to comment on aspects beyond the reasoning as well.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nWere you able to reproduce the project by clicking on Render Website once you cloned it? Were there any issues with reproducibility?\nProvide constructive feedback on any issues with file and/or code organization.\nWhat have you learned from this team‚Äôs project that you are considering implementing in your own project?\n(Optional) Any further comments or feedback?\n\n\n\n\nReview pairings\n\n\nGrading\nPeer reviews will be graded on the extent to which it comprehensively and constructively addresses the components of the reviewee‚Äôs team‚Äôs report.\nOnly the team members participating in the review during the lab session are eligible for points for the peer review. If you‚Äôre unable to make it to lab in person, you should arrange to virtually connect with your team during your lab session.\n\n0 points: No peer review\n1 point: Only one peer review issue open, feedback provided is not constructive or actionable\n2 points: Both peer review issues open, feedback provided is not constructive or actionable\n3 points: Both peer review issues open, feedback provided is not sufficiently thorough\n4 points: Both peer review issues open, one of the reviews is not sufficiently thorough\n5 points: Both peer review issues open, both reviews are constructive, actionable, and sufficiently thorough\n\n\n\n\n\n\n\nNote\n\n\n\nThe feedback issue will come from one team member on GitHub since you can‚Äôt collectively edit an issue. However it must represent the opinions of the entire team. It is not a single team member‚Äôs responsibility to provide feedback, they‚Äôre just the record keeper for the team.",
    "crumbs": [
      "Project",
      "Milestone 3"
    ]
  },
  {
    "objectID": "project/1-working-collaboratively.html",
    "href": "project/1-working-collaboratively.html",
    "title": "Working collaboratively",
    "section": "",
    "text": "Data science is a collaborative discipline. Pretty much no data scientist works alone, so neither should you! In this course you‚Äôll collaborate with teammates on the project.\nThe first milestone of the project, today‚Äôs activity, will introduce you to the technical aspects of collaborating on a reproducible data science project that is version controlled by Git and hosted on GitHub in a repository shared by all teammates.\nYes, this means you and all of your teammates will be pushing to the same repository! Sometimes things will go swimmingly, and sometimes you‚Äôll run into merge conflicts.",
    "crumbs": [
      "Project",
      "Milestone 1"
    ]
  },
  {
    "objectID": "project/1-working-collaboratively.html#activity",
    "href": "project/1-working-collaboratively.html#activity",
    "title": "Working collaboratively",
    "section": "Activity",
    "text": "Activity\n\nSetup\n\nClone the project repo and open the about.qmd file.\nAssign the numbers 1, 2, 3, 4, and 5 to each of the team members. If your team has fewer than 5 people, some people will need to have multiple numbers.\n\n\n\nLet‚Äôs cause a merge conflict!\nOur goal is to see two different types of merges: first we‚Äôll see a type of merge that git can‚Äôt figure out on its own how to do on its own (a merge conflict) and requires human intervention, then another type of where that git can figure out how to do without human intervention.\nDoing this will require some tight choreography, so pay attention!\nTake turns in completing the exercise, only one member at a time. Others should just watch, not doing anything on their own projects (this includes not even pulling changes!) until they are instructed to. If you feel like you won‚Äôt be able to resist the urge to touch your computer when it‚Äôs not your turn, we recommend putting your hands in your pockets or sitting on them!\n\nBefore starting\nEveryone should have the repo cloned and know which role number(s) they are.\nAlso, any teammates who haven‚Äôt done this before should go to their Terminal and type git config pull.rebase false to set up their preferences for pulling.\n\n\nRole 1\n\nGo to about.qmd in your project repo. Change the [team name] to your actual team name.\nRender the project by clicking on Render in the Build tab, commit (all changed files), and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\n\n\nRole 2\n\nChange the team name to some other word.\nRender the project by clicking on Render in the Build tab, commit (all changed files), and push. You should get an error.\nPull. Take a look at the document (about.qmd) with the merge conflict.\nClear the merge conflict by editing the document to choose the correct/preferred change.\nRender the project by clicking on Render in the Build tab.\nClick the Stage checkbox for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.\nCommit and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\n\n\nRole 3\n\nChange the a name of the first team member.\nRender the project by clicking on Render in the Build tab, commit, push. You should get an error.\nPull. No merge conflicts should occur, but you should see a message about merging.\nNow push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\n\n\nRole 4\n\nChange the a name of the first team member to something other than what the previous team member did.\nRender the project by clicking on Render in the Build tab, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. Render the project by clicking on Render in the Build tab, commit, and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\n\n\nRole 5\n\nChange the a name of the rest of the team members and add descriptions for each person with the help of your team members. Role 5 should be the only one typing, the others should help verbally.\nRender the project by clicking on Render in the Build tab and commit. Discuss as a team what you expect to happen when you hit push. Should there be a merge conflict error or not?\nIf there is a merge conflict, fix it. If not, push your changes.\n\n\n\nEveryone\nPull, and observe the changes in your project.",
    "crumbs": [
      "Project",
      "Milestone 1"
    ]
  },
  {
    "objectID": "project/1-working-collaboratively.html#tips-for-collaborating-via-github",
    "href": "project/1-working-collaboratively.html#tips-for-collaborating-via-github",
    "title": "Working collaboratively",
    "section": "Tips for collaborating via GitHub",
    "text": "Tips for collaborating via GitHub\n\nAlways pull first before you start working.\nResolve a merge conflict (render and push) before continuing your work. Never do new work while resolving a merge conflict.\nRender, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.\nIf you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don‚Äôt let it linger and get bigger.",
    "crumbs": [
      "Project",
      "Milestone 1"
    ]
  },
  {
    "objectID": "project/4-writeup-presentation.html",
    "href": "project/4-writeup-presentation.html",
    "title": "Writeup and presentation",
    "section": "",
    "text": "The goals of this milestone are as follows:\n\n‚Ä¶\n\nYour written report must be completed in the report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo: false in the YAML.\nThe mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long (if it were to be printed). There is no minimum page requirement; however, you should comprehensively address all of the analysis in your report.\nTo check how many pages your report is, open it in your browser and go to File &gt; Print &gt; Save as PDF and review the number of pages.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\n\n\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won‚Äôt fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\n\nThis section includes a brief description of your analysis process. Explain the reasoning for the types of analyses you do, exploratory, inferential, or modeling. If you‚Äôve chosen to do inference, make sure to include a justification for why that inferential approach is appropriate. If you‚Äôve chosen to do modeling, describe the model(s) you‚Äôre fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\n\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\nThe analysis results are clearly assesses and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\n\nIn this section you‚Äôll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\n\nThis is an assessment of the overall presentation and formatting of the written report.\n\n\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.\n\n\n\n\n\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion\n6 pts\n\n\nOrganization + formatting\n4 pts",
    "crumbs": [
      "Project",
      "Milestone 4"
    ]
  },
  {
    "objectID": "project/4-writeup-presentation.html#report-components",
    "href": "project/4-writeup-presentation.html#report-components",
    "title": "Writeup and presentation",
    "section": "",
    "text": "This section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won‚Äôt fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\n\nThis section includes a brief description of your analysis process. Explain the reasoning for the types of analyses you do, exploratory, inferential, or modeling. If you‚Äôve chosen to do inference, make sure to include a justification for why that inferential approach is appropriate. If you‚Äôve chosen to do modeling, describe the model(s) you‚Äôre fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\n\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\nThe analysis results are clearly assesses and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\n\nIn this section you‚Äôll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\n\nThis is an assessment of the overall presentation and formatting of the written report.\n\n\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.",
    "crumbs": [
      "Project",
      "Milestone 4"
    ]
  },
  {
    "objectID": "project/4-writeup-presentation.html#report-grading",
    "href": "project/4-writeup-presentation.html#report-grading",
    "title": "Writeup and presentation",
    "section": "",
    "text": "The written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion\n6 pts\n\n\nOrganization + formatting\n4 pts",
    "crumbs": [
      "Project",
      "Milestone 4"
    ]
  },
  {
    "objectID": "project/4-writeup-presentation.html#slides",
    "href": "project/4-writeup-presentation.html#slides",
    "title": "Writeup and presentation",
    "section": "Slides",
    "text": "Slides\nIn addition to the written report, your team will also create presentation slides and deliver presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that‚Äôs easy to collaborate with, e.g., Google Slides.\nYou can also use Quarto to make your slides! While we won‚Äôt be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It‚Äôs no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4-5: Inference/modeling/other analysis\nSlide 6: Conclusions + future work",
    "crumbs": [
      "Project",
      "Milestone 4"
    ]
  },
  {
    "objectID": "project/4-writeup-presentation.html#presentation",
    "href": "project/4-writeup-presentation.html#presentation",
    "title": "Writeup and presentation",
    "section": "Presentation",
    "text": "Presentation\nPresentations will take place in class during the last lab of the semester. The presentation must be no longer than 5 minutes. You can choose to present live in class (recommended) or pre-record a video to be shown in class. Either way you must attend the lab session for the Q&A following your presentation.\nIf you choose to pre-record your presentation, you may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire or another video platform (e.g., YouTube), then add a link to your video in your repo README.\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the ‚Äú+‚Äù and select ‚ÄúUpload files‚Äù.\nLocate the video on your computer and click to upload.\nOnce you‚Äôve uploaded the video to Warpwire, click to share the video and copy the video‚Äôs URL. You will need this when you post the video in the discussion forum.",
    "crumbs": [
      "Project",
      "Milestone 4"
    ]
  },
  {
    "objectID": "project/tips-resources.html",
    "href": "project/tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "The project is very open ended. For instance, in creating a compelling visualization(s) of your data in R, there is no limit on what tools or packages you may use. You do not need to visualize all of the data at once. A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations.\nBefore you finalize your write up, make sure the printing of code chunks is turned off with the option echo: false. In addition to code chunks, ensure all messages are turned off with the options warning: false and message: false.\nFinally, pay attention to details in your write-up and presentation. Neatness, coherency, and clarity will count.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/tips-resources.html#suppress-code-and-warnings",
    "href": "project/tips-resources.html#suppress-code-and-warnings",
    "title": "Project tips + resources",
    "section": "Suppress code and warnings",
    "text": "Suppress code and warnings\n\nInclude the following in the YAML of your report.qmd to suppress all code, warnings, and other messages.\n\nexecute:\n  echo: false\n  warning: false",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/tips-resources.html#headers",
    "href": "project/tips-resources.html#headers",
    "title": "Project tips + resources",
    "section": "Headers",
    "text": "Headers\nUse headers to clearly label each section. Make sure there is a space between the previous line and the header. Use appropriate header levels.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/tips-resources.html#references",
    "href": "project/tips-resources.html#references",
    "title": "Project tips + resources",
    "section": "References",
    "text": "References\nInclude all references in a section called ‚ÄúReferences‚Äù at the end of the report. This course does not have specific requirements for formatting citations and references. Optional: Use Quarto‚Äôs citation support for generating your reference. See Citations & Footnotes on the Quarto documentation for more on that.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/tips-resources.html#appendix",
    "href": "project/tips-resources.html#appendix",
    "title": "Project tips + resources",
    "section": "Appendix",
    "text": "Appendix\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called ‚ÄúAppendix‚Äù. The items in the appendix should be properly labeled. The appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix. We will not grade your appendix.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/tips-resources.html#resize-figures",
    "href": "project/tips-resources.html#resize-figures",
    "title": "Project tips + resources",
    "section": "Resize figures",
    "text": "Resize figures\nResize plots and figures, so you have more space for the narrative. Resize individual figures: Set fig-width and fig-height in chunk options, e.g.,\n#| echo: fenced\n#| label: plot1\n#| fig-height: 3\n#| fig-width: 5\nreplacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig-height and fig-width options in the YAML header as shown below:\nexecute:\n  fig-height: 3\n  fig-width: 5\nReplace the height and width values with values appropriate for your write up.",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/tips-resources.html#arranging-plots",
    "href": "project/tips-resources.html#arranging-plots",
    "title": "Project tips + resources",
    "section": "Arranging plots",
    "text": "Arranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nIf you‚Äôre using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid.\nMore to be added soon‚Ä¶",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "project/description.html",
    "href": "project/description.html",
    "title": "Project description",
    "section": "",
    "text": "TL;DR: Ask a question you‚Äôre curious about and answer it with a dataset of your choice. This is your project in a nutshell.\nMay be too long, but please do read\nThe project for this class will consist of analysis on a dataset of your own choosing. The dataset may already exist, or you may collect your own data using a survey or by conducting an experiment. You can choose the data based on your teams‚Äô interests or based on work in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like) and apply them to a novel dataset in a meaningful way.\nThe goal is not to do an exhaustive data analysis i.e., do not calculate every statistic and procedure you have learned for every variable, but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using R, and that you are proficient at interpreting and presenting the results. Focus on methods that help you begin to answer your research questions. You do not have to apply every statistical procedure we learned. Also, critique your own methods and provide suggestions for improving your analysis. Issues pertaining to the reliability and validity of your data, and appropriateness of the statistical analysis should be discussed here.\nThe project is very open ended. You should create some kind of compelling visualization(s) of this data in R. There is no limit on what tools or packages you may use but sticking to packages we learned in class is required. You do not need to visualize all of the data at once. A single high-quality visualization will receive a much higher grade than a large number of poor-quality visualizations. Also pay attention to your presentation. Neatness, coherency, and clarity will count. All analyses must be done in RStudio, using R, and all components of the project must be reproducible (with the exception of the presentation).\nYou will work on the project with your lab teams.\nThe four milestones for the final project are\n\nMilestone 1 - Working collaboratively\nMilestone 2 - Proposals, with three dataset ideas\nMilestone 3 - Peer review, on another team‚Äôs project\nMilestone 4 - Presentation with slides and a reproducible project writeup of your analysis, with a draft along the way.\n\nYou will not be submitting anything on Gradescope for the project. Submission of these deliverables will happen on GitHub and feedback will be provided as GitHub issues that you need to engage with and close. The collection of the documents in your GitHub repo will create a webpage for your project. To create the webpage go to the Build tab in RStudio, and click on Render Website.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#reproducibility-organization",
    "href": "project/description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nPoints for reproducibility + organization will be based on the reproducibility of the write-up and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#teamwork",
    "href": "project/description.html#teamwork",
    "title": "Project description",
    "section": "Teamwork",
    "text": "Teamwork\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly and penalties may apply beyond the teamwork component of the grade.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project presentation deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#grading-summary",
    "href": "project/description.html#grading-summary",
    "title": "Project description",
    "section": "Grading summary",
    "text": "Grading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#late-work-policy",
    "href": "project/description.html#late-work-policy",
    "title": "Project description",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/2-proposal.html",
    "href": "project/2-proposal.html",
    "title": "Proposal",
    "section": "",
    "text": "The goals of this milestone are as follows:\n\nDiscuss topics you‚Äôre interested in investigating and find data sets on those topics.\nIdentify 3 data sets you‚Äôre interested in potentially using for the project.\nGet these datasets into R.\nWrite up reasons and justifications for why you want to work with these datasets.\nReview your team contract.\n\n\n\n\n\n\n\nImportant\n\n\n\nYou must use one of the data sets in the proposal for the final project, unless instructed otherwise when given feedback.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#criteria-for-datasets",
    "href": "project/2-proposal.html#criteria-for-datasets",
    "title": "Proposal",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 500 observations\nAt least 8 columns\nAt least 6 of the columns must be useful and unique explanatory variables.\n\nIdentifier variables such as ‚Äúname‚Äù, ‚Äúsocial security number‚Äù, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g.¬†‚Äústate abbreviation‚Äù and ‚Äústate name‚Äù), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\nYou can curate one of your datasets via web scraping.\n\nPlease ask a member of the teaching team if you‚Äôre unsure whether your data set meets the criteria.\nIf you set your hearts on a dataset that has fewer observations or variables than what‚Äôs suggested here, that might still be ok; use these numbers as guidance for a successful proposal, not as minimum requirements.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#resources-for-datasets",
    "href": "project/2-proposal.html#resources-for-datasets",
    "title": "Proposal",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn‚Äôt feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nAwesome public datasets\nBikeshare data portal\nCDC\nData.gov\nData is Plural\nDurham Open Data Portal\nEdinburgh Open Data\nElection Studies\nEuropean Statistics\nCORGIS: The Collection of Really Great, Interesting, Situated Datasets\nGeneral Social Survey\nGoogle Dataset Search\nHarvard Dataverse\nInternational Monetary Fund\nIPUMS survey data from around the world\nLos Angeles Open Data\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland‚Äôs official statistics\nPew Research\nPRISM Data Archive Project\nStatistics Canada\nTidyTuesday\nThe National Bureau of Economic Research\nUCI Machine Learning Repository\nUK Government Data\nUNICEF Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Census Data\nUS Government Data\nWorld Bank Data\nYouth Risk Behavior Surveillance System (YRBSS)\nFRED Economic Data",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#introduction-and-data",
    "href": "project/2-proposal.html#introduction-and-data",
    "title": "Proposal",
    "section": "Introduction and data",
    "text": "Introduction and data\nFor each data set:\n\nIdentify the source of the data.\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\nWrite a brief description of the observations.\nAddress ethical concerns about the data, if any.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#research-question",
    "href": "project/2-proposal.html#research-question",
    "title": "Proposal",
    "section": "Research question",
    "text": "Research question\nYour research question should contain at least three variables, and should be a mix of categorical and quantitative variables. When writing a research question, please think about the following:\n\nWhat is your target population?\nIs the question original?\nCan the question be answered?\n\nFor each data set, include the following:\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\nStatement on why this question is important.\nA description of the research topic along with a concise statement of your hypotheses on this topic.\nIdentify the types of variables in your research question. Categorical? Quantitative?",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#glimpse-of-data",
    "href": "project/2-proposal.html#glimpse-of-data",
    "title": "Proposal",
    "section": "Glimpse of data",
    "text": "Glimpse of data\nFor each data set:\n\nPlace the file containing your data in the data folder of the project repo.\nUse the glimpse() function to provide a glimpse of the data set.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "ae/ae-04-flights-wrangling.html",
    "href": "ae/ae-04-flights-wrangling.html",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "",
    "text": "library(tidyverse)\nlibrary(nycflights13)"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling.html#exercise-1",
    "href": "ae/ae-04-flights-wrangling.html#exercise-1",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 1",
    "text": "Exercise 1\nYour turn: Fill in the blanks:\nThe flights data frame has ___ rows. Each row represents a ___."
  },
  {
    "objectID": "ae/ae-04-flights-wrangling.html#exercise-2",
    "href": "ae/ae-04-flights-wrangling.html#exercise-2",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 2",
    "text": "Exercise 2\nYour turn: What are the names of the variables in flights.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling.html#exercise-3---select",
    "href": "ae/ae-04-flights-wrangling.html#exercise-3---select",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 3 - select()",
    "text": "Exercise 3 - select()\n\nDemo: Make a data frame that only contains the variables dep_delay and arr_delay.\n\n\n# add code here\n\n\nDemo: Make a data frame that keeps every variable except dep_delay.\n\n\n# add code here\n\n\nDemo: Make a data frame that includes all variables between year through dep_delay (inclusive). These are all variables that provide information about the departure of each flight.\n\n\n# add code here\n\n\nDemo: Use the select helper contains() to make a data frame that includes the variables associated with the arrival, i.e., contains the string \"arr\\_\" in the name.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling.html#exercise-4---slice",
    "href": "ae/ae-04-flights-wrangling.html#exercise-4---slice",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 4 - slice()",
    "text": "Exercise 4 - slice()\n\nDemo: Display the first five rows of the flights data frame.\n\n\n# add code here\n\n\nDemo: Display the last two rows of the flights data frame.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling.html#exercise-5---arrange",
    "href": "ae/ae-04-flights-wrangling.html#exercise-5---arrange",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 5 - arrange()",
    "text": "Exercise 5 - arrange()\n\nDemo: Let‚Äôs arrange the data by departure delay, so the flights with the shortest departure delays will be at the top of the data frame.\n\n\n# add code here\n\n\nQuestion: What does it mean for the dep_delay to have a negative value?\n\nAdd your response here.\n\nDemo: Arrange the data by descending departure delay, so the flights with the longest departure delays will be at the top.\n\n\n# add code here\n\n\nYour turn: Create a data frame that only includes the plane tail number (tailnum), carrier (carrier), and departure delay for the flight with the longest departure delay. What is the plane tail number (tailnum) for this flight?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling.html#exercise-6---filter",
    "href": "ae/ae-04-flights-wrangling.html#exercise-6---filter",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 6 - filter()",
    "text": "Exercise 6 - filter()\n\nDemo: Filter for all rows where the destination airport is RDU.\n\n\n# add code here\n\n\nDemo: Filter for all rows where the destination airport is RDU and the arrival delay is less than 0.\n\n\n# add code here\n\n\nYour turn: Describe what the code is doing in words.\n\nAdd response here.\n\nflights |&gt;\n  filter(\n    dest %in% c(\"RDU\", \"GSO\"),\n    arr_delay &lt; 0 | dep_delay &lt; 0\n  )\n\n# A tibble: 6,203 √ó 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      800            810       -10      949            955\n 2  2013     1     1      832            840        -8     1006           1030\n 3  2013     1     1      851            851         0     1032           1036\n 4  2013     1     1      917            920        -3     1052           1108\n 5  2013     1     1     1024           1030        -6     1204           1215\n 6  2013     1     1     1127           1129        -2     1303           1309\n 7  2013     1     1     1157           1205        -8     1342           1345\n 8  2013     1     1     1317           1325        -8     1454           1505\n 9  2013     1     1     1449           1450        -1     1651           1640\n10  2013     1     1     1505           1510        -5     1654           1655\n# ‚Ñπ 6,193 more rows\n# ‚Ñπ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nHint: Logical operators in R:\n\n\n\n\n\n\n\noperator\ndefinition\n\n\n\n\n&lt;\nis less than?\n\n\n&lt;=\nis less than or equal to?\n\n\n&gt;\nis greater than?\n\n\n&gt;=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?\n\n\nx & y\nis x AND y?\n\n\nx \\| y\nis x OR y?\n\n\nis.na(x)\nis x NA?\n\n\n!is.na(x)\nis x not NA?\n\n\nx %in% y\nis x in y?\n\n\n!(x %in% y)\nis x not in y?\n\n\n!x\nis not x? (only makes sense if x is TRUE or FALSE)"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling.html#exercise-7---count",
    "href": "ae/ae-04-flights-wrangling.html#exercise-7---count",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 7 - count()",
    "text": "Exercise 7 - count()\n\nDemo: Create a frequency table of the destination locations for flights from New York.\n\n\n# add code here\n\n\nDemo: In which month was there the fewest number of flights? How many flights were there in that month?\n\n\n# add code here\n\n\nYour turn: On which date (month + day) was there the largest number of flights? How many flights were there on that day?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling.html#exercise-8---mutate",
    "href": "ae/ae-04-flights-wrangling.html#exercise-8---mutate",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 8 - mutate()",
    "text": "Exercise 8 - mutate()\n\nDemo: Convert air_time (minutes in the air) to hours and then create a new variable, mph, the miles per hour of the flight.\n\n\n# add code here\n\n\nYour turn: First, count the number of flights each month, and then calculate the proportion of flights in each month. What proportion of flights take place in July?\n\n\n# add code here\n\n\nDemo: Create a new variable, rdu_bound, which indicates whether the flight is to RDU or not. Then, for each departure airport (origin), calculate what proportion of flights originating from that airport are to RDU.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling.html#exercise-9---summarize",
    "href": "ae/ae-04-flights-wrangling.html#exercise-9---summarize",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 9 - summarize()",
    "text": "Exercise 9 - summarize()\n\nDemo: Find mean arrival delay for all flights.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling.html#exercise-10---group_by",
    "href": "ae/ae-04-flights-wrangling.html#exercise-10---group_by",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 10 - group_by()",
    "text": "Exercise 10 - group_by()\n\nDemo: Find mean arrival delay for for each month.\n\n\n# add code here\n\n\nYour turn: What is the median departure delay for each airports around NYC (origin)? Which airport has the shortest median departure delay?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-07-population-types-A.html",
    "href": "ae/ae-07-population-types-A.html",
    "title": "AE 07: Types and classes and populations",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it‚Äôs not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-07-population-types-A.html#packages",
    "href": "ae/ae-07-population-types-A.html#packages",
    "title": "AE 07: Types and classes and populations",
    "section": "Packages",
    "text": "Packages\nWe will use the following two packages in this application exercise.\n\ntidyverse: For data import, wrangling, and visualization.\nscales: For better axis labels.\n\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(scales)"
  },
  {
    "objectID": "ae/ae-07-population-types-A.html#type-coercion",
    "href": "ae/ae-07-population-types-A.html#type-coercion",
    "title": "AE 07: Types and classes and populations",
    "section": "Type coercion",
    "text": "Type coercion\n\nDemo: Determine the type of the following vector. And then, change the type to numeric.\n\nx &lt;- c(\"1\", \"2\", \"3\")\ntypeof(x)\n\n[1] \"character\"\n\nas.numeric(x)\n\n[1] 1 2 3\n\n\nDemo: Once again, determine the type of the following vector. And then, change the type to numeric. What‚Äôs different than the previous exercise?\n\ny &lt;- c(\"a\", \"b\", \"c\")\ntypeof(y)\n\n[1] \"character\"\n\nas.numeric(y)\n\nWarning: NAs introduced by coercion\n\n\n[1] NA NA NA\n\n\nDemo: Once again, determine the type of the following vector. And then, change the type to numeric. What‚Äôs different than the previous exercise?\n\nz &lt;- c(\"1\", \"2\", \"three\")\ntypeof(z)\n\n[1] \"character\"\n\nas.numeric(z)\n\nWarning: NAs introduced by coercion\n\n\n[1]  1  2 NA\n\n\nDemo: Suppose you conducted a survey where you asked people how many cars their household owns collectively. And the answers are as follows:\n\nsurvey_results &lt;- tibble(cars = c(1, 2, \"three\"))\nsurvey_results\n\n# A tibble: 3 √ó 1\n  cars \n  &lt;chr&gt;\n1 1    \n2 2    \n3 three\n\n\nThis is annoying because of that third survey taker who just had to go and type out the number instead of providing as a numeric value. So now you need to update the cars variable to be numeric. You do the following\n\nsurvey_results |&gt;\n  mutate(cars = as.numeric(cars))\n\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `cars = as.numeric(cars)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n# A tibble: 3 √ó 1\n   cars\n  &lt;dbl&gt;\n1     1\n2     2\n3    NA\n\n\nAnd now things are even more annoying because you get a warning NAs introduced by coercion that happened while computing cars = as.numeric(cars) and the response from the third survey taker is now an NA (you lost their data). Fix your mutate() call to avoid this warning.\n\nsurvey_results |&gt;\n  mutate(\n    cars = if_else(cars == \"three\", \"3\", cars),\n    cars = as.numeric(cars)\n  )\n\n# A tibble: 3 √ó 1\n   cars\n  &lt;dbl&gt;\n1     1\n2     2\n3     3\n\n\nYour turn: First, guess the type of the vector. Then, check if you guessed right. I‚Äôve done the first one for you, you‚Äôll see that it‚Äôs helpful to check the type of each element of the vector first.\n\nc(1, 1L, \"C\")\n\nv1 &lt;- c(1, 1L, \"C\")\n\n# to help you guess\ntypeof(1)\n\n[1] \"double\"\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(\"C\")\n\n[1] \"character\"\n\n# to check after you guess\ntypeof(v1)\n\n[1] \"character\"\n\n\nc(1L / 0, \"A\")\n\nv2 &lt;- c(1L / 0, \"A\")\n\n# to help you guess\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(0)\n\n[1] \"double\"\n\ntypeof(1L / 0)\n\n[1] \"double\"\n\ntypeof(\"A\")\n\n[1] \"character\"\n\n# to check after you guess\ntypeof(v2)\n\n[1] \"character\"\n\n\nc(1:3, 5)\n\nv3 &lt;- c(1:3, 5)\n\n# to help you guess\ntypeof(1:3)\n\n[1] \"integer\"\n\ntypeof(5)\n\n[1] \"double\"\n\n# to check after you guess\ntypeof(v3)\n\n[1] \"double\"\n\n\nc(3, \"3+\")\n\nv4 &lt;- c(3, \"3+\")\n\n# to help you guess\ntypeof(3)\n\n[1] \"double\"\n\ntypeof(\"3+\")\n\n[1] \"character\"\n\n# to check after you guess\ntypeof(v4)\n\n[1] \"character\"\n\n\nc(NA, TRUE)\n\nv5 &lt;- c(NA, TRUE)\n\n# to help you guess\ntypeof(NA)\n\n[1] \"logical\"\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n# to check after you guess\ntypeof(v5)\n\n[1] \"logical\""
  },
  {
    "objectID": "ae/ae-07-population-types-A.html#populations-in-continents",
    "href": "ae/ae-07-population-types-A.html#populations-in-continents",
    "title": "AE 07: Types and classes and populations",
    "section": "Populations in continents",
    "text": "Populations in continents\nIn the previous application exercise you joined two datasets (after a bit of data cleaning), and calculated total population in each continent and visualized it.\n\nFirst, you loaded the data:\n\n\ncontinents &lt;- read_csv(\"https://sta199-s24.github.io/data/continents.csv\")\n\nRows: 285 Columns: 4\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): entity, code, continent\ndbl (1): year\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npopulation &lt;- read_csv(\"https://sta199-s24.github.io/data/world-pop-2022.csv\")\n\nRows: 217 Columns: 3\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): country\ndbl (2): year, population\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nThen you cleaned the country names where the spelling in one data frame didn‚Äôt match the other, and joined the data sets:\n\n\npopulation_continent &lt;- population |&gt;\n  mutate(country = case_when(\n    country == \"Congo, Dem. Rep.\" ~ \"Democratic Republic of Congo\",\n    country == \"Congo, Rep.\" ~ \"Congo\",\n    country == \"Hong Kong SAR, China\" ~ \"Hong Kong\",\n    country == \"Korea, Dem. People's Rep.\" ~ \"North Korea\",\n    country == \"Korea, Rep.\" ~ \"South Korea\",\n    country == \"Kyrgyz Republic\" ~ \"Kyrgyzstan\",\n    .default = country\n    )\n  ) |&gt;\n  left_join(continents, by = join_by(country == entity))\n\n\nThen, you calculated total population for each continent.\n\n\npopulation_summary &lt;- population_continent |&gt;\n  group_by(continent) |&gt;\n  summarize(total_pop = sum(population)) |&gt;\n  arrange(desc(total_pop))\n\n\nAnd finally, you visualized these data.\n\n\nggplot(population_summary) +\n  geom_point(aes(x = total_pop, y = continent)) +\n  geom_segment(aes(y = continent, yend = continent, x = 0, xend = total_pop)) +\n  scale_x_continuous(labels = label_number(scale = 1/1000000, suffix = \" bil\")) +\n  theme_minimal() +\n  labs(\n    x = \"Total population\",\n    y = \"Continent\",\n    title = \"World population\",\n    subtitle = \"As of 2022\",\n    caption = \"Data sources: The World Bank and Our World in Data\"\n  )\n\n\n\n\n\n\n\n\n\nQuestion: Take a look at the visualization. How are the continents ordered? What would be a better order?\n\nOrdering the continents by the value of total population would be better.\n\nDemo: Reorder the continents on the y-axis (levels of continent) in order of value of total population. You will want to use a function from the forcats package, see https://forcats.tidyverse.org/reference/index.html for inspiration and help.\n\n\npopulation_summary |&gt;\n  mutate(continent = fct_reorder(continent, total_pop)) |&gt;\n  ggplot() +\n  geom_point(aes(x = total_pop, y = continent)) +\n  geom_segment(aes(y = continent, yend = continent, x = 0, xend = total_pop)) +\n  geom_segment(aes(y = continent, yend = continent, x = 0, xend = total_pop)) +\n  scale_x_continuous(labels = label_number(scale = 1/1000000, suffix = \" bil\")) +\n  theme_minimal() +\n  labs(\n    x = \"Total population\",\n    y = \"Continent\",\n    title = \"World population\",\n    subtitle = \"As of 2022\",\n    caption = \"Data sources: The World Bank and Our World in Data\"\n  )\n\n\n\n\n\n\n\n\n\nThink out loud: Describe what is happening in the each step of the code chunk above.\n\nAnswers may vary."
  },
  {
    "objectID": "ae/ae-08-data-import-A.html",
    "href": "ae/ae-08-data-import-A.html",
    "title": "AE 08: Data import",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it‚Äôs not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-08-data-import-A.html#packages",
    "href": "ae/ae-08-data-import-A.html#packages",
    "title": "AE 08: Data import",
    "section": "Packages",
    "text": "Packages\nWe will use the following two packages in this application exercise.\n\ntidyverse: For data import, wrangling, and visualization.\nreadxl: For importing data from Excel.\n\n\nlibrary(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "ae/ae-13-modeling-loans-A.html",
    "href": "ae/ae-13-modeling-loans-A.html",
    "title": "Modelling loan interest rates",
    "section": "",
    "text": "In this application exercise we will be studying loan interest rates. The dataset is one you‚Äôve come across before in your reading ‚Äì the dataset about loans from the peer-to-peer lender, Lending Club, from the openintro package. We will use tidyverse and tidymodels for data exploration and modeling, respectively.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nBefore we use the dataset, we‚Äôll make a few transformations to it.\nAdd response here.\nloans &lt;- loans_full_schema |&gt;\n  mutate(\n    credit_util = total_credit_utilized / total_credit_limit,\n    bankruptcy = as.factor(if_else(public_record_bankrupt == 0, 0, 1)),\n    verified_income = droplevels(verified_income),\n    homeownership = str_to_title(homeownership),\n    homeownership = fct_relevel(homeownership, \"Rent\", \"Mortgage\", \"Own\")\n  ) |&gt;\n  rename(credit_checks = inquiries_last_12m) |&gt;\n  select(\n    interest_rate, loan_amount, verified_income, \n    debt_to_income, credit_util, bankruptcy, term, \n    credit_checks, issue_month, homeownership\n  )\nHere is a glimpse at the data:\nglimpse(loans)\n\nRows: 10,000\nColumns: 10\n$ interest_rate   &lt;dbl&gt; 14.07, 12.61, 17.09, 6.72, 14.07, 6.72, 13.59, 11.99, ‚Ä¶\n$ loan_amount     &lt;int&gt; 28000, 5000, 2000, 21600, 23000, 5000, 24000, 20000, 2‚Ä¶\n$ verified_income &lt;fct&gt; Verified, Not Verified, Source Verified, Not Verified,‚Ä¶\n$ debt_to_income  &lt;dbl&gt; 18.01, 5.04, 21.15, 10.16, 57.96, 6.46, 23.66, 16.19, ‚Ä¶\n$ credit_util     &lt;dbl&gt; 0.54759517, 0.15003472, 0.66134832, 0.19673228, 0.7549‚Ä¶\n$ bankruptcy      &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, ‚Ä¶\n$ term            &lt;dbl&gt; 60, 36, 36, 36, 36, 36, 60, 60, 36, 36, 60, 60, 36, 60‚Ä¶\n$ credit_checks   &lt;int&gt; 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8, 6, 0, 0, 4, 6, ‚Ä¶\n$ issue_month     &lt;fct&gt; Mar-2018, Feb-2018, Feb-2018, Jan-2018, Mar-2018, Jan-‚Ä¶\n$ homeownership   &lt;fct&gt; Mortgage, Rent, Rent, Rent, Rent, Own, Mortgage, Mortg‚Ä¶"
  },
  {
    "objectID": "ae/ae-13-modeling-loans-A.html#main-effects-model",
    "href": "ae/ae-13-modeling-loans-A.html#main-effects-model",
    "title": "Modelling loan interest rates",
    "section": "Main effects model",
    "text": "Main effects model\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, without an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\nrate_util_home_fit &lt;- linear_reg() |&gt;\n  fit(interest_rate ~ credit_util + homeownership, data = loans)\n\ntidy(rate_util_home_fit)\n\n# A tibble: 4 √ó 5\n  term                  estimate std.error statistic   p.value\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              9.93      0.140    70.8   0        \n2 credit_util              5.34      0.207    25.7   2.20e-141\n3 homeownershipMortgage    0.696     0.121     5.76  8.71e-  9\n4 homeownershipOwn         0.128     0.155     0.827 4.08e-  1\n\n\n\\[\n\\widehat{interest~rate} = 9.93 + 5.34 \\times credit~util + 0.696 \\times Mortgage - 0.128 \\times Own\n\\]\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(\\widehat{interest~rate} = 9.93 + 5.34 \\times credit~util\\)\nMortgage: \\(\\widehat{interest~rate} = 10.626 + 5.34 \\times credit~util\\)\nOwn: \\(\\widehat{interest~rate} = 10.058 + 5.34 \\times credit~util\\)\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nThe same."
  },
  {
    "objectID": "ae/ae-13-modeling-loans-A.html#interaction-effects-model",
    "href": "ae/ae-13-modeling-loans-A.html#interaction-effects-model",
    "title": "Modelling loan interest rates",
    "section": "Interaction effects model",
    "text": "Interaction effects model\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, with an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\nrate_util_home_int_fit &lt;- linear_reg() |&gt;\n  fit(interest_rate ~ credit_util * homeownership, data = loans)\n\ntidy(rate_util_home_int_fit)\n\n# A tibble: 6 √ó 5\n  term                              estimate std.error statistic  p.value\n  &lt;chr&gt;                                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                          9.44      0.199     47.5  0       \n2 credit_util                          6.20      0.325     19.1  1.01e-79\n3 homeownershipMortgage                1.39      0.228      6.11 1.04e- 9\n4 homeownershipOwn                     0.697     0.316      2.20 2.75e- 2\n5 credit_util:homeownershipMortgage   -1.64      0.457     -3.58 3.49e- 4\n6 credit_util:homeownershipOwn        -1.06      0.590     -1.80 7.24e- 2\n\n\n\\[\n\\widehat{interest~rate} = 9.44 + 6.20 \\times credit~util + 1.39 \\times Mortgage + 0.697 \\times Own - 1.64 \\times credit_util:Mortgage - 1.06 \\times credit_util:Own\n\\]\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(\\widehat{interest~rate} = 9.44 + 6.20 \\times credit~util\\)\nMortgage: \\(\\widehat{interest~rate} = 10.83 + 4.56 \\times credit~util\\)\nOwn: \\(\\widehat{interest~rate} = 10.137 + 5.14 \\times credit~util\\)\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nDifferent."
  },
  {
    "objectID": "ae/ae-13-modeling-loans-A.html#choosing-a-model",
    "href": "ae/ae-13-modeling-loans-A.html#choosing-a-model",
    "title": "Modelling loan interest rates",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam‚Äôs Razor - Don‚Äôt overcomplicate the situation! We prefer the simplest best model.\n\nglance(rate_util_home_fit)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic   p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1    0.0682        0.0679  4.83      244. 1.25e-152     3 -29926. 59861. 59897.\n# ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nglance(rate_util_home_int_fit)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic   p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1    0.0694        0.0689  4.83      149. 4.79e-153     5 -29919. 59852. 59903.\n# ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables).\n\nQuestion: Based on the adjusted \\(R^2\\)s of these two models, which one do we prefer?\n\nThe interaction effects model, though just barely."
  },
  {
    "objectID": "ae/ae-10-modeling-fish-A.html",
    "href": "ae/ae-10-modeling-fish-A.html",
    "title": "AE 10: Modelling fish",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it‚Äôs not designed to be an exhaustive key.\n\n\nFor this application exercise, we will work with data on fish. The dataset we will use, called fish, is on two common fish species in fish market sales.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nfish &lt;- read_csv(\"data/fish.csv\")\n\nThe data dictionary is below:\n\n\n\nvariable\ndescription\n\n\n\n\nspecies\nSpecies name of fish\n\n\nweight\nWeight, in grams\n\n\nlength_vertical\nVertical length, in cm\n\n\nlength_diagonal\nDiagonal length, in cm\n\n\nlength_cross\nCross length, in cm\n\n\nheight\nHeight, in cm\n\n\nwidth\nDiagonal width, in cm\n\n\n\n\nVisualizing the model\nWe‚Äôre going to investigate the relationship between the weights and heights of fish.\n\nDemo: Create an appropriate plot to investigate this relationship. Add appropriate labels to the plot.\n\n\nggplot(fish, aes(x = height, y = weight)) +\n  geom_point() +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n\n\n\n\n\n\n\n\nYour turn (5 minutes):\n\nIf you were to draw a a straight line to best represent the relationship between the heights and weights of fish, where would it go? Why?\nStart from the bottom and go up Identify the first and last point and draw a line through most the others.\nNow, let R draw the line for you. Refer to the documentation at https://ggplot2.tidyverse.org/reference/geom_smooth.html. Specifically, refer to the method section.\n\n\nggplot(fish, aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Weights vs. lengths of fish\",\n    x = \"Head-to-tail lentgh (cm)\",\n    y = \"Weight of fish (grams)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nWhat types of questions can this plot help answer?\nIs there a relationship between fish heights and weights of fish?\n\nYour turn (3 minutes):\n\nWe can use this line to make predictions. Predict what you think the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm. Which prediction is considered extrapolation?\nAt 10 cm, we estimate a weight of 375 grams. At 15 cm, we estimate a weight of 600 grams At 20 cm, we estimate a weight of 975 grams. 20 cm would be considered extrapolation.\nWhat is a residual?\nDifference between predicted and observed.\n\n\n\n\nModel fitting\n\nDemo: Fit a model to predict fish weights from their heights.\n\n\nfish_hw_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ height, data = fish)\n\nfish_hw_fit\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = weight ~ height, data = data)\n\nCoefficients:\n(Intercept)       height  \n    -288.42        60.92  \n\n\n\nYour turn (3 minutes): Predict what the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm using this model.\n\n\nx &lt;- c(10, 15, 20)\n-288 + 60.92 * x\n\n[1] 321.2 625.8 930.4\n\n\n\nDemo: Calculate predicted weights for all fish in the data and visualize the residuals under this model.\n\n\nfish_hw_aug &lt;- augment(fish_hw_fit, new_data = fish)\n\nggplot(fish_hw_aug, aes(x = height, y = weight)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +  \n  geom_segment(aes(xend = height, yend = .pred), color = \"gray\") +  \n  geom_point(aes(y = .pred), shape = \"circle open\") + \n  theme_minimal() +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    subtitle = \"Residuals\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nModel summary\n\nDemo: Display the model summary including estimates for the slope and intercept along with measurements of uncertainty around them. Show how you can extract these values from the model output.\n\n\nfish_hw_tidy &lt;- tidy(fish_hw_fit)\nfish_hw_tidy\n\n# A tibble: 2 √ó 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   -288.      34.0      -8.49 1.83e-11\n2 height          60.9      2.64     23.1  2.40e-29\n\n\n\nDemo: Write out your model using mathematical notation.\n\n\\(\\widehat{weight} = -288 + 60.9 \\times height\\)\n\n\nCorrelation\nWe can also assess correlation between two quantitative variables.\n\nYour turn (5 minutes):\n\nWhat is correlation? What are values correlation can take?\nStrength and direction of a linear relationship. It‚Äôs bounded by -1 and 1.\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\n\nDemo: What is the correlation between heights and weights of fish?\n\n\nfish |&gt;\n  summarize(r = cor(height, weight))\n\n# A tibble: 1 √ó 1\n      r\n  &lt;dbl&gt;\n1 0.954\n\n\n\n\nAdding a third variable\n\nDemo: Does the relationship between heights and weights of fish change if we take into consideration species? Plot two separate straight lines for the Bream and Roach species.\n\n\nggplot(fish, \n       aes(x = height, y = weight, color = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nFitting other models\n\nDemo: We can fit more models than just a straight line. Change the following code below to read method = \"loess\". What is different from the plot created before?\n\n\nggplot(fish, \n       aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "ae/ae-09-chronicle-scrape.html",
    "href": "ae/ae-09-chronicle-scrape.html",
    "title": "AE 09: Opinion articles in The Chronicle",
    "section": "",
    "text": "This will be done in the chronicle-scrape.R R script. Save the resulting data frame in the data folder."
  },
  {
    "objectID": "ae/ae-09-chronicle-scrape.html#part-1---data-scraping",
    "href": "ae/ae-09-chronicle-scrape.html#part-1---data-scraping",
    "title": "AE 09: Opinion articles in The Chronicle",
    "section": "",
    "text": "This will be done in the chronicle-scrape.R R script. Save the resulting data frame in the data folder."
  },
  {
    "objectID": "ae/ae-09-chronicle-scrape.html#part-2---data-analysis",
    "href": "ae/ae-09-chronicle-scrape.html#part-2---data-analysis",
    "title": "AE 09: Opinion articles in The Chronicle",
    "section": "Part 2 - Data analysis",
    "text": "Part 2 - Data analysis\nLet‚Äôs start by loading the packages we will need:\n\nlibrary(tidyverse)\n\n\nYour turn (1 minute): Load the data you saved into the data folder and name it chronicle.\n\n\n# add code here\n\n\nYour turn (3 minutes): Who are the most prolific authors of the 100 most recent opinion articles in The Chronicle?\n\n\n# add code here\n\n\nDemo: Draw a line plot of the number of opinion articles published per day in The Chronicle.\n\n\n# add code here\n\n\nDemo: What percent of the most recent 100 opinion articles in The Chronicle mention ‚Äúclimate‚Äù in their title?\n\n\n# add code here\n\n\nYour turn (5 minutes): What percent of the most recent 100 opinion articles in The Chronicle mention ‚Äúclimate‚Äù in their title or abstract?\n\n\n# add code here\n\n\nTime permitting: Come up with another question and try to answer it using the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-05-majors-tidying.html",
    "href": "ae/ae-05-majors-tidying.html",
    "title": "AE 05: Tidying StatSci Majors",
    "section": "",
    "text": "Our ultimate goal in this application exercise is to make the following data visualization."
  },
  {
    "objectID": "ae/ae-05-majors-tidying.html#goal",
    "href": "ae/ae-05-majors-tidying.html#goal",
    "title": "AE 05: Tidying StatSci Majors",
    "section": "",
    "text": "Our ultimate goal in this application exercise is to make the following data visualization."
  },
  {
    "objectID": "ae/ae-05-majors-tidying.html#data",
    "href": "ae/ae-05-majors-tidying.html#data",
    "title": "AE 05: Tidying StatSci Majors",
    "section": "Data",
    "text": "Data\nThe data come from the Office of the University Registrar. They make the data available as a table that you can download as a PDF, but I‚Äôve put the data exported in a CSV file for you. Let‚Äôs load that in.\n\nlibrary(tidyverse)\n\nstatsci &lt;- read_csv(\"https://sta199-s24.github.io/data/statsci.csv\")\n\nAnd let‚Äôs take a look at the data.\n\nstatsci\n\n# A tibble: 4 √ó 14\n  degree   `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019` `2020`\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Statist‚Ä¶     NA      1     NA     NA      4      4      1     NA     NA      1\n2 Statist‚Ä¶      2      2      4      1      3      6      3      4      4      1\n3 Statist‚Ä¶      2      6      1     NA      5      6      6      8      8     17\n4 Statist‚Ä¶      5      9      4     13     10     17     24     21     26     27\n# ‚Ñπ 3 more variables: `2021` &lt;dbl&gt;, `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt;"
  },
  {
    "objectID": "ae/ae-05-majors-tidying.html#pivoting",
    "href": "ae/ae-05-majors-tidying.html#pivoting",
    "title": "AE 05: Tidying StatSci Majors",
    "section": "Pivoting",
    "text": "Pivoting\n\nDemo: Pivot the statsci data frame longer such that each row represents a degree type / year combination and year and number of graduates for that year are columns in the data frame.\n\n\n# add your code here\n\n\nQuestion: What is the type of the year variable? Why? What should it be?\n\nAdd your response here.\n\nDemo: Start over with pivoting, and this time also make sure year is a numerical variable in the resulting data frame.\n\n\n# add your code here\n\n\nQuestion: What does an NA mean in this context? Hint: The data come from the university registrar, and they have records on every single graduates, there shouldn‚Äôt be anything ‚Äúunknown‚Äù to them about who graduated when.\n\nAdd your response here.\n\nDemo: Add on to your pipeline that you started with pivoting and convert NAs in n to 0s.\n\n\n# add your code here\n\n\nDemo: In our plot the degree types are BS, BS2, AB, and AB2. This information is in our dataset, in the degree column, but this column also has additional characters we don‚Äôt need. Create a new column called degree_type with levels BS, BS2, AB, and AB2 (in this order) based on degree. Do this by adding on to your pipeline from earlier.\n\n\n# add your code here\n\n\nYour turn: Now we start making our plot, but let‚Äôs not get too fancy right away. Create the following plot, which will serve as the ‚Äúfirst draft‚Äù on the way to our Goal. Do this by adding on to your pipeline from earlier.\n\n\n\n\n\n\n\n# add your code here\n\n\nYour turn: What aspects of the plot need to be updated to go from the draft you created above to the Goal plot at the beginning of this application exercise.\n\nAdd your response here.\n\nDemo: Update x-axis scale such that the years displayed go from 2011 to 2023 in increments of 2 years. Do this by adding on to your pipeline from earlier.\n\n\n# add your code here\n\n\nDemo: Update line colors using the following level / color assignments. Once again, do this by adding on to your pipeline from earlier.\n\n‚ÄúBS‚Äù = ‚Äúcadetblue4‚Äù\n‚ÄúBS2‚Äù = ‚Äúcadetblue3‚Äù\n‚ÄúAB‚Äù = ‚Äúlightgoldenrod4‚Äù\n‚ÄúAB2‚Äù = ‚Äúlightgoldenrod3‚Äù\n\n\n\n# add your code here\n\n\nYour turn: Update the plot labels (title, subtitle, x, y, and caption) and use theme_minimal(). Once again, do this by adding on to your pipeline from earlier.\n\n\n# add your code here\n\n\nDemo: Finally, adding to your pipeline you‚Äôve developed so far, move the legend into the plot, make its background white, and its border gray. Set fig-width: 7 and fig-height: 5 for your plot in the chunk options.\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-13-modeling-loans.html",
    "href": "ae/ae-13-modeling-loans.html",
    "title": "Modelling loan interest rates",
    "section": "",
    "text": "In this application exercise we will be studying loan interest rates. The dataset is one you‚Äôve come across before in your reading ‚Äì the dataset about loans from the peer-to-peer lender, Lending Club, from the openintro package. We will use tidyverse and tidymodels for data exploration and modeling, respectively.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nBefore we use the dataset, we‚Äôll make a few transformations to it.\nAdd response here.\nloans &lt;- loans_full_schema |&gt;\n  mutate(\n    credit_util = total_credit_utilized / total_credit_limit,\n    bankruptcy = as.factor(if_else(public_record_bankrupt == 0, 0, 1)),\n    verified_income = droplevels(verified_income),\n    homeownership = str_to_title(homeownership),\n    homeownership = fct_relevel(homeownership, \"Rent\", \"Mortgage\", \"Own\")\n  ) |&gt;\n  rename(credit_checks = inquiries_last_12m) |&gt;\n  select(\n    interest_rate, loan_amount, verified_income, \n    debt_to_income, credit_util, bankruptcy, term, \n    credit_checks, issue_month, homeownership\n  )\nHere is a glimpse at the data:\nglimpse(loans)\n\nRows: 10,000\nColumns: 10\n$ interest_rate   &lt;dbl&gt; 14.07, 12.61, 17.09, 6.72, 14.07, 6.72, 13.59, 11.99, ‚Ä¶\n$ loan_amount     &lt;int&gt; 28000, 5000, 2000, 21600, 23000, 5000, 24000, 20000, 2‚Ä¶\n$ verified_income &lt;fct&gt; Verified, Not Verified, Source Verified, Not Verified,‚Ä¶\n$ debt_to_income  &lt;dbl&gt; 18.01, 5.04, 21.15, 10.16, 57.96, 6.46, 23.66, 16.19, ‚Ä¶\n$ credit_util     &lt;dbl&gt; 0.54759517, 0.15003472, 0.66134832, 0.19673228, 0.7549‚Ä¶\n$ bankruptcy      &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, ‚Ä¶\n$ term            &lt;dbl&gt; 60, 36, 36, 36, 36, 36, 60, 60, 36, 36, 60, 60, 36, 60‚Ä¶\n$ credit_checks   &lt;int&gt; 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8, 6, 0, 0, 4, 6, ‚Ä¶\n$ issue_month     &lt;fct&gt; Mar-2018, Feb-2018, Feb-2018, Jan-2018, Mar-2018, Jan-‚Ä¶\n$ homeownership   &lt;fct&gt; Mortgage, Rent, Rent, Rent, Rent, Own, Mortgage, Mortg‚Ä¶"
  },
  {
    "objectID": "ae/ae-13-modeling-loans.html#main-effects-model",
    "href": "ae/ae-13-modeling-loans.html#main-effects-model",
    "title": "Modelling loan interest rates",
    "section": "Main effects model",
    "text": "Main effects model\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, without an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\n# add code here\n\nAdd response here.\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: Add response here.\nMortgage: Add response here.\nOwn: Add response here.\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nAdd response here."
  },
  {
    "objectID": "ae/ae-13-modeling-loans.html#interaction-effects-model",
    "href": "ae/ae-13-modeling-loans.html#interaction-effects-model",
    "title": "Modelling loan interest rates",
    "section": "Interaction effects model",
    "text": "Interaction effects model\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, with an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\n# add code here\n\nAdd response here.\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: Add response here.\nMortgage: Add response here.\nOwn: Add response here.\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nAdd response here."
  },
  {
    "objectID": "ae/ae-13-modeling-loans.html#choosing-a-model",
    "href": "ae/ae-13-modeling-loans.html#choosing-a-model",
    "title": "Modelling loan interest rates",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam‚Äôs Razor - Don‚Äôt overcomplicate the situation! We prefer the simplest best model.\n\n# add code here\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nAdd response here.\n\nQuestion: Based on the adjusted \\(R^2\\)s of these two models, which one do we prefer?\n\nAdd response here."
  },
  {
    "objectID": "ae/ae-04-flights-wrangling-A.html",
    "href": "ae/ae-04-flights-wrangling-A.html",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it‚Äôs not designed to be an exhaustive key.\nlibrary(tidyverse)\nlibrary(nycflights13)"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling-A.html#exercise-1",
    "href": "ae/ae-04-flights-wrangling-A.html#exercise-1",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 1",
    "text": "Exercise 1\nYour turn: Fill in the blanks:\nThe flights data frame has 336776 rows. Each row represents a _flight_."
  },
  {
    "objectID": "ae/ae-04-flights-wrangling-A.html#exercise-2",
    "href": "ae/ae-04-flights-wrangling-A.html#exercise-2",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 2",
    "text": "Exercise 2\nYour turn: What are the names of the variables in flights.\n\nnames(flights)\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\""
  },
  {
    "objectID": "ae/ae-04-flights-wrangling-A.html#exercise-3---select",
    "href": "ae/ae-04-flights-wrangling-A.html#exercise-3---select",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 3 - select()",
    "text": "Exercise 3 - select()\n\nDemo: Make a data frame that only contains the variables dep_delay and arr_delay.\n\n\nflights |&gt;\n  select(dep_delay, arr_delay)\n\n# A tibble: 336,776 √ó 2\n   dep_delay arr_delay\n       &lt;dbl&gt;     &lt;dbl&gt;\n 1         2        11\n 2         4        20\n 3         2        33\n 4        -1       -18\n 5        -6       -25\n 6        -4        12\n 7        -5        19\n 8        -3       -14\n 9        -3        -8\n10        -2         8\n# ‚Ñπ 336,766 more rows\n\n\n\nDemo: Make a data frame that keeps every variable except dep_delay.\n\n\nflights |&gt;\n  select(-dep_delay)\n\n# A tibble: 336,776 √ó 18\n    year month   day dep_time sched_dep_time arr_time sched_arr_time arr_delay\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     1      517            515      830            819        11\n 2  2013     1     1      533            529      850            830        20\n 3  2013     1     1      542            540      923            850        33\n 4  2013     1     1      544            545     1004           1022       -18\n 5  2013     1     1      554            600      812            837       -25\n 6  2013     1     1      554            558      740            728        12\n 7  2013     1     1      555            600      913            854        19\n 8  2013     1     1      557            600      709            723       -14\n 9  2013     1     1      557            600      838            846        -8\n10  2013     1     1      558            600      753            745         8\n# ‚Ñπ 336,766 more rows\n# ‚Ñπ 10 more variables: carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;,\n#   origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;,\n#   minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\nDemo: Make a data frame that includes all variables between year through dep_delay (inclusive). These are all variables that provide information about the departure of each flight.\n\n\nflights |&gt;\n  select(year:dep_delay)\n\n# A tibble: 336,776 √ó 6\n    year month   day dep_time sched_dep_time dep_delay\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     1      517            515         2\n 2  2013     1     1      533            529         4\n 3  2013     1     1      542            540         2\n 4  2013     1     1      544            545        -1\n 5  2013     1     1      554            600        -6\n 6  2013     1     1      554            558        -4\n 7  2013     1     1      555            600        -5\n 8  2013     1     1      557            600        -3\n 9  2013     1     1      557            600        -3\n10  2013     1     1      558            600        -2\n# ‚Ñπ 336,766 more rows\n\n\n\nDemo: Use the select helper contains() to make a data frame that includes the variables associated with the arrival, i.e., contains the string \"arr\\_\" in the name.\n\n\nflights |&gt;\n  select(contains(\"arr_\"))\n\n# A tibble: 336,776 √ó 3\n   arr_time sched_arr_time arr_delay\n      &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1      830            819        11\n 2      850            830        20\n 3      923            850        33\n 4     1004           1022       -18\n 5      812            837       -25\n 6      740            728        12\n 7      913            854        19\n 8      709            723       -14\n 9      838            846        -8\n10      753            745         8\n# ‚Ñπ 336,766 more rows"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling-A.html#exercise-4---slice",
    "href": "ae/ae-04-flights-wrangling-A.html#exercise-4---slice",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 4 - slice()",
    "text": "Exercise 4 - slice()\n\nDemo: Display the first five rows of the flights data frame.\n\n\nflights |&gt;\n  slice(1:5)\n\n# A tibble: 5 √ó 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n# ‚Ñπ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\nDemo: Display the last two rows of the flights data frame.\n\n\nflights |&gt;\n  slice((n()-1):n())\n\n# A tibble: 2 √ó 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     9    30       NA           1159        NA       NA           1344\n2  2013     9    30       NA            840        NA       NA           1020\n# ‚Ñπ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling-A.html#exercise-5---arrange",
    "href": "ae/ae-04-flights-wrangling-A.html#exercise-5---arrange",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 5 - arrange()",
    "text": "Exercise 5 - arrange()\n\nDemo: Let‚Äôs arrange the data by departure delay, so the flights with the shortest departure delays will be at the top of the data frame.\n\n\nflights |&gt;\n  arrange(dep_delay)\n\n# A tibble: 336,776 √ó 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    12     7     2040           2123       -43       40           2352\n 2  2013     2     3     2022           2055       -33     2240           2338\n 3  2013    11    10     1408           1440       -32     1549           1559\n 4  2013     1    11     1900           1930       -30     2233           2243\n 5  2013     1    29     1703           1730       -27     1947           1957\n 6  2013     8     9      729            755       -26     1002            955\n 7  2013    10    23     1907           1932       -25     2143           2143\n 8  2013     3    30     2030           2055       -25     2213           2250\n 9  2013     3     2     1431           1455       -24     1601           1631\n10  2013     5     5      934            958       -24     1225           1309\n# ‚Ñπ 336,766 more rows\n# ‚Ñπ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\nQuestion: What does it mean for the dep_delay to have a negative value?\n\nArrived early.\n\nDemo: Arrange the data by descending departure delay, so the flights with the longest departure delays will be at the top.\n\n\nflights |&gt;\n  arrange(desc(dep_delay))\n\n# A tibble: 336,776 √ó 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     9      641            900      1301     1242           1530\n 2  2013     6    15     1432           1935      1137     1607           2120\n 3  2013     1    10     1121           1635      1126     1239           1810\n 4  2013     9    20     1139           1845      1014     1457           2210\n 5  2013     7    22      845           1600      1005     1044           1815\n 6  2013     4    10     1100           1900       960     1342           2211\n 7  2013     3    17     2321            810       911      135           1020\n 8  2013     6    27      959           1900       899     1236           2226\n 9  2013     7    22     2257            759       898      121           1026\n10  2013    12     5      756           1700       896     1058           2020\n# ‚Ñπ 336,766 more rows\n# ‚Ñπ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\nYour turn: Create a data frame that only includes the plane tail number (tailnum), carrier (carrier), and departure delay for the flight with the longest departure delay. What is the plane tail number (tailnum) for this flight?\n\n\nflights |&gt;\n  select(tailnum, carrier, dep_delay) %&gt;%\n  arrange(dep_delay) |&gt;\n  slice(1)\n\n# A tibble: 1 √ó 3\n  tailnum carrier dep_delay\n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;\n1 N592JB  B6            -43"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling-A.html#exercise-6---filter",
    "href": "ae/ae-04-flights-wrangling-A.html#exercise-6---filter",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 6 - filter()",
    "text": "Exercise 6 - filter()\n\nDemo: Filter the data frame by selecting the rows where the destination airport is RDU.\n\n\nflights |&gt;\n  filter(dest == \"RDU\")\n\n# A tibble: 8,163 √ó 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      800            810       -10      949            955\n 2  2013     1     1      832            840        -8     1006           1030\n 3  2013     1     1      851            851         0     1032           1036\n 4  2013     1     1      917            920        -3     1052           1108\n 5  2013     1     1     1024           1030        -6     1204           1215\n 6  2013     1     1     1127           1129        -2     1303           1309\n 7  2013     1     1     1157           1205        -8     1342           1345\n 8  2013     1     1     1240           1235         5     1415           1415\n 9  2013     1     1     1317           1325        -8     1454           1505\n10  2013     1     1     1449           1450        -1     1651           1640\n# ‚Ñπ 8,153 more rows\n# ‚Ñπ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\nDemo: We can also filter using more than one condition. Here we select all rows where the destination airport is RDU and the arrival delay is less than 0.\n\n\nflights |&gt;\n  filter(dest == \"RDU\", arr_delay &lt; 0)\n\n# A tibble: 4,232 √ó 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      800            810       -10      949            955\n 2  2013     1     1      832            840        -8     1006           1030\n 3  2013     1     1      851            851         0     1032           1036\n 4  2013     1     1      917            920        -3     1052           1108\n 5  2013     1     1     1024           1030        -6     1204           1215\n 6  2013     1     1     1127           1129        -2     1303           1309\n 7  2013     1     1     1157           1205        -8     1342           1345\n 8  2013     1     1     1317           1325        -8     1454           1505\n 9  2013     1     1     1505           1510        -5     1654           1655\n10  2013     1     1     1800           1800         0     1945           1951\n# ‚Ñπ 4,222 more rows\n# ‚Ñπ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\nYour turn: Describe what the code is doing in words.\n\n\nflights |&gt;\n  filter(\n    dest %in% c(\"RDU\", \"GSO\"),\n    arr_delay &lt; 0 | dep_delay &lt; 0\n    )\n\n# A tibble: 6,203 √ó 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      800            810       -10      949            955\n 2  2013     1     1      832            840        -8     1006           1030\n 3  2013     1     1      851            851         0     1032           1036\n 4  2013     1     1      917            920        -3     1052           1108\n 5  2013     1     1     1024           1030        -6     1204           1215\n 6  2013     1     1     1127           1129        -2     1303           1309\n 7  2013     1     1     1157           1205        -8     1342           1345\n 8  2013     1     1     1317           1325        -8     1454           1505\n 9  2013     1     1     1449           1450        -1     1651           1640\n10  2013     1     1     1505           1510        -5     1654           1655\n# ‚Ñπ 6,193 more rows\n# ‚Ñπ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nHint: Logical operators in R:\n\n\n\n\n\n\n\noperator\ndefinition\n\n\n\n\n&lt;\nis less than?\n\n\n&lt;=\nis less than or equal to?\n\n\n&gt;\nis greater than?\n\n\n&gt;=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?\n\n\nx & y\nis x AND y?\n\n\nx \\| y\nis x OR y?\n\n\nis.na(x)\nis x NA?\n\n\n!is.na(x)\nis x not NA?\n\n\nx %in% y\nis x in y?\n\n\n!(x %in% y)\nis x not in y?\n\n\n!x\nis not x? (only makes sense if x is TRUE or FALSE)"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling-A.html#exercise-7---count",
    "href": "ae/ae-04-flights-wrangling-A.html#exercise-7---count",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 7 - count()",
    "text": "Exercise 7 - count()\n\nDemo: Create a frequency table of the destination locations for flights from New York.\n\n\nflights |&gt;\n  count(dest)\n\n# A tibble: 105 √ó 2\n   dest      n\n   &lt;chr&gt; &lt;int&gt;\n 1 ABQ     254\n 2 ACK     265\n 3 ALB     439\n 4 ANC       8\n 5 ATL   17215\n 6 AUS    2439\n 7 AVL     275\n 8 BDL     443\n 9 BGR     375\n10 BHM     297\n# ‚Ñπ 95 more rows\n\n\n\nDemo: In which month was there the fewest number of flights? How many flights were there in that month?\n\n\nflights |&gt;\n  count(month) |&gt;\n  filter(n == min(n))\n\n# A tibble: 1 √ó 2\n  month     n\n  &lt;int&gt; &lt;int&gt;\n1     2 24951\n\n\n\nYour turn: On which date (month + day) was there the largest number of flights? How many flights were there on that day?\n\n\nflights |&gt;\n  count(month, day) |&gt;\n  filter(n == max(n))\n\n# A tibble: 1 √ó 3\n  month   day     n\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    11    27  1014"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling-A.html#exercise-8---mutate",
    "href": "ae/ae-04-flights-wrangling-A.html#exercise-8---mutate",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 8 - mutate()",
    "text": "Exercise 8 - mutate()\n\nDemo: Convert air_time (minutes in the air) to hours and then create a new variable, mph, the miles per hour of the flight.\n\n\nflights |&gt;\n  mutate(\n    hours = air_time / 60,\n    mph = distance / hours\n    ) |&gt;\n  select(air_time, distance, hours, mph)\n\n# A tibble: 336,776 √ó 4\n   air_time distance hours   mph\n      &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1      227     1400 3.78   370.\n 2      227     1416 3.78   374.\n 3      160     1089 2.67   408.\n 4      183     1576 3.05   517.\n 5      116      762 1.93   394.\n 6      150      719 2.5    288.\n 7      158     1065 2.63   404.\n 8       53      229 0.883  259.\n 9      140      944 2.33   405.\n10      138      733 2.3    319.\n# ‚Ñπ 336,766 more rows\n\n\n\nYour turn: Create a new variable to calculate the percentage of flights in each month. What percentage of flights take place in July?\n\n\nflights |&gt;\n  count(month) |&gt;\n  mutate(perc = n / sum(n) * 100)\n\n# A tibble: 12 √ó 3\n   month     n  perc\n   &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n 1     1 27004  8.02\n 2     2 24951  7.41\n 3     3 28834  8.56\n 4     4 28330  8.41\n 5     5 28796  8.55\n 6     6 28243  8.39\n 7     7 29425  8.74\n 8     8 29327  8.71\n 9     9 27574  8.19\n10    10 28889  8.58\n11    11 27268  8.10\n12    12 28135  8.35\n\n\n\nDemo: Create a new variable, rdu_bound, which indicates whether the flight is to RDU or not. Then, for each departure airport (origin), calculate what proportion of flights originating from that airport are to RDU.\n\n\nflights |&gt;\n  mutate(rdu_bound = if_else(dest == \"RDU\", \"Yes\", \"No\")) |&gt;\n  count(origin, rdu_bound) |&gt;\n  group_by(origin) |&gt;\n  mutate(prop = n / sum(n)) |&gt;\n  filter(rdu_bound == \"Yes\")\n\n# A tibble: 3 √ó 4\n# Groups:   origin [3]\n  origin rdu_bound     n   prop\n  &lt;chr&gt;  &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;\n1 EWR    Yes        1482 0.0123\n2 JFK    Yes        3100 0.0279\n3 LGA    Yes        3581 0.0342"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling-A.html#exercise-9---summarize",
    "href": "ae/ae-04-flights-wrangling-A.html#exercise-9---summarize",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 9 - summarize()",
    "text": "Exercise 9 - summarize()\n\nDemo: Find mean arrival delay for all flights.\n\n\nflights |&gt;\n  summarize(mean_dep_delay = mean(dep_delay))\n\n# A tibble: 1 √ó 1\n  mean_dep_delay\n           &lt;dbl&gt;\n1             NA"
  },
  {
    "objectID": "ae/ae-04-flights-wrangling-A.html#exercise-10---group_by",
    "href": "ae/ae-04-flights-wrangling-A.html#exercise-10---group_by",
    "title": "AE 04: NYC flights + data wrangling",
    "section": "Exercise 10 - group_by()",
    "text": "Exercise 10 - group_by()\n\nDemo: Find mean arrival delay for for each month.\n\n\nflights |&gt;\n  group_by(month) |&gt;\n  summarize(mean_arr_delay = mean(arr_delay, na.rm = TRUE))\n\n# A tibble: 12 √ó 2\n   month mean_arr_delay\n   &lt;int&gt;          &lt;dbl&gt;\n 1     1          6.13 \n 2     2          5.61 \n 3     3          5.81 \n 4     4         11.2  \n 5     5          3.52 \n 6     6         16.5  \n 7     7         16.7  \n 8     8          6.04 \n 9     9         -4.02 \n10    10         -0.167\n11    11          0.461\n12    12         14.9  \n\n\n\nYour turn: What is the median departure delay for each airports around NYC (origin)? Which airport has the shortest median departure delay?\n\n\nflights |&gt;\n  group_by(origin) |&gt;\n  summarize(med_dep_delay = median(dep_delay, na.rm = TRUE))\n\n# A tibble: 3 √ó 2\n  origin med_dep_delay\n  &lt;chr&gt;          &lt;dbl&gt;\n1 EWR               -1\n2 JFK               -1\n3 LGA               -3"
  },
  {
    "objectID": "ae/ae-12-modeling-penguins-multi.html",
    "href": "ae/ae-12-modeling-penguins-multi.html",
    "title": "AE 12: Modeling penguins with multiple predictors",
    "section": "",
    "text": "In this application exercise we will be studying penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\nPlease read the following context and take a glimpse at the data set before we get started.\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\nOur goal is to understand better how various body measurements and attributes of penguins relate to their body mass."
  },
  {
    "objectID": "ae/ae-12-modeling-penguins-multi.html#additive-vs.-interaction-models",
    "href": "ae/ae-12-modeling-penguins-multi.html#additive-vs.-interaction-models",
    "title": "AE 12: Modeling penguins with multiple predictors",
    "section": "Additive vs.¬†interaction models",
    "text": "Additive vs.¬†interaction models\n\nYour turn: Run the two chunks of code below and create two separate plots. How are the two plots different than each other? Which plot does the model we fit above represent?\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\nRemoved 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nAdd response here.\n\nYour turn: Interpret the slope coefficient for flipper length in the context of the data and the research question.\n\nAdd response here.\n\nDemo: Predict the body mass of a Dream island penguin with a flipper length of 200 mm.\n\n\n# add code here\n\n\nReview: Look back at Plot B. What assumption does the additive model make about the slopes between flipper length and body mass for each of the three islands?\n\nThe additive model assumes the same slope between body mass and flipper length for all three islands.\n\nDemo: Now fit the interaction model represented in Plot A and write the estimated regression model.\n\n\n# add code here\n\n\\[\nadd~math~text~here\n\\]\n\nReview: What does modeling body mass with an interaction effect get us that without doing so does not?\n\nThe interaction effect allows us to model the rate of change in estimated body mass as flipper length increases as different in the three islands.\n\nYour turn: Predict the body mass of a Dream island penguin with a flipper length of 200 mm.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-12-modeling-penguins-multi.html#choosing-a-model",
    "href": "ae/ae-12-modeling-penguins-multi.html#choosing-a-model",
    "title": "AE 12: Modeling penguins with multiple predictors",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam‚Äôs Razor - Don‚Äôt overcomplicate the situation! We prefer the simplest best model.\n\n# add code here\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables)."
  },
  {
    "objectID": "ae/ae-07-population-types.html",
    "href": "ae/ae-07-population-types.html",
    "title": "AE 07: Types and classes and populations",
    "section": "",
    "text": "We will use the following two packages in this application exercise.\n\ntidyverse: For data import, wrangling, and visualization.\nscales: For better axis labels.\n\n\nlibrary(tidyverse)\nlibrary(scales)"
  },
  {
    "objectID": "ae/ae-07-population-types.html#packages",
    "href": "ae/ae-07-population-types.html#packages",
    "title": "AE 07: Types and classes and populations",
    "section": "",
    "text": "We will use the following two packages in this application exercise.\n\ntidyverse: For data import, wrangling, and visualization.\nscales: For better axis labels.\n\n\nlibrary(tidyverse)\nlibrary(scales)"
  },
  {
    "objectID": "ae/ae-07-population-types.html#type-coercion",
    "href": "ae/ae-07-population-types.html#type-coercion",
    "title": "AE 07: Types and classes and populations",
    "section": "Type coercion",
    "text": "Type coercion\n\nDemo: Determine the type of the following vector. And then, change the type to numeric.\n\n\nx &lt;- c(\"1\", \"2\", \"3\")\n\n# add code here\n\n\nDemo: Once again, determine the type of the following vector. And then, change the type to numeric. What‚Äôs different than the previous exercise?\n\n\ny &lt;- c(\"a\", \"b\", \"c\")\n\n# add code here\n\n\nDemo: Once again, determine the type of the following vector. And then, change the type to numeric. What‚Äôs different than the previous exercise?\n\n\nz &lt;- c(\"1\", \"2\", \"three\")\n\n# add code here\n\n\nDemo: Suppose you conducted a survey where you asked people how many cars their household owns collectively. And the answers are as follows:\n\n\nsurvey_results &lt;- tibble(cars = c(1, 2, \"three\"))\nsurvey_results\n\n# A tibble: 3 √ó 1\n  cars \n  &lt;chr&gt;\n1 1    \n2 2    \n3 three\n\n\nThis is annoying because of that third survey taker who just had to go and type out the number instead of providing as a numeric value. So now you need to update the cars variable to be numeric. You do the following:\n\n# add code here\n\nAnd now things are even more annoying because you get a warning NAs introduced by coercion that happened while computing cars = as.numeric(cars) and the response from the third survey taker is now an NA (you lost their data). Fix your mutate() call to avoid this warning.\n\n# add code here\n\n\nYour turn: First, guess the type of the vector. Then, check if you guessed right. I‚Äôve done the first one for you, you‚Äôll see that it‚Äôs helpful to check the type of each element of the vector first.\n\nc(1, 1L, \"C\")\n\n\n\nv1 &lt;- c(1, 1L, \"C\")\n\n# to help you guess\ntypeof(1)\n\n[1] \"double\"\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(\"C\")\n\n[1] \"character\"\n\n# to check after you guess\ntypeof(v1)\n\n[1] \"character\"\n\n\n-   `c(1L / 0, \"A\")`\n\nv2 &lt;- c(1L / 0, \"A\")\n\n# to help you guess\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(0)\n\n[1] \"double\"\n\ntypeof(1L / 0)\n\n[1] \"double\"\n\ntypeof(\"A\")\n\n[1] \"character\"\n\n# to check after you guess\ntypeof(v2)\n\n[1] \"character\"\n\n\n- `c(1:3, 5)`\n\nv3 &lt;- c(1:3, 5)\n\n# to help you guess\n\n# add code here\n\n# to check after you guess\n\n# add code here\n\n-   `c(3, \"3+\")`\n\nv4 &lt;- c(3, \"3+\")\n\n# to help you guess\n\n# add code here\n\n# to check after you guess\n\n# add code here\n\n-   `c(NA, TRUE)`\n\nv5 &lt;- c(NA, TRUE)\n\n# to help you guess\n\n# add code here\n\n# to check after you guess\n\n# add code here"
  },
  {
    "objectID": "ae/ae-07-population-types.html#populations-in-continents",
    "href": "ae/ae-07-population-types.html#populations-in-continents",
    "title": "AE 07: Types and classes and populations",
    "section": "Populations in continents",
    "text": "Populations in continents\nIn the previous application exercise you joined two datasets (after a bit of data cleaning), and calculated total population in each continent and visualized it.\n\nFirst, you loaded the data:\n\n\ncontinents &lt;- read_csv(\"https://sta199-s24.github.io/data/continents.csv\")\n\nRows: 285 Columns: 4\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): entity, code, continent\ndbl (1): year\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npopulation &lt;- read_csv(\"https://sta199-s24.github.io/data/world-pop-2022.csv\")\n\nRows: 217 Columns: 3\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): country\ndbl (2): year, population\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nThen you cleaned the country names where the spelling in one data frame didn‚Äôt match the other, and joined the data sets:\n\n\npopulation_continent &lt;- population |&gt;\n  mutate(country = case_when(\n    country == \"Congo, Dem. Rep.\" ~ \"Democratic Republic of Congo\",\n    country == \"Congo, Rep.\" ~ \"Congo\",\n    country == \"Hong Kong SAR, China\" ~ \"Hong Kong\",\n    country == \"Korea, Dem. People's Rep.\" ~ \"North Korea\",\n    country == \"Korea, Rep.\" ~ \"South Korea\",\n    country == \"Kyrgyz Republic\" ~ \"Kyrgyzstan\",\n    .default = country\n    )\n  ) |&gt;\n  left_join(continents, by = join_by(country == entity))\n\n\nThen, you calculated total population for each continent.\n\n\npopulation_summary &lt;- population_continent |&gt;\n  group_by(continent) |&gt;\n  summarize(total_pop = sum(population)) |&gt;\n  arrange(desc(total_pop))\n\n\nAnd finally, you visualized these data.\n\n\nggplot(population_summary) +\n  geom_point(aes(x = total_pop, y = continent)) +\n  geom_segment(aes(y = continent, yend = continent, x = 0, xend = total_pop)) +\n  scale_x_continuous(labels = label_number(scale = 1/1000000, suffix = \" bil\")) +\n  theme_minimal() +\n  labs(\n    x = \"Total population\",\n    y = \"Continent\",\n    title = \"World population\",\n    subtitle = \"As of 2022\",\n    caption = \"Data sources: The World Bank and Our World in Data\"\n  )\n\n\n\n\n\n\n\n\n\nQuestion: Take a look at the visualization. How are the continents ordered? What would be a better order?\n\nAdd answer here.\n\nDemo: Reorder the continents on the y-axis (levels of continent) in order of value of total population. You will want to use a function from the forcats package, see https://forcats.tidyverse.org/reference/index.html for inspiration and help.\n\n\n# add code here\n\n\nThink out loud: Describe what is happening in the each step of the code chunk above.\n\nAdd answer here."
  },
  {
    "objectID": "ae/ae-03-duke-forest-A.html",
    "href": "ae/ae-03-duke-forest-A.html",
    "title": "AE 03: Duke Forest",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it‚Äôs not designed to be an exhaustive key.\n\n\n\nPackages\n\nlibrary(tidyverse)\nlibrary(openintro)\n\n\n\nExercise 1\nThe distributions of prices of houses with and without garages are fairly similar, with centers around $600,000. Each distribution has potential outliers on the higher end. Based on this visualization, having a garage does not appear to ‚Äúmake a difference‚Äù.\n\nduke_forest |&gt;\n  mutate(garage = if_else(str_detect(parking, \"Garage\"), \"Garage\", \"No garage\")) |&gt;\n  ggplot(aes(x = price, fill = garage)) +\n  geom_histogram() +\n  facet_wrap(~garage, ncol = 1) +\n  labs(\n    x = \"Price in $\",\n    y = \"\",\n    title = \"Histogram of Price of Homes by Garage or not\",\n    fill = \"Garage or not\"\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\nClaim 1: Yes, there seems to be evidence of a positive relationship between the price of the home and the area of the home.\nClaim 2: No, there does not seem to be a relationship between the price and age of the home.\nClaim 3: No, there does not seem to be any evidence to suggest that larger more expensive homes are newer than those houses that are cheaper and smaller. Points that are lighter colored (newer homes) are not concentrated on the top right of the plot.\n\n\nggplot(\n  duke_forest,\n  aes(x = area, y = price, color = year_built)\n) +\n  geom_point(size = 3) +\n  geom_smooth(se = FALSE) +\n  labs(\n    x = \"Area of Home\",\n    y = \"Price of Home\",\n    title = \"Relationship between Price and Area by Year Built\",\n    color = \"Year Built\"\n  )\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: colour\n‚Ñπ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\n‚Ñπ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?"
  },
  {
    "objectID": "ae/ae-10-modeling-fish.html",
    "href": "ae/ae-10-modeling-fish.html",
    "title": "Modelling fish",
    "section": "",
    "text": "For this application exercise, we will work with data on fish. The dataset we will use, called fish, is on two common fish species in fish market sales.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nfish &lt;- read_csv(\"data/fish.csv\")\n\nThe data dictionary is below:\n\n\n\nvariable\ndescription\n\n\n\n\nspecies\nSpecies name of fish\n\n\nweight\nWeight, in grams\n\n\nlength_vertical\nVertical length, in cm\n\n\nlength_diagonal\nDiagonal length, in cm\n\n\nlength_cross\nCross length, in cm\n\n\nheight\nHeight, in cm\n\n\nwidth\nDiagonal width, in cm\n\n\n\n\nVisualizing the model\nWe‚Äôre going to investigate the relationship between the weights and heights of fish.\n\nDemo: Create an appropriate plot to investigate this relationship. Add appropriate labels to the plot.\n\n\n# add code here\n\n\nYour turn (5 minutes):\n\nIf you were to draw a a straight line to best represent the relationship between the heights and weights of fish, where would it go? Why?\nAdd response here.\nNow, let R draw the line for you. Refer to the documentation at https://ggplot2.tidyverse.org/reference/geom_smooth.html. Specifically, refer to the method section.\n\n\n# add code here\n\n\nWhat types of questions can this plot help answer?\n\nAdd response here.\nYour turn (3 minutes):\n\nWe can use this line to make predictions. Predict what you think the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm. Which prediction is considered extrapolation?\n\nAdd response here.\n\nWhat is a residual?\n\nAdd response here.\n\n\n\nModel fitting\n\nDemo: Fit a model to predict fish weights from their heights.\n\n\n# add code here\n\n\nYour turn (3 minutes): Predict what the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm using this model.\n\n\n# add code here\n\n\nDemo: Calculate predicted weights for all fish in the data and visualize the residuals under this model.\n\n\n# add code here\n\n\n\nModel summary\n\nDemo: Display the model summary including estimates for the slope and intercept along with measurements of uncertainty around them. Show how you can extract these values from the model output.\n\n\n# add code here\n\n\nDemo: Write out your model using mathematical notation.\n\nAdd response here.\n\n\nCorrelation\nWe can also assess correlation between two quantitative variables.\n\nYour turn (5 minutes):\n\nWhat is correlation? What are values correlation can take?\n\nAdd response here.\n\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\n\nDemo: What is the correlation between heights and weights of fish?\n\n\n# add code here\n\n\n\nAdding a third variable\n\nDemo: Does the relationship between heights and weights of fish change if we take into consideration species? Plot two separate straight lines for the Bream and Roach species.\n\n\n# add code here\n\n\n\nFitting other models\n\nDemo: We can fit more models than just a straight line. Change the following code below to read method = \"loess\". What is different from the plot created before?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-00-unvotes.html",
    "href": "ae/ae-00-unvotes.html",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\n\n\n\n\nThe data we‚Äôre using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes &lt;- un_votes |&gt;\n  inner_join(un_roll_calls, by = \"rcid\") |&gt;\n  inner_join(un_roll_call_issues, by = \"rcid\", relationship =\n  \"many-to-many\")"
  },
  {
    "objectID": "ae/ae-00-unvotes.html#introduction",
    "href": "ae/ae-00-unvotes.html#introduction",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\n\n\n\n\nThe data we‚Äôre using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes &lt;- un_votes |&gt;\n  inner_join(un_roll_calls, by = \"rcid\") |&gt;\n  inner_join(un_roll_call_issues, by = \"rcid\", relationship =\n  \"many-to-many\")"
  },
  {
    "objectID": "ae/ae-00-unvotes.html#un-voting-patterns",
    "href": "ae/ae-00-unvotes.html#un-voting-patterns",
    "title": "UN Votes",
    "section": "UN voting patterns",
    "text": "UN voting patterns\nLet‚Äôs create a data visualisation that displays how the voting record of the UK & NI changed over time on a variety of issues, and compares it to two other countries: US and Turkey.\nWe can easily change which countries are being plotted by changing which countries the code above filters for. Note that the country name should be spelled and capitalized exactly the same way as it appears in the data. See the Appendix for a list of the countries in the data.\n\nunvotes |&gt;\n  filter(country %in% c(\"United Kingdom\", \"United States\", \"Turkey\")) |&gt;\n  mutate(year = year(date)) |&gt;\n  group_by(country, year, issue) |&gt;\n  summarize(percent_yes = mean(vote == \"yes\")) |&gt;\n  ggplot(mapping = aes(x = year, y = percent_yes, color = country)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  facet_wrap(~issue) +\n  scale_y_continuous(labels = percent) +\n  labs(\n    title = \"Percentage of 'Yes' votes in the UN General Assembly\",\n    subtitle = \"1946 to 2019\",\n    y = \"% Yes\",\n    x = \"Year\",\n    color = \"Country\"\n  )"
  },
  {
    "objectID": "ae/ae-00-unvotes.html#references",
    "href": "ae/ae-00-unvotes.html#references",
    "title": "UN Votes",
    "section": "References",
    "text": "References\n\nDavid Robinson (2017). unvotes: United Nations General Assembly Voting Data. R package version 0.2.0.\nErik Voeten ‚ÄúData and Analyses of Voting in the UN General Assembly‚Äù Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013).\nMuch of the analysis has been modeled on the examples presented in the unvotes package vignette."
  },
  {
    "objectID": "ae/ae-00-unvotes.html#appendix",
    "href": "ae/ae-00-unvotes.html#appendix",
    "title": "UN Votes",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of countries in the dataset:"
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "",
    "text": "All books are freely available online.\n\nR for Data Science, 2e, Wickham, √áetinkaya-Rundel, Grolemund. O‚ÄôReilly, 2nd edition, 2023. Hard copy available on Amazon.\nIntroduction to Modern Statistics, √áetinkaya-Rundel, Hardin. OpenIntro Inc., 2nd Edition, 2023. Hard copy of 1st edition available on Amazon, 2nd edition currently only available online. (Either edition will work for this course.)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "",
    "text": "All books are freely available online.\n\nR for Data Science, 2e, Wickham, √áetinkaya-Rundel, Grolemund. O‚ÄôReilly, 2nd edition, 2023. Hard copy available on Amazon.\nIntroduction to Modern Statistics, √áetinkaya-Rundel, Hardin. OpenIntro Inc., 2nd Edition, 2023. Hard copy of 1st edition available on Amazon, 2nd edition currently only available online. (Either edition will work for this course.)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-learning-objectives",
    "href": "course-syllabus.html#course-learning-objectives",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will‚Ä¶\n\nlearn to explore, visualize, and analyze data in a reproducible and shareable manner using R and RStudio\ngain experience in data wrangling and munging, exploratory data analysis, predictive modeling, and data visualization\nwork on problems and case studies inspired by and based on real-world questions and data\nlearn to effectively communicate results through written assignments and project presentation",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-community",
    "href": "course-syllabus.html#course-community",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Course community",
    "text": "Course community\n\nDuke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course.\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke‚Äôs Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. Please update your gender pronouns in Duke Hub. You can learn more at the Center for Sexual and Gender Diversity‚Äôs website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website: sta199-s24.github.io.\nAnnouncements will be emailed through Canvas Announcements periodically. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on ed, the course discussion forum. There is a chance another student has already asked a similar question, so please check the other posts on the forum before adding a new question. If you know the answer to a question, I encourage you to respond!\n\nCheck out the Help tab for more resources.\n\n\nEmail\nIf there is a question that‚Äôs not appropriate for the public forum, you are welcome to email me directly. If you email me, please include ‚ÄúSTA 199‚Äù in the subject line. Barring extenuating circumstances, I will respond to STA 199 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#lectures-and-labs",
    "href": "course-syllabus.html#lectures-and-labs",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nLectures and labs are designed to be interactive, so you gain experience applying new concepts and learning from each other. My role as instructor is to introduce you to new methods, tools, and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to prepare for class by completing assigned readings, attend all lecture and lab sessions, and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded based on completing what we do in class.\nYou are expected to bring a laptop, tablet, or Chromebook to each class so that you can participate in the in-class exercises. Please make sure your device is fully charged before you come to class, as the number of outlets in the classroom will not be sufficient to accommodate everyone.\nLectures will be recorded and posted on Panopto (link to be shared when available) however lecture attendance is mandatory. The recordings are for catching up with classes you miss due to illness, etc. You will not get the most out of this class if you‚Äôre not present and actively participating in it ‚Äì this is true for lectures and labs.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#teams",
    "href": "course-syllabus.html#teams",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Teams",
    "text": "Teams\nYou will be assigned to a team early on in the semester. You are encouraged to sit with your teammates in lecture and you will also work with them in some of the lab sessions. All team members are expected to contribute equally to the completion of the project, and you will be asked to evaluate your team members throughout the semester. Failure to adequately contribute to any component of the project will result in a penalty to your mark relative to the team‚Äôs overall mark.\nYou are expected to make use of the provided GitHub repository as the central collaborative platform. Commits to this repository will be used as a metric (one of several) of each team member‚Äôs relative contribution for each project.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#activities-assessment",
    "href": "course-syllabus.html#activities-assessment",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nYou will be assessed based on five components: application exercises, labs, exams, project, and teamwork.\n\nApplication exercises\nParts of some lectures will be dedicated to working on Application Exercises (AEs). These exercises which give you an opportunity to practice apply the statistical concepts and code introduced in the prepare assignment. These AEs are due by the end of the week of the corresponding lecture period (Sunday at midnight). To submit the AEs all you need to do is to push your work to your GitHub repo.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nLabs\nIn labs, you will apply what you‚Äôve learned in the videos and during lectures to complete data analysis tasks. You may discuss lab assignments with other students; however, lab should be completed and submitted individually. Lab assignments must be typed up using Quarto, all work must be pushed to your GitHub repository for the lab, and the PDF output of the lab must be submitted on Gradescope by the deadline.\nLabs are due at 8 am ET on the indicated due date (generally the Monday after the lab).\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nExams\nThere will be two exams in this course. Each exam will include an in-class component (with a cheat sheet) and an open-note take-home component. Through these exams you have the opportunity to demonstrate what you‚Äôve learned in the course thus far. The exams will focus on both conceptual understanding of the content and application through analysis and computational tasks. The content of the exam will be related to the content in videos and reading assignments, lectures, application exercises, and labs.\nMore detail about the exams will be given during the semester.\n\n\nProject\nThe purpose of the project is to apply what you‚Äôve learned throughout the semester to analyze an interesting data-driven research question. The project will be completed with in teams, and each team will present their work in the last lab session of the semester. The write-up will be due on the same day.\nYou cannot pass this course if you have not completed the project.\nMore information about the project will be provided during the semester.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nLabs\n35%\n\n\nProject\n20%\n\n\nExam 1\n20%\n\n\nExam 2\n20%\n\n\nApplication Exercises\n5%\n\n\n\nWhile there are no specific points allocated to attendance, we will be recording your attendance in periodically throughout the semester, and this information will be used as ‚Äúextra credit‚Äù if you‚Äôre in between two grades and a minor bump would help.\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#five-tips-for-success",
    "href": "course-syllabus.html#five-tips-for-success",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. The course has been organized so that the burden of learning is on you. Your TAs and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TAs, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you‚Äôre not sure about the lab, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings.\nDo the lab. The earlier you start, the better. It‚Äôs not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example).\nDon‚Äôt procrastinate. The content builds upon what was taught in previous weeks, so if something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, etc. Don‚Äôt let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours and work with a member of the teaching team to help you identify a good (re)starting point.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic honesty\nTL;DR: Don‚Äôt cheat!\nPlease abide by the following as you work on assignments in this course:\n\nCollaboration: Only work that is clearly assigned as team work should be completed collaboratively.\n\nYou may discuss lab assignments with other students; however, you may not directly share (or copy) code or write up with other students. For team assignments, you may collaborate freely within your team. You may discuss the assignment with other teams; however, you may not directly share (or copy) code or write up with another team. Unauthorized sharing (or copying) of the code or write up will be considered a violation for all students involved.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nFor the project, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\nOn individual assignments you may not directly share work (including code) with another student in this class, and on team assignments you may not directly share work (including code) with another team in this class.\n\nOnline resources: I am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course‚Äôs policy is that you may make use of any online resources (e.g., StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of generative artificial intelligence (AI): You should treat generative AI, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:1 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate‚Äîrather than hinder‚Äîlearning.\n\nEthical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n\n‚úÖ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\n‚ùå AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you.\n\nYou are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask a member of the teaching team.\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one‚Äôs own work, following proper citation of sources, adhering to guidance around group work projects, and more). Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will\n\nautomatically result in a 0 for the assignment,\ncan further impact your overall course grade, and\nwill be reported to the Office of Student Conduct for further action.\n\n\n\nLate work & extensions\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest lab assignment will be dropped to accommodate such circumstances.\n\nLabs may be submitted up to 3 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThere is no late work accepted for application exercises, since these are designed to help you prepare for other assessments in the course.\nThere is no late work accepted for exams.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab by the stated due date, you may email the course coordinator, Dr.¬†Mary Knox, before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let Dr.¬†√áetinkaya-Rundel know if you need help contacting your academic dean.\n\n\nRegrade requests\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the project presentations.\n\n\nAttendance policy\n\nCOVID Symptoms, Exposure, or Infection: Student health, safety, and well-being are the university‚Äôs top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have tested positive for COVID-19 or have possible symptoms and have not yet been tested. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health (dshcheckin@duke.edu, 919-681-9355). Learn more about current university policy related to COVID-19 at https://coronavirus.duke.edu. To keep the university community‚Äôs safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class.\nInclement weather: In the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work.¬† Asynchronous catch-up methods may apply.\nReligious accommodations: Students are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: https://trinity.duke.edu/undergraduate/academic-policies/religious-holidays.\n\n\n\n\n\n\n\nClick here for syllabus bounty!\n\n\n\n\n\nIf you‚Äôve read this far in the syllabus, post a picture of your pet if you have one or your favorite meme on ed in this thread! If you‚Äôre willing, share the name of your pet too!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "STA 199 - Introduction to Data Science and Statistical Thinking",
    "section": "Important dates",
    "text": "Important dates\n\nJan 10: Classes begin\nJan 24: Drop/add ends\nFeb 15: Exam 1 in-class + take-home released\nFeb 19: Exam 1 take-home due\nFeb 26: Project milestone 1 ‚Äì working collaboratively due\nMar 11-15: Spring break\nMar 25: Project milestone 2 ‚Äì proposals due\nMar 27: Last day to withdraw with W\nApr 11: Exam 2 in-class + take-home released\nApr 15: Exam 2 take-home due\nApr 15: Project milestone 3 ‚Äì peer review due\nApr 22: Project milestone 4 ‚Äì presentations and write-up due (in lab)\nApr 24: Classes end\n\nHW deadlines are listed on the course schedule. Class ends on April 24, there is no final exam.\nFor more important dates, see the full Duke Academic Calendar.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "exam-review/exam-1-review.html",
    "href": "exam-review/exam-1-review.html",
    "title": "Exam 1 Review",
    "section": "",
    "text": "In 2020, employees of Blizzard Entertainment circulated a spreadsheet to anonymously share salaries and recent pay increases amidst rising tension in the video game industry over wage disparities and executive compensation. (Source: Blizzard Workers Share Salaries in Revolt Over Pay)\nThe name of the data frame used for this analysis is blizzard_salary and the variables are:\nThe top ten rows of blizzard_salary are shown below:\n# A tibble: 409 √ó 4\n   percent_incr salary_type annual_salary performance_rating\n          &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;             \n 1          1   Salaried               1  High              \n 2          1   Salaried               1  Successful        \n 3          1   Salaried               1  High              \n 4          1   Hourly             33987. Successful        \n 5         NA   Hourly             34798. High              \n 6         NA   Hourly             35360  &lt;NA&gt;              \n 7         NA   Hourly             37440  &lt;NA&gt;              \n 8          0   Hourly             37814. &lt;NA&gt;              \n 9          4   Hourly             41101. Top               \n10          1.2 Hourly             42328  &lt;NA&gt;              \n# ‚Ñπ 399 more rows"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-1",
    "href": "exam-review/exam-1-review.html#question-1",
    "title": "Exam 1 Review",
    "section": "Question 1",
    "text": "Question 1\nWhich of the following is correct? Choose all that apply.\n\nThe blizzard_salary dataset has 399 rows.\nThe blizzard_salary dataset has 4 columns.\nEach row represents a Blizzard Entertainment worker who filled out the spreadsheet.\nThe percent_incr variable is numerical and discrete.\nThe salary_type variable is numerical.\nThe annual_salary variable is numerical.\nThe performance_rating variable is categorical and ordinal."
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-2",
    "href": "exam-review/exam-1-review.html#question-2",
    "title": "Exam 1 Review",
    "section": "Question 2",
    "text": "Question 2\nFigure¬†1 (a) and Figure¬†1 (b) show the distributions of annual salaries of hourly and salaried workers. The two figures show the same data, with the facets organized across rows and across columns. Which of the two figures is better for comparing the median annual salaries of hourly and salaried workers. Explain your reasoning.\n\n\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\nFigure¬†1: Distribution of annual salaries of Blizzard employees"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-3",
    "href": "exam-review/exam-1-review.html#question-3",
    "title": "Exam 1 Review",
    "section": "Question 3",
    "text": "Question 3\nSuppose your teammate wrote the following code as part of their analysis of the data.\nThey then printed out the results shown below. Unfortunately one of the numbers got erased from the printout. It‚Äôs indicated with _____ below.\n# A tibble: 2 √ó 3\n  salary_type mean_annual_salary median_annual_salary\n  &lt;chr&gt;                    &lt;dbl&gt;                &lt;dbl&gt;\n1 Hourly                  63003.               54246.\n2 Salaried                90183.               _____\nWhich of the following is the best estimate for that erased value?\n\n30,000\n50,000\n80,000\n100,000"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-4",
    "href": "exam-review/exam-1-review.html#question-4",
    "title": "Exam 1 Review",
    "section": "Question 4",
    "text": "Question 4\nWhich distribution of annual salaries has a higher standard deviation?\n\nHourly workers\nSalaried workers\nRoughly the same"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-5",
    "href": "exam-review/exam-1-review.html#question-5",
    "title": "Exam 1 Review",
    "section": "Question 5",
    "text": "Question 5\nWhich of the following alternate plots would also be useful for visualizing the distributions of annual salaries of hourly and salaried workers? Choose all that apply.\na. Box plots\nb. Density plots\nc. Pie charts\nd. Waffle charts\ne. Histograms\nf. Scatterplots"
  },
  {
    "objectID": "exam-review/exam-1-review.html#questions-6-and-7",
    "href": "exam-review/exam-1-review.html#questions-6-and-7",
    "title": "Exam 1 Review",
    "section": "Questions 6 and 7",
    "text": "Questions 6 and 7\nSuppose you made the bar plot shown in Figure¬†2 (a) to visualize the distribution of performance_rating and your teammate made the bar plot shown in Figure¬†2 (b).\n\n\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\nFigure¬†2: Distribution of performance rating\n\n\n\nYou made your bar plot without transforming the data in any way, while your friend did first transform the data with code like the following:\n\nblizzard_salary &lt;- blizzard_salary |&gt;\n  _(1)_(performance_rating = fct_relevel(performance_rating, _(2)_))\n\nQuestion 6: What goes in the blank (1)?\n\narrange()\nfilter()\nmutate()\nsummarize()\n\nQuestion 7: What goes in the blank (2)?\n\n\"Poor\", \"Successful\", \"High\", \"Top\"\n\"Successful\", \"High\", \"Top\"\n\"Top\", \"High\", \"Successful\", \"Poor\"\nPoor, Successful, High, Top"
  },
  {
    "objectID": "exam-review/exam-1-review.html#questions-8---10",
    "href": "exam-review/exam-1-review.html#questions-8---10",
    "title": "Exam 1 Review",
    "section": "Questions 8 - 10",
    "text": "Questions 8 - 10\nFinally, another teammate creates the following two plots.\n\n\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\nFigure¬†3: Distribution of salary type by performance rating\n\n\n\nQuestion 8: Your teammate asks you for help deciding which one to use in the final report for visualizing the relationship between performance rating and salary type. In 1-3 sentences, can you help them make a decision, justify your choice, and write the narrative that should go with the plot?\nQuestion 9: A friend with a keen eye points out that the number of observations in Figure¬†3 (a) seems lower than the total number of observations in blizzard_salary. What might be going on here? Explain your reasoning.\nQuestion 10: Below are the proportions of performance ratings for hourly and salaried workers. Place these values in the corresponding segments in Figure¬†3 (b).\n\n\n# A tibble: 4 √ó 3\n  performance_rating Hourly Salaried\n  &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;\n1 High                0.2     0.384 \n2 Successful          0.686   0.521 \n3 Top                 0.114   0.0760\n4 Poor                0       0.0190"
  },
  {
    "objectID": "exam-review/exam-1-review.html#questions-11-and-12",
    "href": "exam-review/exam-1-review.html#questions-11-and-12",
    "title": "Exam 1 Review",
    "section": "Questions 11 and 12",
    "text": "Questions 11 and 12\nThe table below shows the distribution of salary_type and performance_rating.\n\n\n# A tibble: 2 √ó 6\n  salary_type  Poor Successful  High   Top  `NA`\n  &lt;chr&gt;       &lt;int&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 Hourly         NA         24     7     4    28\n2 Salaried        5        137   101    20    83\n\n\nThe pipeline below produces a data frame with a fewer number of rows than blizzard_salary.\n\nblizzard_salary |&gt;\n  filter(salary_type _(1)_ \"Hourly\" _(2)_ performance_rating == \"Poor\") |&gt;\n  _(3)_(annual_salary)\n\n\n\n# A tibble: 5 √ó 4\n  percent_incr salary_type annual_salary performance_rating\n         &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;             \n1            0 Salaried            80000 Poor              \n2            3 Salaried            83000 Poor              \n3            0 Salaried           116000 Poor              \n4            0 Salaried           135219 Poor              \n5            0 Salaried           147500 Poor              \n\n\nQuestion 11: Which of the following goes in blanks (1) and (2)?\n\n\n\n\n(1)\n(2)\n\n\n\n\na.\n!=\n|\n\n\nb.\n==\n&\n\n\nc.\n!=\n&\n\n\nd.\n==\n|\n\n\n\nQuestion 12: Which function or functions go into blank (3)?\n\narrange()\nmutate()\norder()\nsort()"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-13",
    "href": "exam-review/exam-1-review.html#question-13",
    "title": "Exam 1 Review",
    "section": "Question 13",
    "text": "Question 13\nYou‚Äôre reviewing another team‚Äôs work and they made the following visualization:\n\n\n\n\n\n\n\n\n\nAnd they wrote the following interpretation for the relationship between annual salary and percent increase for Top performers:\n\nThe relationship is positive, having a higher salary results in a higher percent increase. There is one clear outlier.\n\nWhich of the following is/are the most accurate and helpful) peer review note for this interpretation. Choose all that apply.\n\nThe interpretation is complete and perfect, no changes needed!\nThe interpretation doesn‚Äôt mention the direction of the relationship.\nThe interpretation doesn‚Äôt mention the form of the relationship, which is linear.\nThe interpretation doesn‚Äôt mention the strength of the relationship, which is somewhat strong.\nThere isn‚Äôt a clear outlier in the plot. If any points stand out as potential outliers, more guidance should be given to the reader to identify them (e.g., salary and/or percent increase amount).\nThe interpretation is causal ‚Äì we don‚Äôt know if the cause of the high percent increase is higher annual salary based on observational data. The causal direction might be the other way around, or there may be other factors contributing to the apparent relationship."
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-14",
    "href": "exam-review/exam-1-review.html#question-14",
    "title": "Exam 1 Review",
    "section": "Question 14",
    "text": "Question 14\nBelow is some code and its output.\n```{r}\n# label=plot blizzard\n\nggplot(blizzard_salary,aes(x=performance_rating,y=percent_incr))+geom_boxplot()\nlabs(x=\"Performance rating\", y = \"Percent increase\")\n```\n\n\nWarning: Removed 39 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n$x\n[1] \"Performance rating\"\n\n$y\n[1] \"Percent increase\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nPart 1: List at least 5 things that should be fixed or improved in the code.\nPart 2: What is the cause of the warning and what does it mean?"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-15",
    "href": "exam-review/exam-1-review.html#question-15",
    "title": "Exam 1 Review",
    "section": "Question 15",
    "text": "Question 15\nYou‚Äôre working on a data analysis on salaries of Blizzard employees in a Quarto document in a project version controlled by Git. You create a plot and write up a paragraph describing any patterns in it. Then, your teammate says ‚Äúrender, commit, and push‚Äù.\nPart 1: What do they mean by each of these three steps. In 1-2 sentences for each, explain in your own words what they mean.\n\nRender:\n\n\nCommit:\n\n\nPush:\n\nPart 2: Your teammate is getting impatient and they interrupt you after you rendered and committed and say ‚ÄúI still can‚Äôt see your changes in our shared GitHub repo when I look at it in my web browser.‚Äù Which of the following answers is the most accurate?\n\nI rendered my document, you should be seeing my changes on GitHub when you look at it in your web browser.\nI committed my changes, you should be seeing my changes on GitHub when you look at it in your web browser.\nI didn‚Äôt yet push my changes, it‚Äôs expected that you are not seeing them on GitHub when you look at it in your web browser. Wait until I push, and check again.\nYou need to pull to see my changes on GitHub in the web browser."
  },
  {
    "objectID": "exam-review/exam-1-review.html#bonus",
    "href": "exam-review/exam-1-review.html#bonus",
    "title": "Exam 1 Review",
    "section": "Bonus",
    "text": "Bonus\nPick a concept we introduced in class so far that you‚Äôve been struggling with and explain it in your own words."
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Dr.¬†Mine √áetinkaya-Rundel (she/her) is Professor of the Practice and Director of Undergraduate Studies at the Department of Statistical Science at Duke University. Mine‚Äôs work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM. Mine also works with RStudio as a Developer Educator.\n\n\n\n\n\n\n\nOffice hours\nLocation\n\n\n\n\nTuesdays and Thursdays 1-1:30 pm (immediately after class)\nBio Sci 111\n\n\nThursdays 2-3 pm\nOld Chem 213",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-team.html#instructor",
    "href": "course-team.html#instructor",
    "title": "Teaching team",
    "section": "",
    "text": "Dr.¬†Mine √áetinkaya-Rundel (she/her) is Professor of the Practice and Director of Undergraduate Studies at the Department of Statistical Science at Duke University. Mine‚Äôs work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM. Mine also works with RStudio as a Developer Educator.\n\n\n\n\n\n\n\nOffice hours\nLocation\n\n\n\n\nTuesdays and Thursdays 1-1:30 pm (immediately after class)\nBio Sci 111\n\n\nThursdays 2-3 pm\nOld Chem 213",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-team.html#teaching-assistants",
    "href": "course-team.html#teaching-assistants",
    "title": "Teaching team",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\n\n\n\n\n\n\nFirst name\nLast name\nRole\n\n\n\nChris\nOswald\nLab leader: M 8:30AM - 9:45AM (Sec 1)\n\n\n\nJasmine\nWang\nLab helper: M 8:30AM - 9:45AM (Sec 1)\n\n\n\nBetsy\nBersson\nHead TA\nLab leader: M 10:05AM - 11:20AM (Sec 2)\n\n\n\nMert\nBildirici\nLab helper: M 10:05AM - 11:20AM (Sec 2)\n\n\n\nWill\nTirone\nLab leader: M 11:45AM - 1:00PM (Sec 3)\n\n\n\nKrish\nBansal\nLab helper: M 11:45AM - 1:00PM (Sec 3)\n\n\n\nCaitrin\nMurphy\nLab leader: M 1:25PM - 2:40PM (Sec 4)\n\n\n\nAvery\nHodges\nLab helper: M 1:25PM - 2:40PM (Sec 4)\n\n\n\nJon\nCampbell\nLab leader: M 1:25PM - 2:40PM (Sec 11)\n\n\n\nFoxx\nHart\nLab helper: M 1:25PM - 2:40PM (Sec 11)\nLecture helper (Tue)\n\n\n\nNetra\nMittal\nLab leader: M 3:05PM - 4:20PM (Sec 5)\n\n\n\nAlexa\nFahrer\nLab helper: M 3:05PM - 4:20PM (Sec 5)\n\n\n\nDevin\nJohnson\nLab leader: M 4:40PM - 5:55PM (Sec 6)\n\n\n\nKonnie\nHuang\nLab helper: M 4:40PM - 5:55PM (Sec 6)\n\n\n\nLi\nFan\nLab leader: M 4:40PM - 5:55PM (Sec 7)\n\n\n\nKelly\nHuang\nLab helper: M 4:40PM - 5:55PM (Sec 7)\n\n\n\nLeah\nJohnson\n\n\n\n\nLisa\nZhang\nLecture helper (Tue + Thur)\n\n\n\nMiles\nKing\nLecture helper (Tue + Thur)\n\n\n\nNoah\nObuya\nLecture helper (Thur)\n\n\n\nFor office hours, please see STA 199 - Office Hours sheet.",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-team.html#course-coordinator",
    "href": "course-team.html#course-coordinator",
    "title": "Teaching team",
    "section": "Course coordinator",
    "text": "Course coordinator\n\nDr.¬†Mary Knox (she/her) is the course coordinator for this course. You can reach out to her (at mary.knox@duke.edu) with any questions regarding missed work, extensions, etc. as well as registration questions.",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "labs/lab-3.html",
    "href": "labs/lab-3.html",
    "title": "Lab 3 - Data tidying and joining",
    "section": "",
    "text": "In this lab you‚Äôll build the data wrangling and visualization skills you‚Äôve developed so far and data tidying and joining to your repertoire.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you‚Äôve completed the labs so far and doesn‚Äôt repeat setup and overview content from those labs. If you have not yet done those, you should go back and review the previous labs before starting on this one.\n\n\n\n\nBy the end of the lab, you will‚Ä¶\n\nBe able to pivot/reshape data using tidyr\nContinue developing your data wrangling skills using dplyr\nBuild on your mastery of data visualizations using ggplot2\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\n\n\n\nLog in to RStudio, clone your lab-3 repo from GitHub, open your lab-3.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\n\n\n\nGo to the course organization at github.com/sta199-s24 organization on GitHub. Click on the repo with the prefix lab-3. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you‚Äôll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ‚ûõ New Project ‚ûõVersion Control ‚ûõ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-3.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\n\n\n\nIn lab-3.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., ‚ÄúAdded author name‚Äù), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\n\n\nIn this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a ‚Äútidy‚Äù way.\n\nlibrary(tidyverse)\n\nRender the document which loads this package with the library() function.\n\n\n\nAs we‚Äôve discussed in lecture, your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nIn addition, the code should all the code should be be able to be read (not run off the page) when you render to PDF. Make sure that is the case, and add line breaks where the code is running off the page.1\n\n\n\n\n\n\nNote\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#learning-objectives",
    "href": "labs/lab-3.html#learning-objectives",
    "title": "Lab 3 - Data tidying and joining",
    "section": "",
    "text": "By the end of the lab, you will‚Ä¶\n\nBe able to pivot/reshape data using tidyr\nContinue developing your data wrangling skills using dplyr\nBuild on your mastery of data visualizations using ggplot2\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#getting-started",
    "href": "labs/lab-3.html#getting-started",
    "title": "Lab 3 - Data tidying and joining",
    "section": "",
    "text": "Log in to RStudio, clone your lab-3 repo from GitHub, open your lab-3.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\n\n\n\nGo to the course organization at github.com/sta199-s24 organization on GitHub. Click on the repo with the prefix lab-3. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you‚Äôll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ‚ûõ New Project ‚ûõVersion Control ‚ûõ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-3.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\n\n\n\nIn lab-3.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., ‚ÄúAdded author name‚Äù), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#packages",
    "href": "labs/lab-3.html#packages",
    "title": "Lab 3 - Data tidying and joining",
    "section": "",
    "text": "In this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a ‚Äútidy‚Äù way.\n\nlibrary(tidyverse)\n\nRender the document which loads this package with the library() function.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#guidelines",
    "href": "labs/lab-3.html#guidelines",
    "title": "Lab 3 - Data tidying and joining",
    "section": "",
    "text": "As we‚Äôve discussed in lecture, your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nIn addition, the code should all the code should be be able to be read (not run off the page) when you render to PDF. Make sure that is the case, and add line breaks where the code is running off the page.1\n\n\n\n\n\n\nNote\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#part-1",
    "href": "labs/lab-3.html#part-1",
    "title": "Lab 3 - Data tidying and joining",
    "section": "Part 1",
    "text": "Part 1\nInflation across the world\nFor this part of the analysis you will work with inflation data from various countries in the world over the last 30 years.\n\ncountry_inflation &lt;- read_csv(\"data/country-inflation.csv\")\n\n\nQuestion 1\nGet to know the data.\n\nglimpse() at the country_inflation data frame and answer the following questions based on the output. How many rows does country_inflation have and what does each row represent? How many columns does country_inflation have and what does each column represent?\nDisplay a list of the countries included in the dataset.\n\n\n\n\n\n\n\nTip\n\n\n\nA function that can be useful for part (b) is pull(). Check out its documentation for examples of usage.\n\n\n\n\nQuestion 2\nWhich countries had the top three highest inflation rates in 2021? Your output should be a data frame with two columns, country and 2021, with inflation rates in descending order, and three rows for the top three countries. Briefly comment on how the inflation rates for these countries compare to the inflation rate for United States in that year.\n\n\n\n\n\n\nTip\n\n\n\nColumn names that are numbers are not considered ‚Äúproper‚Äù in R, therefore to select them you‚Äôll need to surround them with backticks, e.g.¬†select( ` 1993 ` ).\n\n\n\n\nQuestion 3\nIn a single pipeline,\n\ncalculate the ratio of the inflation in 2021 and inflation in 1993 for each country and store this information in a new column called inf_ratio,\narrange the data frame in decreasing order of inf_ratio, and\nselect the variables country and inf_ratio to display as the result of the pipeline.\n\nDo not save this new variable in inf_ratio, only calculate and display it so you can answer the following question based on the output of the pipeline.\nWhich country‚Äôs inflation change is the largest over this time period? Did inflation increase of decrease between 1993 and 2021 in this country?\n\n\n\n\n\n\nTip\n\n\n\nFor this question you‚Äôll once again need to use variables whose names are numbers (years) in your pipeline. Make sure to surround the names of such variables with backticks (`).\n\n\n\n\nQuestion 4\nReshape (pivot) country_inflation such that each row represents a country/year combination, with columns country, year, and annual_inflation. Then, display the resulting data frame and state how many rows and columns it has.\nRequirements:\n\nYour code must use one of pivot_longer() or pivot_wider(). There are other ways you can do this reshaping move in R, but this question requires solving this problem by pivoting.\nIn your pivot_*() function, you must use names_transform = as.numeric as an argument to transform the variable type to numeric as you pivot the data so that in the resulting data frame the year variable is numeric.\nThe resulting data frame must be saved as something other than country_inflation so you (1) can refer to this data frame later in your analysis and (2) do not overwrite country_inflation. Use a short but informative name.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe remaining questions in Part 1 require the use of the pivoted data frame from Question 4.\n\n\n\n\nQuestion 5\nUse a separate, single pipeline to answer each of the following questions.\nRequirement: Your code must use the filter() function for each part, not arrange().\n\nWhat is the highest inflation rate observed between 1993 and 2021? The output of the pipeline should be a data frame with one row and three columns. In addition to code and output, your response should include a single sentence stating the country and year.\nWhat is the lowest inflation rate observed between 1993 and 2021? The output of the pipeline should be a data frame with one row and three columns. In addition to code and output, your response should include a single sentence stating the country and year.\nPutting (a) and (b) together: What are the highest and the lowest inflation rates observed between 1993 and 2021? The output of the pipeline should be a data frame with two rows and three columns.\n\n\n\nQuestion 6\na. Create a vector called countries_of_interest which contains the names of up tp five countries you want to visualize the inflation rates for over the years. For example, if these countries are T√ºrkiye and United States, you can express this as follows:\n\ncountries_of_interest &lt;- c(\"T√ºrkiye\", \"United States\")\n\nIf they are T√ºrkiye, United States, and China, you can express this as follows:\n\ncountries_of_interest &lt;- c(\n  \"T√ºrkiye\", \"United States\", \"China (People's Republic of)\"\n)\n\nSo on and so forth‚Ä¶ Then, in 1-2 sentences, state why you chose these countries.\n\n\n\n\n\n\nNote\n\n\n\nYour countries_of_interest should consist of no more than five countries. Make sure that the spelling of your countries matches how they appear in the dataset.\n\n\nb. In a single pipeline, filter your reshaped dataset to include only the countries_of_interest from part (a), and save the resulting data frame with a new name so you (1) can refer to this data frame later in your analysis and (2) do not overwrite the data frame you‚Äôre starting with. Use a short but informative name. Then, in a new pipeline, find the distinct() countries in the data frame you created.\n\n\n\n\n\n\nTip\n\n\n\nThe number of distinct countries in the filtered data frame you created in part (b) should equal the number of countries you chose in part (a). If it doesn‚Äôt, you might have misspelled a country name or made a mistake in how to filter for these countries. Go back and check your code.\n\n\n\n\nQuestion 7\nUsing your data frame from the previous question, create a plot of annual inflation vs.¬†year for these countries. Then, in a few sentences, describe the patterns you observe in the plot, particularly focusing on anything you find surprising or not surprising, based on your knowledge (or lack thereof) of these countries economies.\nRequirements for the plot:\n\nData should be represented with points as well as lines connecting the points for each country.\nEach country should be represented by a different color line and different color and shape points.\nAxes and legend should be properly labeled.\nThe plot should have an appropriate title (and optionally a subtitle).\nPlot should be customized in at least one way ‚Äì you could use a different than default color scale, or different than default theme, or some other customization.\n\n\nIf you haven‚Äôt yet done so, now is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#part-2",
    "href": "labs/lab-3.html#part-2",
    "title": "Lab 3 - Data tidying and joining",
    "section": "Part 2",
    "text": "Part 2\nInflation in the US\nThe OECD defines inflation as follows:\n\nInflation is a rise in the general level of prices of goods and services that households acquire for the purpose of consumption in an economy over a period of time.\nThe main measure of inflation is the annual inflation rate which is the movement of the Consumer Price Index (CPI) from one month/period to the same month/period of the previous year expressed as percentage over time.\nSource: OECD CPI FAQ\n\nCPI is broken down into 12 divisions such as food, housing, health, etc. Your goal in this part is to create another time series plot of annual inflation, this time for US only.\nThe data you will need to create this visualization is spread across two files:\n\nus-inflation.csv: Annual inflation rate for the US for 12 CPI divisions. Each division is identified by an ID number.\ncpi-divisions.csv: A ‚Äúlookup table‚Äù of CPI division ID numbers and their descriptions.\n\nLet‚Äôs load both of these files.\n\nus_inflation &lt;- read_csv(\"data/us-inflation.csv\")\ncpi_divisions &lt;- read_csv(\"data/cpi-divisions.csv\")\n\n\nQuestion 8\na. How many columns and how many rows does the us_inflation dataset have? What are the variables in it? Add a brief (1-2 sentences) narrative summarizing this information.\nb. How many columns and how many rows does the cpi_divisions dataset have? What are the variables in it? Add a brief (1-2 sentences) narrative summarizing this information.\nc. Create a new dataset by joining the us_inflation dataset with the cpi_division_id dataset.\n\nDetermine which type of join is the most appropriate one and use that.\nNote that the two datasets don‚Äôt have a common variable. Review the help for the join functions to determine how to use the by argument when the names of the variables that the datasets should be joined by are different.\nUse a short but informative name for the joined dataset, and do not overwrite either of the datasets that go into creating it.\n\nThen, find the number of rows and columns of the resulting dataset and report the names of its columns. Add a brief (1-2 sentences) narrative summarizing this information.\n\n\nQuestion 9\na. Create a vector called divisions_of_interest which contains the descriptions or IDs of CPI divisions you want to visualize. Your divisions_of_interest should consist of no more than five divisions. If you‚Äôre using descriptions, make sure that the spelling of your divisions matches how they appear in the dataset. Then, in 1-2 sentences, state why you chose these divisions.\n\n\n\n\n\n\nTip\n\n\n\nRefer back to the guidance provided in Question 6 if you‚Äôre not sure how to create this vector.\n\n\nb. In a single pipeline, filter your reshaped dataset to include only the divisions_of_interest from part (a), and save the resulting data frame with a new name so you (1) can refer to this data frame later in your analysis and (2) do not overwrite the data frame you‚Äôre starting with. Use a short but informative name. Then, in a new pipeline, find the distinct() divisions in the data frame you created.\n\n\nQuestion 10\nUsing your data frame from the previous question, create a plot of annual inflation vs.¬†year for these divisions. Then, in a few sentences, describe the patterns you observe in the plot, particularly focusing on anything you find surprising or not surprising, based on your knowledge (or lack thereof) of inflation rates in the US over the last decade.\n\nData should be represented with points as well as lines connecting the points for each division.\nEach division should be represented by a different color line and different color and shape points.\nAxes and legend should be properly labeled.\nThe plot should have an appropriate title (and optionally a subtitle).\nPlot should be customized in at least one way ‚Äì you could use a different than default color scale, or different than default theme, or some other customization.\nIf your legend has labels that are too long, you can try moving the legend to the bottom and stack the labels vertically. Hint: The legend.position and legend.direction arguments of the theme() functions will be useful.\n\n\nggplot(...) +\n  ... +\n  theme(\n    legend.position = \"bottom\", \n    legend.direction = \"vertical\"\n  )\n\n\nIf you haven‚Äôt yet done so since Part 1, now is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#submission",
    "href": "labs/lab-3.html#submission",
    "title": "Lab 3 - Data tidying and joining",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered ‚Äúon time‚Äù.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark all the pages associated with question. All the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#grading",
    "href": "labs/lab-3.html#grading",
    "title": "Lab 3 - Data tidying and joining",
    "section": "Grading",
    "text": "Grading\nThe lab is graded out of a total of 50 points.\nYou can earn up to 5 points on each question:\n\n5: Response shows excellent understanding and addresses all or almost all of the rubric items.\n4: Response shows good understanding and addresses most of the rubric items.\n3: Response shows understanding and addresses a majority of the rubric items.\n2: Response shows effort and misses many of the rubric items.\n1: Response does not show sufficient effort or understanding and/or is largely incomplete.\n0: No attempt.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#footnotes",
    "href": "labs/lab-3.html#footnotes",
    "title": "Lab 3 - Data tidying and joining",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRemember, haikus not novellas when writing code!‚Ü©Ô∏é",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-0.html",
    "href": "labs/lab-0.html",
    "title": "Lab 0 - Hello, World and STA 199!",
    "section": "",
    "text": "This lab will set you up for the computing workflow and give you an opportunity to introduce yourselves to each other and the teaching team.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "labs/lab-0.html#access-r-and-rstudio",
    "href": "labs/lab-0.html#access-r-and-rstudio",
    "title": "Lab 0 - Hello, World and STA 199!",
    "section": "Access R and RStudio",
    "text": "Access R and RStudio\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 to log into the Docker container. You should now see the RStudio environment.\n\nGo to https://cmgr.oit.duke.edu/containers and under Reservations available click on reserve STA 198-199 to reserve a container for yourself.\n\n\n\n\n\n\nNote\n\n\n\nA container is a self-contained instance of RStudio for you, and you alone. You will do all of your computing in your container.\n\n\nOnce you‚Äôve reserved the container you‚Äôll see that it will show up under My reservations.\nTo launch your container click on it under My reservations, then click Login, and then Start.1",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "labs/lab-0.html#create-a-github-account",
    "href": "labs/lab-0.html#create-a-github-account",
    "title": "Lab 0 - Hello, World and STA 199!",
    "section": "Create a GitHub account",
    "text": "Create a GitHub account\nGo to https://github.com/ and walk through the steps for creating an account. You do not have to use your Duke email address, but I recommend doing so.2\n\n\n\n\n\n\nNote\n\n\n\nYou‚Äôll need to choose a user name. I recommend reviewing the user name advice at https://happygitwithr.com/github-acct#username-advice before choosing a username.\n\n\n\n\n\n\n\n\nWhat if I already have a GitHub account?\n\n\n\n\n\nIf you already have a GitHub account, you do not need to create a new one for this course. Just log in to that account to make sure you still remember your username and password.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "labs/lab-0.html#set-up-your-ssh-key",
    "href": "labs/lab-0.html#set-up-your-ssh-key",
    "title": "Lab 0 - Hello, World and STA 199!",
    "section": "Set up your SSH key",
    "text": "Set up your SSH key\nYou will authenticate GitHub using SSH (Secure Shell Protocol ‚Äì it doesn‚Äôt really matter what this means for the purpose of this course). Below is an outline of the authentication steps; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nGo back to your RStudio container and type credentials::ssh_setup_github() into your console.\nR will ask ‚ÄúNo SSH key found. Generate one now?‚Äù You should click 1 for yes.\nYou will generate a key. It will begin with ‚Äússh-rsa‚Ä¶.‚Äù R will then ask ‚ÄúWould you like to open a browser now?‚Äù You should click 1 for yes.\nYou may be asked to provide your GitHub username and password to log into GitHub. After entering this information, you should paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta199).\n\nYou can find more detailed instructions here if you‚Äôre interested.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "labs/lab-0.html#configure-git",
    "href": "labs/lab-0.html#configure-git",
    "title": "Lab 0 - Hello, World and STA 199!",
    "section": "Configure Git",
    "text": "Configure Git\nThere is one more thing we need to do before getting started on the assignment. Specifically, we need to configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\n\n\n\n\n\n\nNote\n\n\n\nYou‚Äôll hear about üì¶ packages a lot in the context of R ‚Äì basically they‚Äôre how developers write functions and bundle them to distribute to the community (and more on this later too!).\n\n\nType the following lines of code in the console in RStudio filling in your name and the address associated with your GitHub account.\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\"\n)\n\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"Mine √áetinkaya-Rundel\", \n  user.email = \"cetinkaya.mine@gmail.com\"\n)\n\nYou are now ready interact with GitHub via RStudio!\n\n\n\n\n\n\nNeed a recap? Watch this video!\n\n\n\n\n\nThe following video walks you through the steps outlined in the SSH key generation and Git configuration sections above.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "labs/lab-0.html#footnotes",
    "href": "labs/lab-0.html#footnotes",
    "title": "Lab 0 - Hello, World and STA 199!",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYes, it‚Äôs too many steps. I don‚Äôt know why! But it works, and you‚Äôll get used to it. Trust me, it beats downloading and installing everything you need on your computers!‚Ü©Ô∏é\nGitHub has some perks for students you can take advantage of later in the course or in your future work, and it helps to have a .edu address to get verified as a student.‚Ü©Ô∏é",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "labs/lab-7.html",
    "href": "labs/lab-7.html",
    "title": "Lab 7 - Modeling II",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-2.html",
    "href": "labs/lab-2.html",
    "title": "Lab 2 - Data wrangling",
    "section": "",
    "text": "In this lab you‚Äôll continue to hone your data science workflow as well as bring together what you learned so far in the course (data visualization) with what‚Äôs coming up (data wrangling).\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you‚Äôve completed Lab 0 and Lab 1 and doesn‚Äôt repeat setup and overview content from those labs. If you have not yet done those, you should go back and review them before starting with this one.\n\n\n\n\nBy the end of the lab, you will‚Ä¶\n\nBe able to create transform data using dplyr\nBuild on your mastery of data visualizations using ggplot2\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\n\n\n\nGo to the course organization at github.com/sta199-s24 organization on GitHub. Click on the repo with the prefix lab-2. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you‚Äôll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ‚ûõ New Project ‚ûõVersion Control ‚ûõ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-2.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\n\n\n\nIn lab-2.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., ‚ÄúAdded author name‚Äù), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\n\n\n\nIn this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a ‚Äútidy‚Äù way.\n\nlibrary(tidyverse)\n\nRender the document which loads this package with the library() function.\n\n\n\n\n\n\nNote\n\n\n\nRemember: The rendered document will include a message about which packages the tidyverse package is loading along with it. It‚Äôs just R being informative, a message does not indicate anything is wrong (it‚Äôs not a warning or an error).\n\n\n\n\n\nAs we‚Äôve discussed in lecture, your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nIn addition, the code should all the code should be be able to be read (not run off the page) when you render to PDF. Make sure that is the case, and add line breaks where the code is running off the page.1\n\n\n\n\n\n\nNote\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#learning-objectives",
    "href": "labs/lab-2.html#learning-objectives",
    "title": "Lab 2 - Data wrangling",
    "section": "",
    "text": "By the end of the lab, you will‚Ä¶\n\nBe able to create transform data using dplyr\nBuild on your mastery of data visualizations using ggplot2\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#getting-started",
    "href": "labs/lab-2.html#getting-started",
    "title": "Lab 2 - Data wrangling",
    "section": "",
    "text": "Go to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\n\n\n\nGo to the course organization at github.com/sta199-s24 organization on GitHub. Click on the repo with the prefix lab-2. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you‚Äôll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ‚ûõ New Project ‚ûõVersion Control ‚ûõ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-2.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\n\n\n\nIn lab-2.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., ‚ÄúAdded author name‚Äù), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#packages",
    "href": "labs/lab-2.html#packages",
    "title": "Lab 2 - Data wrangling",
    "section": "",
    "text": "In this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a ‚Äútidy‚Äù way.\n\nlibrary(tidyverse)\n\nRender the document which loads this package with the library() function.\n\n\n\n\n\n\nNote\n\n\n\nRemember: The rendered document will include a message about which packages the tidyverse package is loading along with it. It‚Äôs just R being informative, a message does not indicate anything is wrong (it‚Äôs not a warning or an error).",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#guidelines",
    "href": "labs/lab-2.html#guidelines",
    "title": "Lab 2 - Data wrangling",
    "section": "",
    "text": "As we‚Äôve discussed in lecture, your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nIn addition, the code should all the code should be be able to be read (not run off the page) when you render to PDF. Make sure that is the case, and add line breaks where the code is running off the page.1\n\n\n\n\n\n\nNote\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#part-1",
    "href": "labs/lab-2.html#part-1",
    "title": "Lab 2 - Data wrangling",
    "section": "Part 1",
    "text": "Part 1\nBack to the Midwest!\nIn this part you will revisit and build on some of your findings from Lab 1, where you explored the midwest data frame. Remember that this data frame is bundled with the ggplot2 package and is automatically loaded when you load the tidyverse package. As a refresher, the data contains demographic characteristics of counties in the Midwest region of the United States. You can read documentation for the data set, including variable definitions by typing ?midwest in the Console or searching for midwest in the Help pane.\n\nQuestion 1\nCalculate the number of counties in each state and display your results in descending order of number of counties. Which state has the highest number of counties, and how many? Which state has the lowest number, and how many?\n\n\n\n\n\n\nNote\n\n\n\nThe number of counties in a state can change over time, so the values you see in this output may not be true today.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message ‚ÄúAdded answer for Question 1‚Äù.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\n\n\nQuestion 2\nWhile in a given state two counties can‚Äôt have the same name, across states some county names might be shared. A classmate says ‚ÄúLook at that, there is a county called ___ in each state in this dataset!‚Äù In a single pipeline, discover all counties that could fill in the blank. Your response should be a data frame with only the county names that could fill in the blank and how many times they appear in the data.\n\n\n\n\n\n\nTip\n\n\n\nYou will want to use the filter() function in your answer, which requires a logical condition to describe what you want to filter for. For example filter(x &gt; 2) means filter for values of x greater than 2, filter(y &lt;= 3) means filter for values of y less than or equal to 3.\nThe table below is a summary of logical operators and how to articulate them in R.\n\n\n\noperator\ndefinition\n\n\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n==\nexactly equal to\n\n\n!=\nnot equal to\n\n\nx & y\nx AND y\n\n\nx¬†|¬†y\nx OR y\n\n\nis.na(x)\ntest if x is NA\n\n\n!is.na(x)\ntest if x is not NA\n\n\nx %in% y\ntest if x is in y\n\n\n!(x %in% y)\ntest if x is not in y\n\n\n!x\nnot x\n\n\n\n\n\n\nRender, commit, and push your changes to GitHub with the commit message ‚ÄúAdded answer for Question 2‚Äù.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\n\n\nQuestion 3\nReturn to the following box plot of population densities where you were asked to identify at least one outlier.\n\n\n\n\n\n\n\n\n\nIn this question part, we want you to revisit this box plot and identify the counties described in each part.\na. The counties with a population density higher than 25,000. Your code must use the filter() function.\nb. The county with the highest population density. Your code must use the max() function.\nAnswer using a single data wrangling pipeline for each part. Your response should be a data frame five columns: county name, state name, population density, total population, and area, in this order. If your response has multiple rows, the data frame should be arranged in descending order of population density.\n\nRender, commit, and push your changes to GitHub with the commit message ‚ÄúAdded answer for Question 3‚Äù.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\n\n\nQuestion 4\nIn Lab 1 you were also asked to describe the distribution of population densities. The following is one acceptable description that touches on shape, center, and spread of this distribution. Calculate the values that should go into the blanks.\n\nThe distribution of population density of counties is unimodal and extremely right-skewed. A typical Midwestern county has population density of ____ people per unit area. The middle 50% of the counties have population densities between ___ to ___ people per unit area.\n\n\n\n\n\n\n\nTip\n\n\n\nThink about which measures of center and spread are appropriate for skewed distributions.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message ‚ÄúAdded answer for Question 4‚Äù.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\n\n\nQuestion 5\nAnother visualization from Lab 1 was the following that showed the proportion of urban counties in each state.\n\n\n\n\n\n\n\n\n\nCalculate these proportions in a single data pipeline.\n\n\n\n\n\n\nTip\n\n\n\nRemember, you‚Äôll first need to create a new variable called metro which takes on the value Yes if the value of inmetro is 1, and No otherwise. You can refer to Lab 1 if you need a refresher on how to do this.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message ‚ÄúAdded answer for Question 5‚Äù.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\n\n\nQuestion 6\nReturn to the following scatter plot of percentage below poverty vs.¬†percentage of people with a college degree, where the color and shape of points are determined by state where you were asked to identify at least one county that is a clear outlier by name.\n\n\n\n\n\n\n\n\n\na. In a single pipeline, identify the observations marked in the orange square on the upper left corner. Your answer should be a data frame with four variables: county, state, percentage below poverty, and percentage college educated.\nb. In a single pipeline, identify the observations marked in the red square in the plot above. Your answer should again be a data frame with four variables: county, state, percentage below poverty, and percentage college educated.\nc. Bring your answers from part (a) and part (b) together! In a single pipeline, and a single filter() statement, identify the observations marked in the red and orange square in the plot above. Your answer should again be a data frame with four variables: county, state, percentage below poverty, and percentage college educated.\nd. Create a new variable in midwest called potential_outlier. This variable should take on the value:\n\nYes if the point is one the ones you identified in part (c), i.e., one of the points marked in the squares in the plot above.\nNo otherwise.\n\nThen, display the updated midwest data frame, with county, state, percentage below poverty, percentage college educated, potential_outlier as the selected variables, arranged in ascending order of potential_outlier.\nc. Recreate the visualization above, i.e.¬†a scatterplot of percentage below poverty vs.¬†percentage of people with a college degree, however color the points by the newly created potential_outlier variable instead of state.\n\nRender, commit, and push your changes to GitHub with the commit message ‚ÄúAdded answer for Question 6‚Äù.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\n\n\nQuestion 7\na. In a single pipeline, calculate the total population for each state and save the resulting data frame as state_population and display it in descending order of total population.\nb. Then, in a separate pipeline, calculate the proportion of the total population in each state and, once again, display the results in descending order of proportion of population.\n\n\n\n\n\n\nTip\n\n\n\nIn answering parts (a) and (b), you‚Äôll create two new variables, one for total population and other for proportion of total proportion. Make sure to give them ‚Äúreasonable‚Äù names ‚Äì short but evocative.\n\n\nc. Which Midwestern state is most populous and what percent of the Midwest population lives there? Which is the least populous and what percent lives there?\n\nRender, commit, and push your changes to GitHub with the commit message ‚ÄúAdded answer for Question 7‚Äù.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\n\n\nQuestion 8\nCalculate the average percentage below poverty for each state and save the resulting data frame as state_poverty with the columns state and mean_percbelowpoverty.\nThen, in a new pipeline, display the state_poverty data frame in ascending order of mean_percbelowpoverty. Which state has the lowest average percentage below poverty across its counties? Which state has the highest average percentage below poverty across its counties?\n\nRender, commit, and push your changes to GitHub with the commit message ‚ÄúAdded answer for Question 8‚Äù.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#part-2",
    "href": "labs/lab-2.html#part-2",
    "title": "Lab 2 - Data wrangling",
    "section": "Part 2",
    "text": "Part 2\nAll about group_by()!\n\nQuestion 9\nSuppose we have the following data frame:\n\ndf &lt;- tibble(\n  var_1 = c(10, 20, 30, 40, 50),\n  var_2 = c(\"Pizza\", \"Burger\", \"Pizza\", \"Pizza\", \"Burger\"),\n  var_3 = c(\"Apple\", \"Apple\", \"Pear\", \"Pear\", \"Banana\")\n)\n\ndf\n\n# A tibble: 5 √ó 3\n  var_1 var_2  var_3 \n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; \n1    10 Pizza  Apple \n2    20 Burger Apple \n3    30 Pizza  Pear  \n4    40 Pizza  Pear  \n5    50 Burger Banana\n\n\na. What does the following code chunk do? Run it and analyze the result and articulate in words what arrange() does.\n\ndf |&gt;\n  arrange(var_2)\n\nb. What does the following code chunk do? Run it and analyze the result and articulate in words what group_by() does. Also comment on how it‚Äôs different from the arrange() in part (a)?\n\ndf |&gt;\n  group_by(var_2)\n\nc. What does the following code chunk do? Run it and analyze the result and articulate in words what the pipeline does.\n\ndf |&gt;\n  group_by(var_2) |&gt;\n  summarize(mean_var_1 = mean(var_1))\n\nd. What does the following code chunk do? Run it and analyze the result and articulate in words what the pipeline does. Then, comment on what the message says.\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  summarize(mean_var_1 = mean(var_1))\n\ne. What does the following code chunk do? Run it and analyze the result and articulate in words what the pipeline does, especially mentioning what the .groups argument does. How is the output different from the one in part (d).\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  summarize(mean_var_1 = mean(var_1), .groups = \"drop\")\n\nf. What do the following pipelines do? Run both and analyze their results and articulate in words what each pipeline does. How are the outputs of the two pipelines different?\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  summarize(mean_var_1 = mean(var_1), .groups = \"drop\")\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  mutate(mean_var_1 = mean(var_1))\n\n\nRender, commit, and push your changes to GitHub with an appropriate commit message.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\n\n\nQuestion 10\nDid you select your pages on Gradescope? You don‚Äôt need to write an answer for this question, if you select your pages when you upload your lab to Gradescope, you‚Äôll get full points on this question. Otherwise, you‚Äôll get a 0 on this question.2",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#submission",
    "href": "labs/lab-2.html#submission",
    "title": "Lab 2 - Data wrangling",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered ‚Äúon time‚Äù.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark all the pages associated with question. All the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#grading",
    "href": "labs/lab-2.html#grading",
    "title": "Lab 2 - Data wrangling",
    "section": "Grading",
    "text": "Grading\nThe lab is graded out of a total of 50 points.\nOn Questions 1 through 9, you can earn up to 5 points on each question:\n\n5: Response shows excellent understanding and addresses all or almost all of the rubric items.\n4: Response shows good understanding and addresses most of the rubric items.\n3: Response shows understanding and addresses a majority of the rubric items.\n2: Response shows effort and misses many of the rubric items.\n1: Response does not show sufficient effort or understanding and/or is largely incomplete.\n0: No attempt.\n\nOn Question 10, you can earn either 0 or 5 points for selecting questions and pages on Gradescope:\n\n5: Selected questions and pages on Gradescope.\n0: Did not select some or all questions and pages on Gradescope.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#footnotes",
    "href": "labs/lab-2.html#footnotes",
    "title": "Lab 2 - Data wrangling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRemember, haikus not novellas when writing code!‚Ü©Ô∏é\nWe‚Äôre assigning points to this seemingly trivial task because not selecting your pages and questions will greatly slow down the grading. So we want to make sure you‚Äôre properly motivated to complete this task!‚Ü©Ô∏é",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-4.html",
    "href": "labs/lab-4.html",
    "title": "Lab 4 - Web scraping and ethics",
    "section": "",
    "text": "In this lab you‚Äôll build the data wrangling and visualization skills you‚Äôve developed so far and data tidying and joining to your repertoire.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you‚Äôve completed the labs so far and doesn‚Äôt repeat setup and overview content from those labs. If you have not yet done those, you should go back and review the previous labs before starting on this one.\n\n\n\n\nBy the end of the lab, you will‚Ä¶\n\nBe able to scrape data from web pages using the rvest package\nClean and analyze the data you have scraped\nCome up with your own questions about the data and answer them\nBe able to use the robotstxt package as well as read the Terms of Use/Service of a website to check if a website allows scraping\nRead articles on the ethics of AI tools and LLMs and reflect on the implications of these tools for society\n\n\n\n\nLog in to RStudio, clone your lab-4 repo from GitHub, open your lab-4.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\n\n\n\nGo to the course organization at github.com/sta199-s24 organization on GitHub. Click on the repo with the prefix lab-3. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you‚Äôll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ‚ûõ New Project ‚ûõVersion Control ‚ûõ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-3.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\n\n\n\nIn lab-3.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., ‚ÄúAdded author name‚Äù), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\nIn this lab we will work with the following packages:\n\ntidyverse: for tidy data wrangling and visualization\nrvest: for data scraping\nrobotstxt: for checking the robots.txt files of websites for permission to scrape data\nknitr: for making a pretty table\n\nSome of the later questions in the lab ask you to come up with your own questions about the data and answer them. If this requires additional packages, you should feel free to load them as well.\n\n\n\nAs we‚Äôve discussed in lecture, your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nIn addition, the code should all the code should be be able to be read (not run off the page) when you render to PDF. Make sure that is the case, and add line breaks where the code is running off the page.1\n\n\n\n\n\n\nNote\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#learning-objectives",
    "href": "labs/lab-4.html#learning-objectives",
    "title": "Lab 4 - Web scraping and ethics",
    "section": "",
    "text": "By the end of the lab, you will‚Ä¶\n\nBe able to scrape data from web pages using the rvest package\nClean and analyze the data you have scraped\nCome up with your own questions about the data and answer them\nBe able to use the robotstxt package as well as read the Terms of Use/Service of a website to check if a website allows scraping\nRead articles on the ethics of AI tools and LLMs and reflect on the implications of these tools for society",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#getting-started",
    "href": "labs/lab-4.html#getting-started",
    "title": "Lab 4 - Web scraping and ethics",
    "section": "",
    "text": "Log in to RStudio, clone your lab-4 repo from GitHub, open your lab-4.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\n\n\n\nGo to the course organization at github.com/sta199-s24 organization on GitHub. Click on the repo with the prefix lab-3. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you‚Äôll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ‚ûõ New Project ‚ûõVersion Control ‚ûõ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-3.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\n\n\n\nIn lab-3.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., ‚ÄúAdded author name‚Äù), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#packages",
    "href": "labs/lab-4.html#packages",
    "title": "Lab 4 - Web scraping and ethics",
    "section": "",
    "text": "In this lab we will work with the following packages:\n\ntidyverse: for tidy data wrangling and visualization\nrvest: for data scraping\nrobotstxt: for checking the robots.txt files of websites for permission to scrape data\nknitr: for making a pretty table\n\nSome of the later questions in the lab ask you to come up with your own questions about the data and answer them. If this requires additional packages, you should feel free to load them as well.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#guidelines",
    "href": "labs/lab-4.html#guidelines",
    "title": "Lab 4 - Web scraping and ethics",
    "section": "",
    "text": "As we‚Äôve discussed in lecture, your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nIn addition, the code should all the code should be be able to be read (not run off the page) when you render to PDF. Make sure that is the case, and add line breaks where the code is running off the page.1\n\n\n\n\n\n\nNote\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#part-1---scraping-data-from-web-pages",
    "href": "labs/lab-4.html#part-1---scraping-data-from-web-pages",
    "title": "Lab 4 - Web scraping and ethics",
    "section": "Part 1 - Scraping data from web pages",
    "text": "Part 1 - Scraping data from web pages\n\nQuestion 1\n\n\n\n\n\n\nImportant\n\n\n\nYou do not need to do anything in your Quarto file for this question. All of the work for this question will be done in lab-4-clubs-scrape.R.\n\n\nYour task for this question is to scrape data on Duke Student Groups from https://dukegroups.com/club_signup?view=all. Scroll down and click on load all groups.\nYou will do this in lab-4-clubs-scrape.R, which gives some scaffolding for you to complete this task. The goal is to scrape information on\n\nName of club: names\nLink to club page: urls\nType of club: club_types\nResources of club: resources\nMembership type of club: membership_types\nCheckboxes that indicate the club is open / closed for joining: membership_status\n\nThe scheme shown in the image should also help you figure out which pieces of information come from which parts of the website.\n\n\n\n\n\nYou will scrape each of these as individual vectors, clean them up a bit, and then bring them together in a data frame (a tibble) and write it out to a CSV file called clubs.csv in the data folder of your project/repository.\n\n\n\n\n\n\nHint\n\n\n\nThere are some hints for cleaning the data in the script provided for you. For example, some of the fields you scrape will have some extraneous characters in them like \\ns, \\rs, etc. Two examples are provided below.\n\nname &lt;- \"\\r Academic Advising Center\\r\"\nurl &lt;- \"\\r\\n\\t\\t\\t\\t\\t\\t\\t\\thttps://dukegroups.com/AOTA/\\r\\n\\t\\t\\t\\t\\t\\t\\t\"\n\nTo clean these up, first, we would want to remove the extraneous characters. The stringr package (which comes with the tidyverse) offers some great functions for dealing with such nuisance, see https://stringr.tidyverse.org/reference/index.html for a full list. In this case, we can use the following steps:\n\nstr_remove() to remove the character(s) once or str_remove_all() to remove all occurences of the character(s) we don‚Äôt want\n\n\nname |&gt;\n  str_remove_all(\"\\r\")\nurl |&gt;\n  str_remove_all(\"\\r\") |&gt;\n  str_remove_all(\"\\n\") |&gt;\n  str_remove_all(\"\\t\")\n\n\nstr_trim() for trimming white space at the beginning and end of text strings\n\n\nname |&gt;\n  str_remove_all(\"\\r\") |&gt;\n  str_trim()\n\nThese types of functions will be helpful for cleaning the data you scrape as well.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#part-2---data-cleaning",
    "href": "labs/lab-4.html#part-2---data-cleaning",
    "title": "Lab 4 - Web scraping and ethics",
    "section": "Part 2 - Data cleaning",
    "text": "Part 2 - Data cleaning\n\nQuestion 2\nRead the clubs.csv file you created in Question 1 into your Quarto document.\nThe club_type_detail variable contains two pieces of information for most (though not all) clubs:\n\nMany of the entries are of the form House/Quad Council - Housing & Residence Life or Open Membership (DSG) - Faith, Religion, & Spirituality, where the piece before the hyphen (-) is club_type while the piece after the hyphen is detail.\nSome of the entries are of the form Student Government or Student Affairs Unit, basically just club_type but no detail.\n\nSeparate the club_type variable into two, club_type and detail, and then trim any extraneous white space from the resulting variables, as needed. Save the resulting dataset with these two new variables as clubs, i.e., overwrite the data frame.\nThen, display the first 10 rows of the dataset, relocate()ing club_type and detail variables to the beginning of the dataset to make sure they appear in the output in your rendered document.\n\n\nQuestion 3\nAnother variable that needs some cleaning up is membership_status. Currently it should either be NA or contain some text that says \"Select ... to register for this group\". Recode this variable to say \"Closed\" if the current value is NA or \"Open\" otherwise. Save the resulting dataset with these two new variables as clubs, i.e., overwrite the data frame.\nThen, display the first 10 rows of the dataset, relocate()ing membership_status to the beginning of the dataset to make sure it appears in the output in your rendered document.\n\n\n\n\n\n\nWarning\n\n\n\nAt this point you should have a clubs dataset with seven columns in the following order:\n\nname\nresources\nclub_type\ndetail: May be blank for some clubs\nmembership_type\nmembership_status: with values Open and Closed\nurl\n\nIf your dataset has a structure of columns different than what‚Äôs outlined above, go back to earlier exercises and review your answers.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#part-3---data-analysis",
    "href": "labs/lab-4.html#part-3---data-analysis",
    "title": "Lab 4 - Web scraping and ethics",
    "section": "Part 3 - Data analysis",
    "text": "Part 3 - Data analysis\n\nQuestion 4\nSolve each of the following questions (parts) with a single pipeline.\n\nFind the distinct membership_types and the number of clubs with each type of membership.\nFind the number of clubs that have a Mission statement.\nFind the clubs that are Greek and mention Faith in their detail.\n\n\n\nQuestion 5\nRecreate the following table in a single pipeline.\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\nFirst, count the number of clubs that fall into each club_type and membership_status.\nThen, pivot the resulting data frame so the levels of membership_status are across two columns as opposed to in a single column.\nRead the documentation for the pivoting function you‚Äôre using to discover how you can replace NAs with 0s while pivoting the data.\nCreate a new column Total that is the sum of Closed and Open columns.\nUse the kable() function (refer back to your take-home exam if you need a hint) to nicely format your table.\n\n\n\n\n\nQuestion 6\nAsk a simple question of interest to you about student clubs at Duke that you can answer with these data. Then, answer your question in a single pipeline and a brief narrative describing your findings. If your question is too complex to answer in a single pipeline, go back and revise your question.\n\n\nQuestion 7\nAsk another question of interest to you about student clubs at Duke that you can answer with a visualization of these data. Then, answer your question, with a visualization and a brief narrative describing your findings.\n\n\n\n\n\n\nNote\n\n\n\nIf you are collaborating with classmates and brainstorming possible questions together, make sure the questions you choose are unique to you.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#part-4---ethics",
    "href": "labs/lab-4.html#part-4---ethics",
    "title": "Lab 4 - Web scraping and ethics",
    "section": "Part 4 - Ethics",
    "text": "Part 4 - Ethics\n\n\n\n\n\n\nImportant\n\n\n\nThe following two questions ask you to summarize articles on data science ethics. You are not allowed to use Chat GPT or similar tools in answering these questions ‚Äì you must actually read the articles and summarize them yourself. Please be ethical, at a minimum when discussing ethics!\n\n\n\nQuestion 8\nFor each of the following websites, first determine whether you‚Äôre allowed to scrape data from them using tools we‚Äôve learned in this course.\nThen, read (the relevant portions of their) Terms of Use/Service.\n\nESPN: https://www.espn.com / https://disneytermsofuse.com/english/#License-Grant-and-Restrictions\nX/Twitter: https://twitter.com / https://twitter.com/en/tos\nRotten Tomatoes: https://www.rottentomatoes.com / https://www.rottentomatoes.com/policies/terms-of-use\n\nFinally, summarize your findings about whether you can or cannot scrape data from these websites in 1 sentence for each website. Additionally, quote the relevant sentence(s) from the Terms of Use/Service.\n\n\n\n\n\n\nHint\n\n\n\nIn the Terms of Use/Service documents, it might be productive to search for keywords like ‚Äúscrape‚Äù or ‚Äúscraping‚Äù to find the relevant portions.\n\n\n\n\nQuestion 9\nOne current ethical discussion in data science involves the training of ‚ÄúLarge Language Models‚Äù such as ChatGPT. These models are trained using massive corpora (document sets) that include large amounts of work that is covered under copyright law. Read the following two articles:\n\nDo Large Language Models Violate Copyright Law?\nReexamining ‚ÄúFair Use‚Äù in the Age of AI\n\nWrite a short paragraph (maximum 8 sentences) discussing the arguments on both sides of the discussion over copyright in training large language models.\n\n\nQuestion 10\nAnother major ethical discussion in data science resolves around discriminatory biases in machine learning models. These biases can have real-world impacts in lending, criminal justice, hiring, and more. Many of these algorithms are so-called ‚Äúblack boxes‚Äù, meaning the exact process they take from input to output is unclear. Read the following articles:\n\nAmazon scraps secret AI recruiting tool that showed bias against\nThe Atlantic: The False Promise of Risk Assessment\n\nWrite a short paragraph (maximum 8 sentences) discussing the nature of biases in machine learning and in datasets, and any possible solutions that could help limit those biases.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#submission",
    "href": "labs/lab-4.html#submission",
    "title": "Lab 4 - Web scraping and ethics",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered ‚Äúon time‚Äù.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you‚Äôll be prompted to submit it.\nMark all the pages associated with question. All the pages of your lab should be associated with at least one question (i.e., should be ‚Äúchecked‚Äù).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#grading",
    "href": "labs/lab-4.html#grading",
    "title": "Lab 4 - Web scraping and ethics",
    "section": "Grading",
    "text": "Grading\nThe lab is graded out of a total of 50 points.\nYou can earn up to 5 points on each question:\n\n5: Response shows excellent understanding and addresses all or almost all of the rubric items.\n4: Response shows good understanding and addresses most of the rubric items.\n3: Response shows understanding and addresses a majority of the rubric items.\n2: Response shows effort and misses many of the rubric items.\n1: Response does not show sufficient effort or understanding and/or is largely incomplete.\n0: No attempt.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#footnotes",
    "href": "labs/lab-4.html#footnotes",
    "title": "Lab 4 - Web scraping and ethics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRemember, haikus not novellas when writing code!‚Ü©Ô∏é",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "slides/19-logistic-regression.html#while-you-wait-for-class-to-begin",
    "href": "slides/19-logistic-regression.html#while-you-wait-for-class-to-begin",
    "title": "Logistic regression",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\n\nAny questions from prepare materials?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#duke-community-standard",
    "href": "slides/19-logistic-regression.html#duke-community-standard",
    "title": "Logistic regression",
    "section": "Duke Community Standard",
    "text": "Duke Community Standard\nDuke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, respect, and accountability. Citizens of this community commit to reflect upon and uphold these principles in all academic and nonacademic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard:\n\n¬†I will not lie, cheat, or steal in my academic endeavors;\n¬†I will conduct myself honorably in all my endeavors; and\n¬†I will act if the Standard is compromised.\n\nhttps://trinity.duke.edu/undergraduate/academic-policies/community-standard-student-conduct"
  },
  {
    "objectID": "slides/19-logistic-regression.html#duke-community-standard-1",
    "href": "slides/19-logistic-regression.html#duke-community-standard-1",
    "title": "Logistic regression",
    "section": "Duke Community Standard",
    "text": "Duke Community Standard\n‚ÄúDuke University has high expectations for students‚Äô scholarship and conduct. In accepting admission, students indicate their willingness to subscribe to and be governed by the rules and regulations of the university, which flow from the Duke Community Standard. These policies reflect the Duke Community Standard‚Äôs fundamental values‚Äîhonesty, fairness, respect, and accountability. Undergraduates acknowledge the right of the university to take disciplinary action, including suspension or expulsion, for failure to abide by the regulations or for other conduct adjudged unsatisfactory or detrimental to the university community.¬† Students and groups may be held accountable for any violation of university policy that may or may not be included in this guide, whether on or off campus.‚Äù\nhttps://trinity.duke.edu/undergraduate/academic-policies/community-standard-student-conduct"
  },
  {
    "objectID": "slides/19-logistic-regression.html#basic-guidelines",
    "href": "slides/19-logistic-regression.html#basic-guidelines",
    "title": "Logistic regression",
    "section": "Basic guidelines",
    "text": "Basic guidelines\n\nBe a Good Human\n\n\n\nUse electronic devices for things related to coursework only and in a way that does not distract your classmates\n\nNo videos on cell phones\nNo phone calls!\n\nTake off your headphones\n\nIf you need an accommodation for wearing headphones in class, reach out to SDAO to get this offcially approved\n\nKeep chatter to ‚Äúyour turn‚Äù portions or limited to clarification questions\nIf you have a guest in class, make sure they are aware of the DCS and take responsibility for their behaviour"
  },
  {
    "objectID": "slides/19-logistic-regression.html#announcements",
    "href": "slides/19-logistic-regression.html#announcements",
    "title": "Logistic regression",
    "section": "Announcements",
    "text": "Announcements\n\nPeer eval 2 is due Sunday night, results will be published on Monday\nLab 6 is due on Monday:\n\nRender your document. If your code is running off the page so we can‚Äôt see your entire code, we will not evaluate any of it. The question will automatically receive a 0. This is something you can and should verify before you turn in your work.\nIf you‚Äôre using functions that are not introduced in the course materials, you must cite your sources. Failure to do so is a violation of the Duke Community Standard and will be treated as such.\n\nLab 7 will cover material from this week and next week. Start to working through prepare materials between now and Monday."
  },
  {
    "objectID": "slides/19-logistic-regression.html#recap-ae-13-modeling-loans",
    "href": "slides/19-logistic-regression.html#recap-ae-13-modeling-loans",
    "title": "Logistic regression",
    "section": "Recap: ae-13-modeling-loans",
    "text": "Recap: ae-13-modeling-loans\n\nWhat is the practical difference between a model with parallel and non-parallel lines?\nWhat is the definition of R-squared?\nWhy do we choose models based on adjusted R-squared and not R-squared?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#predict-interest-rate",
    "href": "slides/19-logistic-regression.html#predict-interest-rate",
    "title": "Logistic regression",
    "section": "Predict interest rate‚Ä¶",
    "text": "Predict interest rate‚Ä¶\nfrom credit utilization and homeownership\n\nrate_util_home_fit &lt;- linear_reg() |&gt;\n  fit(interest_rate ~ credit_util + homeownership, data = loans)\n\n\ntidy(rate_util_home_fit)\n\n# A tibble: 4 √ó 5\n  term                  estimate std.error statistic   p.value\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              9.93      0.140    70.8   0        \n2 credit_util              5.34      0.207    25.7   2.20e-141\n3 homeownershipMortgage    0.696     0.121     5.76  8.71e-  9\n4 homeownershipOwn         0.128     0.155     0.827 4.08e-  1"
  },
  {
    "objectID": "slides/19-logistic-regression.html#intercept",
    "href": "slides/19-logistic-regression.html#intercept",
    "title": "Logistic regression",
    "section": "Intercept",
    "text": "Intercept\n\n\n# A tibble: 4 √ó 5\n  term                  estimate std.error statistic   p.value\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              9.93      0.140    70.8   0        \n2 credit_util              5.34      0.207    25.7   2.20e-141\n3 homeownershipMortgage    0.696     0.121     5.76  8.71e-  9\n4 homeownershipOwn         0.128     0.155     0.827 4.08e-  1\n\n\n\nIntercept: Loan applicants who rent and have 0 credit utilization are predicted to receive an interest rate of 9.93%, on average."
  },
  {
    "objectID": "slides/19-logistic-regression.html#slopes",
    "href": "slides/19-logistic-regression.html#slopes",
    "title": "Logistic regression",
    "section": "Slopes",
    "text": "Slopes\n\n\n# A tibble: 4 √ó 5\n  term                  estimate std.error statistic   p.value\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              9.93      0.140    70.8   0        \n2 credit_util              5.34      0.207    25.7   2.20e-141\n3 homeownershipMortgage    0.696     0.121     5.76  8.71e-  9\n4 homeownershipOwn         0.128     0.155     0.827 4.08e-  1\n\n\n\n\nAll else held constant, for each additional percent credit utilization is higher, interest rate is predicted to be higher, on average, by 0.0534%.\nAll else held constant, the model predicts that loan applicants who have a mortgage for their home receive 0.696% higher interest rate than those who rent their home, on average.\nAll else held constant, the model predicts that loan applicants who own their home receive 0.128% higher interest rate than those who rent their home, on average."
  },
  {
    "objectID": "slides/19-logistic-regression.html#predict-loginterest-rate",
    "href": "slides/19-logistic-regression.html#predict-loginterest-rate",
    "title": "Logistic regression",
    "section": "Predict log(interest rate)",
    "text": "Predict log(interest rate)\n\nrate_log_cc_fit &lt;- linear_reg() |&gt;\n  fit(log(interest_rate) ~ credit_checks, data = loans)\n\ntidy(rate_log_cc_fit)\n\n# A tibble: 2 √ó 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     2.39     0.00512     468.  0       \n2 credit_checks   0.0236   0.00166      14.2 2.39e-45"
  },
  {
    "objectID": "slides/19-logistic-regression.html#model",
    "href": "slides/19-logistic-regression.html#model",
    "title": "Logistic regression",
    "section": "Model",
    "text": "Model\n\n\n# A tibble: 2 √ó 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     2.39     0.00512     468.  0       \n2 credit_checks   0.0236   0.00166      14.2 2.39e-45\n\n\n\n\\[\n\\widehat{log(interest~rate)} = 2.39 + 0.0236 \\times credit~checks\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#slope",
    "href": "slides/19-logistic-regression.html#slope",
    "title": "Logistic regression",
    "section": "Slope",
    "text": "Slope\n\n\n# A tibble: 2 √ó 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     2.39     0.00512     468.  0       \n2 credit_checks   0.0236   0.00166      14.2 2.39e-45\n\n\n\nFor each additional credit check, log of interest rate is predicted to be higher, on average, by 0.0236%."
  },
  {
    "objectID": "slides/19-logistic-regression.html#slope-1",
    "href": "slides/19-logistic-regression.html#slope-1",
    "title": "Logistic regression",
    "section": "Slope",
    "text": "Slope\n\\[\nlog(interest~rate_{x+1}) - log(interest~rate_{x}) =  0.0236\n\\]\n\n\\[\nlog(\\frac{interest~rate_{x+1}}{interest~rate_{x}}) = 0.0236\n\\]\n\n\n\\[\ne^{log(\\frac{interest~rate_{x+1}}{interest~rate_{x}})} = e^{0.0236}\n\\]\n\n\n\\[\n\\frac{interest~rate_{x+1}}{interest~rate_{x}} = 1.024\n\\]\n\n\nFor each additional credit check, interest rate is predicted to be higher, on average, by a factor of 1.024."
  },
  {
    "objectID": "slides/19-logistic-regression.html#what-is-logistic-regression",
    "href": "slides/19-logistic-regression.html#what-is-logistic-regression",
    "title": "Logistic regression",
    "section": "What is logistic regression?",
    "text": "What is logistic regression?\n\n\n\nSimilar to linear regression‚Ä¶. but\nModeling tool when our response is categorical"
  },
  {
    "objectID": "slides/19-logistic-regression.html#modelling-binary-outcomes",
    "href": "slides/19-logistic-regression.html#modelling-binary-outcomes",
    "title": "Logistic regression",
    "section": "Modelling binary outcomes",
    "text": "Modelling binary outcomes\n\nVariables with binary outcomes follow the Bernouilli distribution:\n\n\\(y_i \\sim Bern(p)\\)\n\\(p\\): Probability of success\n\\(1-p\\): Probability of failure\n\nWe can‚Äôt model \\(y\\) directly, so instead we model \\(p\\)"
  },
  {
    "objectID": "slides/19-logistic-regression.html#linear-model",
    "href": "slides/19-logistic-regression.html#linear-model",
    "title": "Logistic regression",
    "section": "Linear model",
    "text": "Linear model\n\\[\np_i = \\beta_o + \\beta_1 \\times X_1 + \\cdots + \\epsilon\n\\]\n\nBut remember that \\(p\\) must be between 0 and 1\nWe need a link function that transforms the linear model to have an appropriate range"
  },
  {
    "objectID": "slides/19-logistic-regression.html#logit-link-function",
    "href": "slides/19-logistic-regression.html#logit-link-function",
    "title": "Logistic regression",
    "section": "Logit link function",
    "text": "Logit link function\nThe logit function take values between 0 and 1 (probabilities) and maps them to values in the range negative infinity to positive infinity:\n\\[\nlogit(p) = log \\bigg( \\frac{p}{1 - p} \\bigg)\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#this-isnt-exactly-what-we-need-though..",
    "href": "slides/19-logistic-regression.html#this-isnt-exactly-what-we-need-though..",
    "title": "Logistic regression",
    "section": "This isn‚Äôt exactly what we need though‚Ä¶..",
    "text": "This isn‚Äôt exactly what we need though‚Ä¶..\n\nRecall, the goal is to take values between -\\(\\infty\\) and \\(\\infty\\) and map them to probabilities.\nWe need the opposite of the link function‚Ä¶ or the inverse\nTaking the inverse of the logit function will map arbitrary real values back to the range [0, 1]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#generalized-linear-model",
    "href": "slides/19-logistic-regression.html#generalized-linear-model",
    "title": "Logistic regression",
    "section": "Generalized linear model",
    "text": "Generalized linear model\n\nWe model the logit (log-odds) of \\(p\\) :\n\n\\[\nlogit(p) = log \\bigg( \\frac{p}{1 - p} \\bigg) = \\beta_o + \\beta_1 \\times X1_i + \\cdots + \\epsilon\n\\]\n\nThen take the inverse to obtain the predicted \\(p\\):\n\n\\[\np_i = \\frac{e^{\\beta_o + \\beta_1 \\times X1_i + \\cdots + \\epsilon}}{1 + e^{\\beta_o + \\beta_1 \\times X1_i + \\cdots + \\epsilon}}\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#a-logistic-model-visualized",
    "href": "slides/19-logistic-regression.html#a-logistic-model-visualized",
    "title": "Logistic regression",
    "section": "A logistic model visualized",
    "text": "A logistic model visualized"
  },
  {
    "objectID": "slides/19-logistic-regression.html#takeaways",
    "href": "slides/19-logistic-regression.html#takeaways",
    "title": "Logistic regression",
    "section": "Takeaways",
    "text": "Takeaways\n\nGeneralized linear models allow us to fit models to predict non-continuous outcomes\nPredicting binary outcomes requires modeling the log-odds of success, where p = probability of success\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/11-web-scraping.html#while-you-wait-for-class-to-begin",
    "href": "slides/11-web-scraping.html#while-you-wait-for-class-to-begin",
    "title": "Web scraping",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\n\n\nIf you haven‚Äôt yet done so: Install a Chrome browser and the SelectorGadget extension:\n\nChrome\nSelectorGadget\n\nGo to your ae repo, commit any remaining changes, push, and then pull for today‚Äôs application exercise."
  },
  {
    "objectID": "slides/11-web-scraping.html#announcements",
    "href": "slides/11-web-scraping.html#announcements",
    "title": "Web scraping",
    "section": "Announcements",
    "text": "Announcements\n\nLab 4 on Monday\nChallenge: Resist the urge to ask a GPT before spending some time thinking!"
  },
  {
    "objectID": "slides/11-web-scraping.html#reading-the-chronicle",
    "href": "slides/11-web-scraping.html#reading-the-chronicle",
    "title": "Web scraping",
    "section": "Reading The Chronicle",
    "text": "Reading The Chronicle\n\nHow often do you read The Chronicle?\n\nEvery day\n3-5 times a week\nOnce a week\nRarely"
  },
  {
    "objectID": "slides/11-web-scraping.html#reading-the-chronicle-1",
    "href": "slides/11-web-scraping.html#reading-the-chronicle-1",
    "title": "Web scraping",
    "section": "Reading The Chronicle",
    "text": "Reading The Chronicle\n\nWhat do you think is the most common word in the titles of The Chronicle opinion pieces?"
  },
  {
    "objectID": "slides/11-web-scraping.html#analyzing-the-chronicle",
    "href": "slides/11-web-scraping.html#analyzing-the-chronicle",
    "title": "Web scraping",
    "section": "Analyzing The Chronicle",
    "text": "Analyzing The Chronicle"
  },
  {
    "objectID": "slides/11-web-scraping.html#reading-the-chronicle-2",
    "href": "slides/11-web-scraping.html#reading-the-chronicle-2",
    "title": "Web scraping",
    "section": "Reading The Chronicle",
    "text": "Reading The Chronicle\n\nHow do you think the sentiments in opinion pieces in The Chronicle compare across authors? Roughly the same? Wildly different? Somewhere in between?"
  },
  {
    "objectID": "slides/11-web-scraping.html#analyzing-the-chronicle-1",
    "href": "slides/11-web-scraping.html#analyzing-the-chronicle-1",
    "title": "Web scraping",
    "section": "Analyzing The Chronicle",
    "text": "Analyzing The Chronicle"
  },
  {
    "objectID": "slides/11-web-scraping.html#all-of-this-analysis-is-done-in-r",
    "href": "slides/11-web-scraping.html#all-of-this-analysis-is-done-in-r",
    "title": "Web scraping",
    "section": "All of this analysis is done in R!",
    "text": "All of this analysis is done in R!\n\n(mostly) with tools you already know!"
  },
  {
    "objectID": "slides/11-web-scraping.html#common-words-in-the-chronicle-titles",
    "href": "slides/11-web-scraping.html#common-words-in-the-chronicle-titles",
    "title": "Web scraping",
    "section": "Common words in The Chronicle titles",
    "text": "Common words in The Chronicle titles\nCode for the earlier plot:\n\nchronicle |&gt;\n  tidytext::unnest_tokens(word, title) |&gt;\n  anti_join(tidytext::stop_words) |&gt;\n  count(word, sort = TRUE) |&gt;\n  slice_head(n = 20) |&gt;\n  mutate(word = fct_reorder(word, n)) |&gt;\n  ggplot(aes(y = word, x = n, fill = log(n))) +\n  geom_col(show.legend = FALSE) +\n  theme_minimal(base_size = 16) +\n  labs(\n    x = \"Number of mentions\",\n    y = \"Word\",\n    title = \"The Chronicle - Opinion pieces\",\n    subtitle = \"Common words in the 500 most recent opinion pieces\",\n    caption = \"Source: Data scraped from The Chronicle on Feb 21, 2024\"\n  ) +\n  theme(\n    plot.title.position = \"plot\",\n    plot.caption = element_text(color = \"gray30\")\n  )"
  },
  {
    "objectID": "slides/11-web-scraping.html#avg-sentiment-scores-of-abstracts",
    "href": "slides/11-web-scraping.html#avg-sentiment-scores-of-abstracts",
    "title": "Web scraping",
    "section": "Avg sentiment scores of abstracts",
    "text": "Avg sentiment scores of abstracts\nCode for the earlier plot:\n\nchronicle |&gt;\n  tidytext::unnest_tokens(word, abstract) |&gt;\n  anti_join(tidytext::stop_words) |&gt;\n  left_join(tidytext::get_sentiments(\"afinn\")) |&gt; \n  group_by(author, title) |&gt;\n  summarize(total_sentiment = sum(value, na.rm = TRUE), .groups = \"drop\") |&gt;\n  group_by(author) |&gt;\n  summarize(\n    n_articles = n(),\n    avg_sentiment = mean(total_sentiment, na.rm = TRUE),\n  ) |&gt;\n  filter(n_articles &gt; 1 & !is.na(author)) |&gt;\n  arrange(desc(avg_sentiment)) |&gt;\n  slice(c(1:10, 49:58)) |&gt;\n  mutate(\n    author = fct_reorder(author, avg_sentiment),\n    neg_pos = if_else(avg_sentiment &lt; 0, \"neg\", \"pos\"),\n    label_position = if_else(neg_pos == \"neg\", 0.25, -0.25)\n  ) |&gt;\n  ggplot(aes(y = author, x = avg_sentiment)) +\n  geom_col(aes(fill = neg_pos), show.legend = FALSE) +\n  geom_text(\n    aes(x = label_position, label = author, color = neg_pos),\n    hjust = c(rep(1,10), rep(0, 10)),\n    show.legend = FALSE,\n    fontface = \"bold\"\n  ) +\n  geom_text(\n    aes(label = round(avg_sentiment, 1)),\n    hjust = c(rep(1.25,10), rep(-0.25, 10)),\n    color = \"white\",\n    fontface = \"bold\"\n  ) +\n  scale_fill_manual(values = c(\"neg\" = \"#4d4009\", \"pos\" = \"#FF4B91\")) +\n  scale_color_manual(values = c(\"neg\" = \"#4d4009\", \"pos\" = \"#FF4B91\")) +\n  scale_x_continuous(breaks = -5:5, minor_breaks = NULL) +\n  scale_y_discrete(breaks = NULL) +\n  coord_cartesian(xlim = c(-5, 5)) +\n  labs(\n    x = \"negative  ‚Üê     Average sentiment score (AFINN)     ‚Üí  positive\",\n    y = NULL,\n    title = \"The Chronicle - Opinion pieces\\nAverage sentiment scores of abstracts by author\",\n    subtitle = \"Top 10 average positive and negative scores\",\n    caption = \"Source: Data scraped from The Chronicle on Feb 21, 2024\"\n  ) +\n  theme_void(base_size = 16) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5, margin = unit(c(0.5, 0, 1, 0), \"lines\")),\n    axis.text.y = element_blank(),\n    plot.caption = element_text(color = \"gray30\")\n  )"
  },
  {
    "objectID": "slides/11-web-scraping.html#where-is-the-data-coming-from",
    "href": "slides/11-web-scraping.html#where-is-the-data-coming-from",
    "title": "Web scraping",
    "section": "Where is the data coming from?",
    "text": "Where is the data coming from?\n\nhttps://www.dukechronicle.com/section/opinion"
  },
  {
    "objectID": "slides/11-web-scraping.html#where-is-the-data-coming-from-1",
    "href": "slides/11-web-scraping.html#where-is-the-data-coming-from-1",
    "title": "Web scraping",
    "section": "Where is the data coming from?",
    "text": "Where is the data coming from?\n\n\n\n\n\n\n\n\n\nchronicle\n\n# A tibble: 500 √ó 6\n   title                                           author date       abstract column url  \n   &lt;chr&gt;                                           &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;\n 1 All the world‚Äôs a stage                         Anna ‚Ä¶ 2024-02-22 If we a‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n 2 Words that matter: For Alexei Navalny           Carol‚Ä¶ 2024-02-22 In some‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n 3 Which would you save: Friend or romantic partn‚Ä¶ Jess ‚Ä¶ 2024-02-22 Love sh‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n 4 Happiness is not what you‚Äôre looking for        Paul ‚Ä¶ 2024-02-21 We hing‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n 5 Closing Duke's Herbarium: A fear of long-term ‚Ä¶ Matth‚Ä¶ 2024-02-21 Without‚Ä¶ LETTE‚Ä¶ http‚Ä¶\n 6 CS Majors launch 'ambiguous and labelless rela‚Ä¶ Monda‚Ä¶ 2024-02-20 Unlike ‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n 7 The fear of being single                        Heidi‚Ä¶ 2024-02-20 But it ‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n 8 Save the Duke Herbarium                         Henry‚Ä¶ 2024-02-17 The Duk‚Ä¶ LETTE‚Ä¶ http‚Ä¶\n 9 What Duke can learn from retiring ex-president‚Ä¶ Rober‚Ä¶ 2024-02-17 In Duke‚Ä¶ GUEST‚Ä¶ http‚Ä¶\n10 Love, love                                      Gabri‚Ä¶ 2024-02-16 Somehow‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n# ‚Ñπ 490 more rows"
  },
  {
    "objectID": "slides/11-web-scraping.html#scraping-the-web-what-why",
    "href": "slides/11-web-scraping.html#scraping-the-web-what-why",
    "title": "Web scraping",
    "section": "Scraping the web: what? why?",
    "text": "Scraping the web: what? why?\n\nIncreasing amount of data is available on the web\nThese data are provided in an unstructured format: you can always copy&paste, but it‚Äôs time-consuming and prone to errors\nWeb scraping is the process of extracting this information automatically and transform it into a structured dataset\nTwo different scenarios:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy).\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files."
  },
  {
    "objectID": "slides/11-web-scraping.html#hypertext-markup-language",
    "href": "slides/11-web-scraping.html#hypertext-markup-language",
    "title": "Web scraping",
    "section": "Hypertext Markup Language",
    "text": "Hypertext Markup Language\nMost of the data on the web is still largely available as HTML - while it is structured (hierarchical) it often is not available in a form useful for analysis (flat / tidy).\n\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\n    &lt;br/&gt;\n    &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n    &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n    &lt;div class=\"contact\"&gt;\n      &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\n      &lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;\n      &lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;\n      &lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;"
  },
  {
    "objectID": "slides/11-web-scraping.html#rvest",
    "href": "slides/11-web-scraping.html#rvest",
    "title": "Web scraping",
    "section": "rvest",
    "text": "rvest\n\n\n\nThe rvest package makes basic processing and manipulation of HTML data straight forward\nIt‚Äôs designed to work with pipelines built with |&gt;\nrvest.tidyverse.org\n\n\nlibrary(rvest)"
  },
  {
    "objectID": "slides/11-web-scraping.html#rvest-1",
    "href": "slides/11-web-scraping.html#rvest-1",
    "title": "Web scraping",
    "section": "rvest",
    "text": "rvest\nCore functions:\n\nread_html() - read HTML data from a url or character string.\nhtml_elements() - select specified elements from the HTML document using CSS selectors (or xpath).\nhtml_element() - select a single element from the HTML document using CSS selectors (or xpath).\nhtml_table() - parse an HTML table into a data frame.\nhtml_text() / html_text2() - extract tag‚Äôs text content.\nhtml_name - extract a tag/element‚Äôs name(s).\nhtml_attrs - extract all attributes.\nhtml_attr - extract attribute value(s) by name."
  },
  {
    "objectID": "slides/11-web-scraping.html#html-rvest-xml2",
    "href": "slides/11-web-scraping.html#html-rvest-xml2",
    "title": "Web scraping",
    "section": "html, rvest, & xml2",
    "text": "html, rvest, & xml2\n\nhtml &lt;- \n'&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\n    &lt;br/&gt;\n    &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n    &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n    &lt;div class=\"contact\"&gt;\n      &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\n      &lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;\n      &lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;\n      &lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;'\n\n\n\nread_html(html)\n\n{html_document}\n&lt;html&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"&gt;\\n&lt;title ...\n[2] &lt;body&gt;\\n    &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\\n    &lt;br&gt;&lt;div class=\"name\" id=\"first ..."
  },
  {
    "objectID": "slides/11-web-scraping.html#selecting-elements",
    "href": "slides/11-web-scraping.html#selecting-elements",
    "title": "Web scraping",
    "section": "Selecting elements",
    "text": "Selecting elements\n\nread_html(html) |&gt; html_elements(\"p\")\n\n{xml_nodeset (1)}\n[1] &lt;p align=\"center\"&gt;Hello world!&lt;/p&gt;\n\n\n\n\nread_html(html) |&gt; html_elements(\"p\") |&gt; html_text()\n\n[1] \"Hello world!\"\n\n\n\n\n\nread_html(html) |&gt; html_elements(\"p\") |&gt; html_name()\n\n[1] \"p\"\n\n\n\n\n\nread_html(html) |&gt; html_elements(\"p\") |&gt; html_attrs()\n\n[[1]]\n   align \n\"center\" \n\n\n\n\n\nread_html(html) |&gt; html_elements(\"p\") |&gt; html_attr(\"align\")\n\n[1] \"center\""
  },
  {
    "objectID": "slides/11-web-scraping.html#more-selecting-tags",
    "href": "slides/11-web-scraping.html#more-selecting-tags",
    "title": "Web scraping",
    "section": "More selecting tags",
    "text": "More selecting tags\n\n\nread_html(html) |&gt; html_elements(\"div\")\n\n{xml_nodeset (7)}\n[1] &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n[2] &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n[3] &lt;div class=\"contact\"&gt;\\n      &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\\n      &lt;div class ...\n[4] &lt;div class=\"home\"&gt;555-555-1234&lt;/div&gt;\n[5] &lt;div class=\"home\"&gt;555-555-2345&lt;/div&gt;\n[6] &lt;div class=\"work\"&gt;555-555-9999&lt;/div&gt;\n[7] &lt;div class=\"fax\"&gt;555-555-8888&lt;/div&gt;\n\n\n\n\n\n\nread_html(html) |&gt; html_elements(\"div\") |&gt; html_text()\n\n[1] \"John\"                                                                                  \n[2] \"Doe\"                                                                                   \n[3] \"\\n      555-555-1234\\n      555-555-2345\\n      555-555-9999\\n      555-555-8888\\n    \"\n[4] \"555-555-1234\"                                                                          \n[5] \"555-555-2345\"                                                                          \n[6] \"555-555-9999\"                                                                          \n[7] \"555-555-8888\""
  },
  {
    "objectID": "slides/11-web-scraping.html#css-selectors",
    "href": "slides/11-web-scraping.html#css-selectors",
    "title": "Web scraping",
    "section": "CSS selectors",
    "text": "CSS selectors\n\nWe will use a tool called SelectorGadget to help us identify the HTML elements of interest by constructing a CSS selector which can be used to subset the HTML document.\n\n\n\nSome examples of basic selector syntax is below,\n\n\n\n\n\n\n\n\n\n\nSelector\nExample\nDescription\n\n\n\n\n.class\n.title\nSelect all elements with class=‚Äútitle‚Äù\n\n\n#id\n#name\nSelect all elements with id=‚Äúname‚Äù\n\n\nelement\np\nSelect all &lt;p&gt; elements\n\n\nelement element\ndiv p\nSelect all &lt;p&gt; elements inside a &lt;div&gt; element\n\n\nelement&gt;element\ndiv &gt; p\nSelect all &lt;p&gt; elements with &lt;div&gt; as a parent\n\n\n[attribute]\n[class]\nSelect all elements with a class attribute\n\n\n[attribute=value]\n[class=title]\nSelect all elements with class=‚Äútitle‚Äù"
  },
  {
    "objectID": "slides/11-web-scraping.html#css-classes-and-ids",
    "href": "slides/11-web-scraping.html#css-classes-and-ids",
    "title": "Web scraping",
    "section": "CSS classes and ids",
    "text": "CSS classes and ids\n\nread_html(html) |&gt; html_elements(\".name\")\n\n{xml_nodeset (2)}\n[1] &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n[2] &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n\n\n\n\nread_html(html) |&gt; html_elements(\"div.name\")\n\n{xml_nodeset (2)}\n[1] &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;\n[2] &lt;div class=\"name\" id=\"last\"&gt;Doe&lt;/div&gt;\n\n\n\n\n\nread_html(html) |&gt; html_elements(\"#first\")\n\n{xml_nodeset (1)}\n[1] &lt;div class=\"name\" id=\"first\"&gt;John&lt;/div&gt;"
  },
  {
    "objectID": "slides/11-web-scraping.html#text-with-html_text-vs.-html_text2",
    "href": "slides/11-web-scraping.html#text-with-html_text-vs.-html_text2",
    "title": "Web scraping",
    "section": "Text with html_text() vs.¬†html_text2()",
    "text": "Text with html_text() vs.¬†html_text2()\n\nhtml = read_html(\n  \"&lt;p&gt;  \n    This is the first sentence in the paragraph.\n    This is the second sentence that should be on the same line as the first sentence.&lt;br&gt;This third sentence should start on a new line.\n  &lt;/p&gt;\"\n)\n\n\n\nhtml |&gt; html_text()\n\n[1] \"  \\n    This is the first sentence in the paragraph.\\n    This is the second sentence that should be on the same line as the first sentence.This third sentence should start on a new line.\\n  \"\n\nhtml |&gt; html_text2()\n\n[1] \"This is the first sentence in the paragraph. This is the second sentence that should be on the same line as the first sentence.\\nThis third sentence should start on a new line.\""
  },
  {
    "objectID": "slides/11-web-scraping.html#html-tables-with-html_table",
    "href": "slides/11-web-scraping.html#html-tables-with-html_table",
    "title": "Web scraping",
    "section": "HTML tables with html_table()",
    "text": "HTML tables with html_table()\n\nhtml_table = \n'&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;This is a title&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;table&gt;\n      &lt;tr&gt; &lt;th&gt;a&lt;/th&gt; &lt;th&gt;b&lt;/th&gt; &lt;th&gt;c&lt;/th&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;/tr&gt;\n      &lt;tr&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;5&lt;/td&gt; &lt;/tr&gt;\n    &lt;/table&gt;\n  &lt;/body&gt;\n&lt;/html&gt;'\n\n\n\nread_html(html_table) |&gt;\n  html_elements(\"table\") |&gt; \n  html_table()\n\n[[1]]\n# A tibble: 3 √ó 3\n      a     b     c\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     2     3\n2     2     3     4\n3     3     4     5"
  },
  {
    "objectID": "slides/11-web-scraping.html#selectorgadget",
    "href": "slides/11-web-scraping.html#selectorgadget",
    "title": "Web scraping",
    "section": "SelectorGadget",
    "text": "SelectorGadget\nSelectorGadget (selectorgadget.com) is a javascript based tool that helps you interactively build an appropriate CSS selector for the content you are interested in."
  },
  {
    "objectID": "slides/11-web-scraping.html#opinion-articles-in-the-chronicle",
    "href": "slides/11-web-scraping.html#opinion-articles-in-the-chronicle",
    "title": "Web scraping",
    "section": "Opinion articles in The Chronicle",
    "text": "Opinion articles in The Chronicle\nGo to https://www.dukechronicle.com/section/opinion?page=1&per_page=500.\n\nHow many articles are on the page?"
  },
  {
    "objectID": "slides/11-web-scraping.html#goal",
    "href": "slides/11-web-scraping.html#goal",
    "title": "Web scraping",
    "section": "Goal",
    "text": "Goal\n\n\n\nScrape data and organize it in a tidy format in R\nPerform light text parsing to clean data\nSummarize and visualze the data"
  },
  {
    "objectID": "slides/11-web-scraping.html#ae-09",
    "href": "slides/11-web-scraping.html#ae-09",
    "title": "Web scraping",
    "section": "ae-09",
    "text": "ae-09\n\n\nGo to the project navigator in RStudio (top right corner of your RStudio window) and open the project called ae.\nIf there are any uncommitted files, commit them, and then click Pull.\nOpen the file called chronicle-scrape.R and follow along."
  },
  {
    "objectID": "slides/11-web-scraping.html#recap",
    "href": "slides/11-web-scraping.html#recap",
    "title": "Web scraping",
    "section": "Recap",
    "text": "Recap\n\nUse the SelectorGadget identify tags for elements you want to grab\nUse rvest to first read the whole page (into R) and then parse the object you‚Äôve read in to the elements you‚Äôre interested in\nPut the components together in a data frame (a tibble) and analyze it like you analyze any other data"
  },
  {
    "objectID": "slides/11-web-scraping.html#a-new-r-workflow",
    "href": "slides/11-web-scraping.html#a-new-r-workflow",
    "title": "Web scraping",
    "section": "A new R workflow",
    "text": "A new R workflow\n\nWhen working in a Quarto document, your analysis is re-run each time you knit\nIf web scraping in a Quarto document, you‚Äôd be re-scraping the data each time you knit, which is undesirable (and not nice)!\nAn alternative workflow:\n\nUse an R script to save your code\nSaving interim data scraped using the code in the script as CSV or RDS files\nUse the saved data in your analysis in your Quarto document"
  },
  {
    "objectID": "slides/11-web-scraping.html#ethics-can-you-vs-should-you",
    "href": "slides/11-web-scraping.html#ethics-can-you-vs-should-you",
    "title": "Web scraping",
    "section": "Ethics: ‚ÄúCan you?‚Äù vs ‚ÄúShould you?‚Äù",
    "text": "Ethics: ‚ÄúCan you?‚Äù vs ‚ÄúShould you?‚Äù\n\n\n\n\n\n\n\nSource: Brian Resnick, Researchers just released profile data on 70,000 OkCupid users without permission, Vox."
  },
  {
    "objectID": "slides/11-web-scraping.html#can-you-vs-should-you",
    "href": "slides/11-web-scraping.html#can-you-vs-should-you",
    "title": "Web scraping",
    "section": "‚ÄúCan you?‚Äù vs ‚ÄúShould you?‚Äù",
    "text": "‚ÄúCan you?‚Äù vs ‚ÄúShould you?‚Äù"
  },
  {
    "objectID": "slides/11-web-scraping.html#challenges-unreliable-formatting",
    "href": "slides/11-web-scraping.html#challenges-unreliable-formatting",
    "title": "Web scraping",
    "section": "Challenges: Unreliable formatting",
    "text": "Challenges: Unreliable formatting\n\n\n\n\n\n\n\nalumni.duke.edu/news/notable-alumni"
  },
  {
    "objectID": "slides/11-web-scraping.html#challenges-data-broken-into-many-pages",
    "href": "slides/11-web-scraping.html#challenges-data-broken-into-many-pages",
    "title": "Web scraping",
    "section": "Challenges: Data broken into many pages",
    "text": "Challenges: Data broken into many pages"
  },
  {
    "objectID": "slides/11-web-scraping.html#workflow-screen-scraping-vs.-apis",
    "href": "slides/11-web-scraping.html#workflow-screen-scraping-vs.-apis",
    "title": "Web scraping",
    "section": "Workflow: Screen scraping vs.¬†APIs",
    "text": "Workflow: Screen scraping vs.¬†APIs\nTwo different scenarios for web scraping:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/12-chat-gpt.html#while-you-wait-for-class-to-begin",
    "href": "slides/12-chat-gpt.html#while-you-wait-for-class-to-begin",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\n\n\nOpen your lab-4 project, save and commit any pending changes, and push them to GitHub\nAny questions from prepare materials?"
  },
  {
    "objectID": "slides/12-chat-gpt.html#announcements",
    "href": "slides/12-chat-gpt.html#announcements",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Announcements",
    "text": "Announcements\n\nFill out TEAMMATES survey to provide feedback to your teammates (and to let us know how things are going)\nFill out the (optional) midterm course evaluation\nA note on AE scores ‚Äì they will continue to be updated!\nYet another survey: The Campus Culture Survey ‚Äì UG participation is very low, help lift it up!"
  },
  {
    "objectID": "slides/12-chat-gpt.html#lab-4-update",
    "href": "slides/12-chat-gpt.html#lab-4-update",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Lab 4 update",
    "text": "Lab 4 update\nPull changes, see that Question 1 in lab-4.qmd is updated with the following code chunk:\n```{r}\n#| file: lab-4-clubs-scrape.R\n#| eval: false\n```\nRender lab-4.qmd and commit and push your changes."
  },
  {
    "objectID": "slides/12-chat-gpt.html#goal",
    "href": "slides/12-chat-gpt.html#goal",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Goal",
    "text": "Goal\n\n\n\nScrape data and organize it in a tidy format in R\nPerform light text parsing to clean data\nSummarize and visualize the data"
  },
  {
    "objectID": "slides/12-chat-gpt.html#ae-09",
    "href": "slides/12-chat-gpt.html#ae-09",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "ae-09",
    "text": "ae-09\n\n\nGo to the project navigator in RStudio (top right corner of your RStudio window) and open the project called ae.\nIf there are any uncommitted files, commit them, and then click Pull.\nOpen the file called chronicle-scrape.R and follow along."
  },
  {
    "objectID": "slides/12-chat-gpt.html#recap",
    "href": "slides/12-chat-gpt.html#recap",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Recap",
    "text": "Recap\n\nUse the SelectorGadget identify tags for elements you want to grab\nUse rvest to first read the whole page (into R) and then parse the object you‚Äôve read in to the elements you‚Äôre interested in\nPut the components together in a data frame (a tibble) and analyze it like you analyze any other data"
  },
  {
    "objectID": "slides/12-chat-gpt.html#a-new-r-workflow",
    "href": "slides/12-chat-gpt.html#a-new-r-workflow",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "A new R workflow",
    "text": "A new R workflow\n\nWhen working in a Quarto document, your analysis is re-run each time you knit\nIf web scraping in a Quarto document, you‚Äôd be re-scraping the data each time you knit, which is undesirable (and not nice)!\nAn alternative workflow:\n\nUse an R script to save your code\nSaving interim data scraped using the code in the script as CSV or RDS files\nUse the saved data in your analysis in your Quarto document"
  },
  {
    "objectID": "slides/12-chat-gpt.html#ethics-can-you-vs-should-you",
    "href": "slides/12-chat-gpt.html#ethics-can-you-vs-should-you",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Ethics: ‚ÄúCan you?‚Äù vs ‚ÄúShould you?‚Äù",
    "text": "Ethics: ‚ÄúCan you?‚Äù vs ‚ÄúShould you?‚Äù\n\n\n\n\n\n\n\nSource: Brian Resnick, Researchers just released profile data on 70,000 OkCupid users without permission, Vox."
  },
  {
    "objectID": "slides/12-chat-gpt.html#can-you-vs-should-you",
    "href": "slides/12-chat-gpt.html#can-you-vs-should-you",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "‚ÄúCan you?‚Äù vs ‚ÄúShould you?‚Äù",
    "text": "‚ÄúCan you?‚Äù vs ‚ÄúShould you?‚Äù"
  },
  {
    "objectID": "slides/12-chat-gpt.html#challenges-unreliable-formatting",
    "href": "slides/12-chat-gpt.html#challenges-unreliable-formatting",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Challenges: Unreliable formatting",
    "text": "Challenges: Unreliable formatting\n\n\n\n\n\n\n\nalumni.duke.edu/news/notable-alumni"
  },
  {
    "objectID": "slides/12-chat-gpt.html#challenges-data-broken-into-many-pages",
    "href": "slides/12-chat-gpt.html#challenges-data-broken-into-many-pages",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Challenges: Data broken into many pages",
    "text": "Challenges: Data broken into many pages"
  },
  {
    "objectID": "slides/12-chat-gpt.html#workflow-screen-scraping-vs.-apis",
    "href": "slides/12-chat-gpt.html#workflow-screen-scraping-vs.-apis",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Workflow: Screen scraping vs.¬†APIs",
    "text": "Workflow: Screen scraping vs.¬†APIs\nTwo different scenarios for web scraping:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files"
  },
  {
    "objectID": "slides/12-chat-gpt.html#workflow-scraping-from-many-pages",
    "href": "slides/12-chat-gpt.html#workflow-scraping-from-many-pages",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Workflow: Scraping from many pages",
    "text": "Workflow: Scraping from many pages\n\nSo far you‚Äôve learned to scrape data from a single page\nIf you wanted to scrape data from multiple, similarly structured web pages (e.g., scrape the text and other metadata for each opinion article on The Chronicle):\n\nWrite the code to scrape one page\nTurn it into a function that takes the webpage URL as an argument and returns the scraped, structured data\nMap the function over the list of URLs of interest"
  },
  {
    "objectID": "slides/12-chat-gpt.html#using-chat-gpt",
    "href": "slides/12-chat-gpt.html#using-chat-gpt",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Using Chat GPT",
    "text": "Using Chat GPT\n\nHow are you using Chat GPT for this class?"
  },
  {
    "objectID": "slides/12-chat-gpt.html#example-1---from-lab-4",
    "href": "slides/12-chat-gpt.html#example-1---from-lab-4",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Example 1 - From Lab 4",
    "text": "Example 1 - From Lab 4\n\nAnother variable that needs some cleaning up is membership_status. Currently it should either be NA or contain some text that says \"Select ... to register for this group\". Recode this variable to say \"Closed\" if the current value is NA or \"Open\" otherwise. Save the resulting dataset with these two new variables as clubs, i.e., overwrite the data frame.\nThen, display the first 10 rows of the dataset, relocate()ing membership_status to the beginning of the dataset to make sure it appears in the output in your rendered document."
  },
  {
    "objectID": "slides/12-chat-gpt.html#sample-data",
    "href": "slides/12-chat-gpt.html#sample-data",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Sample data",
    "text": "Sample data\n\ndf &lt;- tribble(\n  ~club, ~membership_status,\n  1, \"Select AI Competition Club's group. Select the group and click on the Join button at the bottom of the page to register for this group\",\n  2, NA,\n  3, \"Select Black Pre-Law Society at Duke's group. Select the group and click on the Join button at the bottom of the page to register for this group\",\n  4, NA,\n  5, NA,\n  6, \"Select Duke Women's Flag Football Team's group. Select the group and click on the Join button at the bottom of the page to register for this group\",\n  7, NA,\n  8, NA,\n  9, NA,\n  10, \"Select Latino Medical Student Association's group. Select the group and click on the Join button at the bottom of the page to register for this group\",\n  11, NA,\n  12, \"Select Native American/Indigenous Student Alliance's group. Select the group and click on the Join button at the bottom of the page to register for this group\",\n  13, NA,\n  14, NA,\n  15, NA,\n  16, NA,\n  17, NA,\n  18, NA,\n  19, \"Select Society of Women Engineers's group. Select the group and click on the Join button at the bottom of the page to register for this group\",\n  20, NA,\n  21, NA\n)\n\ndf"
  },
  {
    "objectID": "slides/12-chat-gpt.html#sample-data-output",
    "href": "slides/12-chat-gpt.html#sample-data-output",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Sample data",
    "text": "Sample data\n\n# A tibble: 21 √ó 2\n    club membership_status                                                                \n   &lt;dbl&gt; &lt;chr&gt;                                                                            \n 1     1 Select AI Competition Club's group. Select the group and click on the Join butto‚Ä¶\n 2     2 &lt;NA&gt;                                                                             \n 3     3 Select Black Pre-Law Society at Duke's group. Select the group and click on the ‚Ä¶\n 4     4 &lt;NA&gt;                                                                             \n 5     5 &lt;NA&gt;                                                                             \n 6     6 Select Duke Women's Flag Football Team's group. Select the group and click on th‚Ä¶\n 7     7 &lt;NA&gt;                                                                             \n 8     8 &lt;NA&gt;                                                                             \n 9     9 &lt;NA&gt;                                                                             \n10    10 Select Latino Medical Student Association's group. Select the group and click on‚Ä¶\n# ‚Ñπ 11 more rows"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-1-prompt",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-1-prompt",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 1 prompt",
    "text": "Chat GPT - Take 1 prompt\n\nWhat is wrong with this promopt?\n\n\nAnother variable that needs some cleaning up is membership_status. Currently it should either be NA or contain some text that says \"Select ... to register for this group\". Recode this variable to say \"Closed\" if the current value is NA or \"Open\" otherwise. Save the resulting dataset with these two new variables as clubs, i.e., overwrite the data frame.\nThen, display the first 10 rows of the dataset, relocate()ing membership_status to the beginning of the dataset to make sure it appears in the output in your rendered document."
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-1-response",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-1-response",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 1 response",
    "text": "Chat GPT - Take 1 response\n\nExplain what the following code does.\n\n\nCertainly! To achieve this in R, you can follow these steps:\n# Assuming your dataset is named 'clubs'\n# Recode membership_status variable\nclubs$membership_status &lt;- ifelse(is.na(clubs$membership_status), \"Closed\", \"Open\")\n\n# Relocate membership_status to the beginning of the dataset\nclubs &lt;- clubs[c(\"membership_status\", setdiff(names(clubs), \"membership_status\"))]\n\n# Display the first 10 rows of the dataset\nhead(clubs, 10)\nMake sure to replace ‚Äòclubs‚Äô with the actual name of your dataset. This code will recode the membership_status variable as per your instructions, then move it to the beginning of the dataset and display the first 10 rows."
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-1-code",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-1-code",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 1 code",
    "text": "Chat GPT - Take 1 code\n\n# Assuming your dataset is named 'clubs'\n# Recode membership_status variable\nclubs$membership_status &lt;- ifelse(is.na(clubs$membership_status), \"Closed\", \"Open\")\n\nError in eval(expr, envir, enclos): object 'clubs' not found\n\n# Relocate membership_status to the beginning of the dataset\nclubs &lt;- clubs[c(\"membership_status\", setdiff(names(clubs), \"membership_status\"))]\n\nError in eval(expr, envir, enclos): object 'clubs' not found\n\n# Display the first 10 rows of the dataset\nhead(clubs, 10)\n\nError in eval(expr, envir, enclos): object 'clubs' not found"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-1-code-edit",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-1-code-edit",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 1 code + edit",
    "text": "Chat GPT - Take 1 code + edit\n\nclubs &lt;- df\n\n# Assuming your dataset is named 'clubs'\n# Recode membership_status variable\nclubs$membership_status &lt;- ifelse(is.na(clubs$membership_status), \"Closed\", \"Open\")\n\n# Relocate membership_status to the beginning of the dataset\nclubs &lt;- clubs[c(\"membership_status\", setdiff(names(clubs), \"membership_status\"))]\n\n# Display the first 10 rows of the dataset\nhead(clubs, 10)\n\n# A tibble: 10 √ó 2\n   membership_status  club\n   &lt;chr&gt;             &lt;dbl&gt;\n 1 Open                  1\n 2 Closed                2\n 3 Open                  3\n 4 Closed                4\n 5 Closed                5\n 6 Open                  6\n 7 Closed                7\n 8 Closed                8\n 9 Closed                9\n10 Open                 10"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-2-prompt",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-2-prompt",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 2 prompt",
    "text": "Chat GPT - Take 2 prompt\n\nCan you suggest an alternate solution in R?"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-2-response",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-2-response",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 2 response",
    "text": "Chat GPT - Take 2 response\n\nExplain what the following code does.\n\n\nCertainly! An alternate solution can use the mutate and relocate functions from the dplyr package. Here‚Äôs an alternative code:\nlibrary(dplyr)\n\n# Assuming your dataset is named 'clubs'\nclubs &lt;- clubs %&gt;%\n  mutate(membership_status = ifelse(is.na(membership_status), \"Closed\", \"Open\")) %&gt;%\n  relocate(membership_status, .before = 1)\n\n# Display the first 10 rows of the dataset\nhead(clubs, 10)\nThis code achieves the same result but uses the mutate function from the dplyr package for variable recoding and the relocate function to move the membership_status variable to the beginning of the dataset. Make sure to replace ‚Äòclubs‚Äô with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-2-code",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-2-code",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 2 code",
    "text": "Chat GPT - Take 2 code\n\nlibrary(dplyr)\n\n# Assuming your dataset is named 'clubs'\nclubs &lt;- clubs %&gt;%\n  mutate(membership_status = ifelse(is.na(membership_status), \"Closed\", \"Open\")) %&gt;%\n  relocate(membership_status, .before = 1)\n\n# Display the first 10 rows of the dataset\nhead(clubs, 10)\n\n# A tibble: 10 √ó 2\n   membership_status  club\n   &lt;chr&gt;             &lt;dbl&gt;\n 1 Open                  1\n 2 Closed                2\n 3 Open                  3\n 4 Closed                4\n 5 Closed                5\n 6 Open                  6\n 7 Closed                7\n 8 Closed                8\n 9 Closed                9\n10 Open                 10"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-3-prompt",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-3-prompt",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 3 prompt",
    "text": "Chat GPT - Take 3 prompt\n\nCan you suggest a tidyverse-based solution?"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-3-response",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-3-response",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 3 response",
    "text": "Chat GPT - Take 3 response\n\nCertainly! If you want to stick to the tidyverse, you can use the mutate and slice_head functions from the dplyr package along with the forcats package for factor manipulation. Here‚Äôs a tidyverse-based solution:\nlibrary(dplyr)\nlibrary(forcats)\n\n# Assuming your dataset is named 'clubs'\nclubs &lt;- clubs %&gt;%\n  mutate(membership_status = fct_recode(membership_status, Closed = \"NA\", Open = \"Select ... to register for this group\")) %&gt;%\n  slice_head(n = 10) %&gt;%\n  relocate(membership_status, .before = 1)\n\n# Display the first 10 rows of the dataset\nclubs\nThis code uses fct_recode from the forcats package to recode the levels of the membership_status variable. The slice_head function is then used to select the first 10 rows, and relocate is used to move the membership_status variable to the beginning of the dataset. Make sure to replace ‚Äòclubs‚Äô with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-3-code",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-3-code",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 3 code",
    "text": "Chat GPT - Take 3 code\n\nlibrary(dplyr)\nlibrary(forcats)\n\n# Assuming your dataset is named 'clubs'\nclubs &lt;- clubs %&gt;%\n  mutate(membership_status = fct_recode(membership_status, Closed = \"NA\", Open = \"Select ... to register for this group\")) %&gt;%\n  slice_head(n = 10) %&gt;%\n  relocate(membership_status, .before = 1)\n\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `membership_status = fct_recode(membership_status, Closed = \"NA\", Open =\n  \"Select ... to register for this group\")`.\nCaused by warning:\n! Unknown levels in `f`: NA, Select ... to register for this group\n\n# Display the first 10 rows of the dataset\nclubs\n\n# A tibble: 10 √ó 2\n   membership_status                                                                  club\n   &lt;fct&gt;                                                                             &lt;dbl&gt;\n 1 Select AI Competition Club's group. Select the group and click on the Join butto‚Ä¶     1\n 2 &lt;NA&gt;                                                                                  2\n 3 Select Black Pre-Law Society at Duke's group. Select the group and click on the ‚Ä¶     3\n 4 &lt;NA&gt;                                                                                  4\n 5 &lt;NA&gt;                                                                                  5\n 6 Select Duke Women's Flag Football Team's group. Select the group and click on th‚Ä¶     6\n 7 &lt;NA&gt;                                                                                  7\n 8 &lt;NA&gt;                                                                                  8\n 9 &lt;NA&gt;                                                                                  9\n10 Select Latino Medical Student Association's group. Select the group and click on‚Ä¶    10"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-4-prompt",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-4-prompt",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 4 prompt",
    "text": "Chat GPT - Take 4 prompt\n\nThe text ‚ÄúSelect ‚Ä¶ to register for this group‚Äù can vary for each group. For example, it can be ‚Äú‚ÄúSelect blah blah to register for this group‚Äù or it can be ‚ÄúSelect la di da to register for this group‚Äù. Can you suggest a tidyverse-based solution that would capture all of possible options for the ‚Ä¶ in this text?"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-4-response",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-4-response",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 4 response",
    "text": "Chat GPT - Take 4 response\n\nExplain what the following code does.\n\n\nCertainly! If the text ‚ÄúSelect ‚Ä¶ to register for this group‚Äù varies for each group, you can use the str_detect function from the stringr package to identify those cases. Here‚Äôs a tidyverse-based solution:\nlibrary(dplyr)\nlibrary(stringr)\n\n# Assuming your dataset is named 'clubs'\nclubs &lt;- clubs %&gt;%\n  mutate(membership_status = ifelse(str_detect(membership_status, \"Select .* to register for this group\"), \"Open\", \"Closed\")) %&gt;%\n  relocate(membership_status, .before = 1)\n\n# Display the first 10 rows of the dataset\nhead(clubs, 10)\nThis code uses str_detect to check if the membership_status contains the pattern ‚ÄúSelect ‚Ä¶ to register for this group‚Äù. If it does, it sets the status to ‚ÄúOpen‚Äù; otherwise, it sets it to ‚ÄúClosed‚Äù. Make sure to replace ‚Äòclubs‚Äô with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-4-code",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-4-code",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 4 code",
    "text": "Chat GPT - Take 4 code\n\nlibrary(dplyr)\nlibrary(stringr)\n\n# Assuming your dataset is named 'clubs'\nclubs &lt;- clubs %&gt;%\n  mutate(membership_status = ifelse(str_detect(membership_status, \"Select .* to register for this group\"), \"Open\", \"Closed\")) %&gt;%\n  relocate(membership_status, .before = 1)\n\n# Display the first 10 rows of the dataset\nhead(clubs, 10)\n\n# A tibble: 10 √ó 2\n   membership_status  club\n   &lt;chr&gt;             &lt;dbl&gt;\n 1 Open                  1\n 2 &lt;NA&gt;                  2\n 3 Open                  3\n 4 &lt;NA&gt;                  4\n 5 &lt;NA&gt;                  5\n 6 Open                  6\n 7 &lt;NA&gt;                  7\n 8 &lt;NA&gt;                  8\n 9 &lt;NA&gt;                  9\n10 Open                 10"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-5-prompt",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-5-prompt",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 5 prompt",
    "text": "Chat GPT - Take 5 prompt\n\nWhat is different about this prompt?\n\n\nLet‚Äôs try again. Can you write a tidyverse-based solution where membership status is recoded as Closed if the current value is NA and Open if the current value is anything else. Then, using the relocate() function, the membership status is moved to be the first column in the output."
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-5-response",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-5-response",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 5 response",
    "text": "Chat GPT - Take 5 response\n\nExplain what the following code does.\n\n\nCertainly! My apologies for the confusion. Here‚Äôs a tidyverse-based solution that recodes the membership status and moves it to be the first column using the dplyr package:\nlibrary(dplyr)\n\n# Assuming your dataset is named 'clubs'\nclubs &lt;- clubs %&gt;%\n  mutate(membership_status = if_else(is.na(membership_status), \"Closed\", \"Open\")) %&gt;%\n  relocate(membership_status, .before = 1)\n\n# Display the first 10 rows of the dataset\nhead(clubs, 10)\nThis code uses the mutate function to recode membership_status as ‚ÄúClosed‚Äù if it‚Äôs NA and ‚ÄúOpen‚Äù otherwise. Then, the relocate function is used to move membership_status to be the first column in the dataset. Make sure to replace ‚Äòclubs‚Äô with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-5-code",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-5-code",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 5 code",
    "text": "Chat GPT - Take 5 code\n\nlibrary(dplyr)\n\n# Assuming your dataset is named 'clubs'\nclubs &lt;- clubs %&gt;%\n  mutate(membership_status = if_else(is.na(membership_status), \"Closed\", \"Open\")) %&gt;%\n  relocate(membership_status, .before = 1)\n\n# Display the first 10 rows of the dataset\nhead(clubs, 10)\n\n# A tibble: 10 √ó 2\n   membership_status  club\n   &lt;chr&gt;             &lt;dbl&gt;\n 1 Open                  1\n 2 Closed                2\n 3 Open                  3\n 4 Closed                4\n 5 Closed                5\n 6 Open                  6\n 7 Closed                7\n 8 Closed                8\n 9 Closed                9\n10 Open                 10"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-5-code-edit",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-5-code-edit",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 5 code + edit",
    "text": "Chat GPT - Take 5 code + edit\n\nclubs |&gt;\n  mutate(membership_status = if_else(is.na(membership_status), \"Closed\", \"Open\"))\n\n# A tibble: 21 √ó 2\n    club membership_status\n   &lt;dbl&gt; &lt;chr&gt;            \n 1     1 Open             \n 2     2 Closed           \n 3     3 Open             \n 4     4 Closed           \n 5     5 Closed           \n 6     6 Open             \n 7     7 Closed           \n 8     8 Closed           \n 9     9 Closed           \n10    10 Open             \n# ‚Ñπ 11 more rows"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-5-code-edit-1",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-5-code-edit-1",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 5 code + edit",
    "text": "Chat GPT - Take 5 code + edit\n\nclubs |&gt;\n  mutate(membership_status = if_else(is.na(membership_status), \"Closed\", \"Open\")) |&gt;\n  relocate(membership_status)\n\n# A tibble: 21 √ó 2\n   membership_status  club\n   &lt;chr&gt;             &lt;dbl&gt;\n 1 Open                  1\n 2 Closed                2\n 3 Open                  3\n 4 Closed                4\n 5 Closed                5\n 6 Open                  6\n 7 Closed                7\n 8 Closed                8\n 9 Closed                9\n10 Open                 10\n# ‚Ñπ 11 more rows"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-5-code-edit-2",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-5-code-edit-2",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 5 code + edit",
    "text": "Chat GPT - Take 5 code + edit\n\nclubs &lt;- clubs |&gt;\n  mutate(membership_status = if_else(is.na(membership_status), \"Closed\", \"Open\")) |&gt;\n  relocate(membership_status)\n\nclubs\n\n# A tibble: 21 √ó 2\n   membership_status  club\n   &lt;chr&gt;             &lt;dbl&gt;\n 1 Open                  1\n 2 Closed                2\n 3 Open                  3\n 4 Closed                4\n 5 Closed                5\n 6 Open                  6\n 7 Closed                7\n 8 Closed                8\n 9 Closed                9\n10 Open                 10\n# ‚Ñπ 11 more rows"
  },
  {
    "objectID": "slides/12-chat-gpt.html#example-2",
    "href": "slides/12-chat-gpt.html#example-2",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Example 2",
    "text": "Example 2\n\nEach CSI franchise includes a number of series, each with the character string \"CSI\" (in capital letters) in their title. Using this information, create a new data frame called csi that only has titles from the CSI-verse and all of the columns from tv for these titles. Then, display the first 10 rows of csi. Note: The titles and seasons included in the dataset may not be all CSI titles and titles that have ever aired."
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-1-prompt-1",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-1-prompt-1",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 1 prompt",
    "text": "Chat GPT - Take 1 prompt\n\nEach CSI franchise includes a number of series, each with the character string \"CSI\" (in capital letters) in their title. Using this information, create a new data frame called csi that only has titles from the CSI-verse and all of the columns from tv for these titles. Then, display the first 10 rows of csi. Note: The titles and seasons included in the dataset may not be all CSI titles and titles that have ever aired."
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-1-response-1",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-1-response-1",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 1 response",
    "text": "Chat GPT - Take 1 response\n\nCertainly! To filter the tv data frame to include only titles from the CSI-verse, you can use the filter function from the dplyr package. Here‚Äôs the code:\nlibrary(dplyr)\n\n# Assuming your dataset is named 'tv'\ncsi &lt;- tv %&gt;%\n  filter(str_detect(title, \"CSI\", case_insensitive = TRUE))\n\n# Display the first 10 rows of the 'csi' data frame\nhead(csi, 10)\nThis code uses the filter function to select rows where the title column contains the string ‚ÄúCSI‚Äù (case-insensitive). The resulting data frame, csi, will include only titles from the CSI-verse along with all the columns from the original tv data frame. Make sure to replace ‚Äòtv‚Äô with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-1-code-1",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-1-code-1",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 1 code",
    "text": "Chat GPT - Take 1 code\n\nWhat is wrong with the following code?\n\n\ntv &lt;- read_csv(\"data/tv.csv\")\n\n\nlibrary(dplyr)\n\n# Assuming your dataset is named 'tv'\ncsi &lt;- tv %&gt;%\n  filter(str_detect(title, \"CSI\", case_insensitive = TRUE))\n\nError in `filter()`:\n‚Ñπ In argument: `str_detect(title, \"CSI\", case_insensitive = TRUE)`.\nCaused by error in `str_detect()`:\n! unused argument (case_insensitive = TRUE)\n\n# Display the first 10 rows of the 'csi' data frame\nhead(csi, 10)\n\nError in eval(expr, envir, enclos): object 'csi' not found"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-2-prompt-1",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-2-prompt-1",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 2 prompt",
    "text": "Chat GPT - Take 2 prompt\n\nstr_detect doesn‚Äôt have a case_insensitive argument, can you try again?"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-2-response-1",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-2-response-1",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 2 response",
    "text": "Chat GPT - Take 2 response\n\nYou are correct, and I appreciate your understanding. The str_detect function itself doesn‚Äôt have a case_insensitive argument. Instead, you can use the str_which function along with the case_insensitive argument in the filter function. Here‚Äôs the corrected code:\nlibrary(dplyr)\n\n# Assuming your dataset is named 'tv'\ncsi &lt;- tv %&gt;%\n  filter(str_detect(title, \"CSI\", ignore_case = TRUE))\n\n# Display the first 10 rows of the 'csi' data frame\nhead(csi, 10)\nThis code uses str_detect within the filter function and includes the ignore_case = TRUE argument to perform a case-insensitive search. The resulting csi data frame will contain only titles from the CSI-verse along with all the columns from the original tv data frame. Make sure to replace ‚Äòtv‚Äô with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-2-code-1",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-2-code-1",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 2 code",
    "text": "Chat GPT - Take 2 code\n\nlibrary(dplyr)\n\n# Assuming your dataset is named 'tv'\ncsi &lt;- tv %&gt;%\n  filter(str_detect(title, \"CSI\", ignore_case = TRUE))\n\nError in `filter()`:\n‚Ñπ In argument: `str_detect(title, \"CSI\", ignore_case = TRUE)`.\nCaused by error in `str_detect()`:\n! unused argument (ignore_case = TRUE)\n\n# Display the first 10 rows of the 'csi' data frame\nhead(csi, 10)\n\nError in eval(expr, envir, enclos): object 'csi' not found"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-3-prompt-1",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-3-prompt-1",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 3 prompt",
    "text": "Chat GPT - Take 3 prompt\n\nstr_detect doesn‚Äôt have an ignore_case argument either, can you try again?"
  },
  {
    "objectID": "slides/12-chat-gpt.html#chat-gpt---take-3-response-1",
    "href": "slides/12-chat-gpt.html#chat-gpt---take-3-response-1",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Chat GPT - Take 3 response",
    "text": "Chat GPT - Take 3 response\n\nI apologize for the oversight. It seems there was a mistake in my responses. To perform a case-insensitive search, you can use the stringi package along with stri_detect_regex. Here‚Äôs the corrected code:\nlibrary(dplyr)\nlibrary(stringi)\n\n# Assuming your dataset is named 'tv'\ncsi &lt;- tv %&gt;%\n  filter(stri_detect_regex(title, \"CSI\", case_insensitive = TRUE))\n\n# Display the first 10 rows of the 'csi' data frame\nhead(csi, 10)\nThis code uses stri_detect_regex from the stringi package within the filter function, and it includes the case_insensitive = TRUE argument for a case-insensitive search. The resulting csi data frame will contain only titles from the CSI-verse along with all the columns from the original tv data frame. Make sure to replace ‚Äòtv‚Äô with the actual name of your dataset."
  },
  {
    "objectID": "slides/12-chat-gpt.html#lets-go-back-to-take-1",
    "href": "slides/12-chat-gpt.html#lets-go-back-to-take-1",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Let‚Äôs go back to Take 1",
    "text": "Let‚Äôs go back to Take 1\nand edit it a bit:\n\ntv |&gt;\n  filter(str_detect(title, \"CSI\"))\n\n# A tibble: 36 √ó 9\n   season title                         year month   day av_rating genre_1 genre_2 genre_3\n    &lt;dbl&gt; &lt;chr&gt;                        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1      1 CSI: Crime Scene Investigat‚Ä¶  2001     1    20      8.32 Crime   Drama   Mystery\n 2      2 CSI: Crime Scene Investigat‚Ä¶  2002     1    10      8.26 Crime   Drama   Mystery\n 3      3 CSI: Crime Scene Investigat‚Ä¶  2003     1    15      8.30 Crime   Drama   Mystery\n 4      4 CSI: Crime Scene Investigat‚Ä¶  2004     1    18      8.33 Crime   Drama   Mystery\n 5      5 CSI: Crime Scene Investigat‚Ä¶  2005     1    24      8.38 Crime   Drama   Mystery\n 6      6 CSI: Crime Scene Investigat‚Ä¶  2006     1    16      8.21 Crime   Drama   Mystery\n 7      7 CSI: Crime Scene Investigat‚Ä¶  2007     1    14      8.43 Crime   Drama   Mystery\n 8      8 CSI: Crime Scene Investigat‚Ä¶  2008     1     7      8.07 Crime   Drama   Mystery\n 9      9 CSI: Crime Scene Investigat‚Ä¶  2009     1    27      7.80 Crime   Drama   Mystery\n10     10 CSI: Crime Scene Investigat‚Ä¶  2010     1    23      7.69 Crime   Drama   Mystery\n# ‚Ñπ 26 more rows"
  },
  {
    "objectID": "slides/12-chat-gpt.html#lets-go-back-to-take-1-1",
    "href": "slides/12-chat-gpt.html#lets-go-back-to-take-1-1",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Let‚Äôs go back to Take 1",
    "text": "Let‚Äôs go back to Take 1\n\ncsi &lt;- tv |&gt;\n  filter(str_detect(title, \"CSI\"))\n\ncsi\n\n# A tibble: 36 √ó 9\n   season title                         year month   day av_rating genre_1 genre_2 genre_3\n    &lt;dbl&gt; &lt;chr&gt;                        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n 1      1 CSI: Crime Scene Investigat‚Ä¶  2001     1    20      8.32 Crime   Drama   Mystery\n 2      2 CSI: Crime Scene Investigat‚Ä¶  2002     1    10      8.26 Crime   Drama   Mystery\n 3      3 CSI: Crime Scene Investigat‚Ä¶  2003     1    15      8.30 Crime   Drama   Mystery\n 4      4 CSI: Crime Scene Investigat‚Ä¶  2004     1    18      8.33 Crime   Drama   Mystery\n 5      5 CSI: Crime Scene Investigat‚Ä¶  2005     1    24      8.38 Crime   Drama   Mystery\n 6      6 CSI: Crime Scene Investigat‚Ä¶  2006     1    16      8.21 Crime   Drama   Mystery\n 7      7 CSI: Crime Scene Investigat‚Ä¶  2007     1    14      8.43 Crime   Drama   Mystery\n 8      8 CSI: Crime Scene Investigat‚Ä¶  2008     1     7      8.07 Crime   Drama   Mystery\n 9      9 CSI: Crime Scene Investigat‚Ä¶  2009     1    27      7.80 Crime   Drama   Mystery\n10     10 CSI: Crime Scene Investigat‚Ä¶  2010     1    23      7.69 Crime   Drama   Mystery\n# ‚Ñπ 26 more rows"
  },
  {
    "objectID": "slides/12-chat-gpt.html#guidelines-and-best-practices-for-using-chat-gpt",
    "href": "slides/12-chat-gpt.html#guidelines-and-best-practices-for-using-chat-gpt",
    "title": "Web scraping wrap-up + Chat GPT",
    "section": "Guidelines and best practices for using Chat GPT",
    "text": "Guidelines and best practices for using Chat GPT\n\n\nDo not just copy-paste the prompt ‚Äì for appropriate academic conduct, for your own learning, and for getting to better results faster\nEngineer the prompt until the response starts to look like code you‚Äôre learning in the course\nIf the response is not correct, ask for a correction\nIf the response doesn‚Äôt follow the guidelines, ask for a correction\nDo not just copy-paste code from Chat GPT responses, run it line-by-line and edit as needed\nWatch out for clear mistakes in the response: do not keep loading packages that are already loaded, use the base pipe |&gt;, use tidyverse-based code, etc.\n\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/06-tidying-data.html#while-you-wait-for-class-to-begin",
    "href": "slides/06-tidying-data.html#while-you-wait-for-class-to-begin",
    "title": "Tidying data",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\n\nGo to your ae repo, click Pull to get today‚Äôs application exercise to get ready for later.\nQuestions from the prepare materials?"
  },
  {
    "objectID": "slides/06-tidying-data.html#announcements",
    "href": "slides/06-tidying-data.html#announcements",
    "title": "Tidying data",
    "section": "Announcements",
    "text": "Announcements\n\nLab 2 due Monday, 8 am"
  },
  {
    "objectID": "slides/06-tidying-data.html#ae-04-flights-wrangling",
    "href": "slides/06-tidying-data.html#ae-04-flights-wrangling",
    "title": "Tidying data",
    "section": "ae-04-flights-wrangling",
    "text": "ae-04-flights-wrangling\n\n\nGo to the project navigator in RStudio (top right corner of your RStudio window) and open the project called ae.\nOpen the file called ae-04-flights-wrangling.qmd and render it."
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-pipe",
    "href": "slides/06-tidying-data.html#recap-pipe",
    "title": "Tidying data",
    "section": "Recap: pipe",
    "text": "Recap: pipe\n\nThe pipe operator passes what comes before it into the function that comes after it as the first argument in that function.\n\n\nsum(1, 2)\n\n[1] 3\n\n1 |&gt; \n  sum(2)\n\n[1] 3\n\n\n\nAlways use a line break after the pipe, and indent the next line of code.\n\nJust like always use a line break between layers of ggplots, after +, and indent the next line."
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-logical-operators",
    "href": "slides/06-tidying-data.html#recap-logical-operators",
    "title": "Tidying data",
    "section": "Recap: logical operators",
    "text": "Recap: logical operators\n\n\n\noperator\ndefinition\n\n\n\n\n&lt;\nis less than?\n\n\n&lt;=\nis less than or equal to?\n\n\n&gt;\nis greater than?\n\n\n&gt;=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-logical-operators-1",
    "href": "slides/06-tidying-data.html#recap-logical-operators-1",
    "title": "Tidying data",
    "section": "Recap: logical operators",
    "text": "Recap: logical operators\n\n\n\n\n\n\n\noperator\ndefinition\n\n\n\n\nx & y\nis x AND y?\n\n\nx \\| y\nis x OR y?\n\n\nis.na(x)\nis x NA?\n\n\n!is.na(x)\nis x not NA?\n\n\nx %in% y\nis x in y?\n\n\n!(x %in% y)\nis x not in y?\n\n\n!x\nis not x? (only makes sense if x is TRUE or FALSE)"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-assignment",
    "href": "slides/06-tidying-data.html#recap-assignment",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\nLet‚Äôs make a tiny data frame to use as an example:\n\nlibrary(tidyverse)\ndf &lt;- tibble(x = c(1, 2, 3, 4, 5), y = c(\"a\", \"a\", \"b\", \"c\", \"c\"))\ndf\n\n# A tibble: 5 √ó 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     1 a    \n2     2 a    \n3     3 b    \n4     4 c    \n5     5 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-assignment-1",
    "href": "slides/06-tidying-data.html#recap-assignment-1",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\n\n\nDo something and show me\n\n\ndf |&gt;\n  mutate(x = x * 2)\n\n# A tibble: 5 √ó 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c    \n\ndf\n\n# A tibble: 5 √ó 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     1 a    \n2     2 a    \n3     3 b    \n4     4 c    \n5     5 c    \n\n\n\n\nDo something and save result\n\n\ndf &lt;- df |&gt;\n  mutate(x = x * 2)\ndf\n\n# A tibble: 5 √ó 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-assignment-2",
    "href": "slides/06-tidying-data.html#recap-assignment-2",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\n\n\nDo something, save result, overwriting original\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(x = x * 2)\ndf\n\n# A tibble: 5 √ó 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c    \n\n\n\n\nDo something, save result, not overwriting original\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf_new &lt;- df |&gt;\n  mutate(x = x * 2)\ndf_new\n\n# A tibble: 5 √ó 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-assignment-3",
    "href": "slides/06-tidying-data.html#recap-assignment-3",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\n\n\nDo something, save result, overwriting original when you shouldn‚Äôt\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\ndf\n\n# A tibble: 3 √ó 2\n  y     mean_x\n  &lt;chr&gt;  &lt;dbl&gt;\n1 a        1.5\n2 b        3  \n3 c        4.5\n\n\n\n\nDo something, save result, not overwriting original when you shouldn‚Äôt\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf_summary &lt;- df |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\ndf_summary\n\n# A tibble: 3 √ó 2\n  y     mean_x\n  &lt;chr&gt;  &lt;dbl&gt;\n1 a        1.5\n2 b        3  \n3 c        4.5"
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-assignment-4",
    "href": "slides/06-tidying-data.html#recap-assignment-4",
    "title": "Tidying data",
    "section": "Recap: assignment",
    "text": "Recap: assignment\n\n\n\nDo something, save result, overwriting original\ndata frame\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(z = x + 2)\ndf\n\n# A tibble: 5 √ó 3\n      x y         z\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 a         3\n2     2 a         4\n3     3 b         5\n4     4 c         6\n5     5 c         7\n\n\n\n\nDo something, save result, overwriting original\ncolumn\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(x = x + 2)\ndf\n\n# A tibble: 5 √ó 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     3 a    \n2     4 a    \n3     5 b    \n4     6 c    \n5     7 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#tidy-data",
    "href": "slides/06-tidying-data.html#tidy-data",
    "title": "Tidying data",
    "section": "Tidy data",
    "text": "Tidy data\n\n‚ÄúTidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table.‚Äù\nTidy Data, https://vita.had.co.nz/papers/tidy-data.pdf\n\n\nNote: ‚Äúeasy to manipulate‚Äù = ‚Äústraightforward to manipulate‚Äù"
  },
  {
    "objectID": "slides/06-tidying-data.html#goal",
    "href": "slides/06-tidying-data.html#goal",
    "title": "Tidying data",
    "section": "Goal",
    "text": "Goal\nVisualize StatSci majors over the years!"
  },
  {
    "objectID": "slides/06-tidying-data.html#data",
    "href": "slides/06-tidying-data.html#data",
    "title": "Tidying data",
    "section": "Data",
    "text": "Data\n\nstatsci &lt;- read_csv(\"https://sta199-s24.github.io/data/statsci.csv\")\nstatsci\n\n# A tibble: 4 √ó 14\n  degree      `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019` `2020` `2021`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Statistica‚Ä¶     NA      1     NA     NA      4      4      1     NA     NA      1      2\n2 Statistica‚Ä¶      2      2      4      1      3      6      3      4      4      1     NA\n3 Statistica‚Ä¶      2      6      1     NA      5      6      6      8      8     17     16\n4 Statistica‚Ä¶      5      9      4     13     10     17     24     21     26     27     35\n# ‚Ñπ 2 more variables: `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt;\n\n\n\n\nThe first column (variable) is the degree, and there are 4 possible degrees: BS (Bachelor of Science), BS2 (Bachelor of Science, 2nd major), AB (Bachelor of Arts), AB2 (Bachelor of Arts, 2nd major).\nThe remaining columns show the number of students graduating with that major in a given academic year from 2011 to 2023."
  },
  {
    "objectID": "slides/06-tidying-data.html#lets-plan",
    "href": "slides/06-tidying-data.html#lets-plan",
    "title": "Tidying data",
    "section": "Let‚Äôs plan!",
    "text": "Let‚Äôs plan!\n\nTake a look at the plot we aim to make and sketch the data frame we need to make the plot. Determine what each row and each column of the data frame should be. Hint: We need data to be in columns to map to aesthetic elements of the plot."
  },
  {
    "objectID": "slides/06-tidying-data.html#ae-05-majors-tidying",
    "href": "slides/06-tidying-data.html#ae-05-majors-tidying",
    "title": "Tidying data",
    "section": "ae-05-majors-tidying",
    "text": "ae-05-majors-tidying\n\n\nGo to the project navigator in RStudio (top right corner of your RStudio window) and open the project called ae.\nIf there are any uncommitted files, commit them, and then click Pull.\nOpen the file called ae-05-majors-tidying.qmd and render it."
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-pivoting",
    "href": "slides/06-tidying-data.html#recap-pivoting",
    "title": "Tidying data",
    "section": "Recap: pivoting",
    "text": "Recap: pivoting\n\n\nData sets can‚Äôt be labeled as wide or long but they can be made wider or longer for a certain analysis that requires a certain format\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do so within the pivot_longer() function.\nYou can tweak a plot forever, but at some point the tweaks are likely not very productive. However, you should always be critical of defaults (however pretty they might be) and see if you can improve the plot to better portray your data / results / what you want to communicate.\n\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/09-exam-1-review.html#while-you-wait-for-class-to-begin",
    "href": "slides/09-exam-1-review.html#while-you-wait-for-class-to-begin",
    "title": "Exam 1 review",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\nQuestions for/about the exam?"
  },
  {
    "objectID": "slides/09-exam-1-review.html#packages",
    "href": "slides/09-exam-1-review.html#packages",
    "title": "Exam 1 review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "slides/09-exam-1-review.html#announcements",
    "href": "slides/09-exam-1-review.html#announcements",
    "title": "Exam 1 review",
    "section": "Announcements",
    "text": "Announcements\n\nExam format / flow\nAcademic dishonesty / Duke Community Standard"
  },
  {
    "objectID": "slides/09-exam-1-review.html#explicit-vs.-implicit-type-coercion",
    "href": "slides/09-exam-1-review.html#explicit-vs.-implicit-type-coercion",
    "title": "Exam 1 review",
    "section": "Explicit vs.¬†implicit type coercion",
    "text": "Explicit vs.¬†implicit type coercion\n\nExplicit type coercion: You ask R to change the type of a variable\nImplicit type coercion: R changes / makes assumptions for you about the type of a variable without you asking for it\n\nThis happens because in a vector, you can‚Äôt have multiple types of values"
  },
  {
    "objectID": "slides/09-exam-1-review.html#vectors",
    "href": "slides/09-exam-1-review.html#vectors",
    "title": "Exam 1 review",
    "section": "Vectors",
    "text": "Vectors\n\n\nA vector is a collection of values\n\nAtomic vectors can only contain values of the same type\nLists can contain values of different types\n\nWhy do we care? Because each column of a data frame is a vector.\n\n\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3),          # numeric (double)\n  y = c(\"a\", \"b\", \"c\"),    # character\n  z = c(TRUE, FALSE, TRUE) # logical\n)\ndf\n\n# A tibble: 3 √ó 3\n      x y     z    \n  &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt;\n1     1 a     TRUE \n2     2 b     FALSE\n3     3 c     TRUE"
  },
  {
    "objectID": "slides/09-exam-1-review.html#explicit-coercion",
    "href": "slides/09-exam-1-review.html#explicit-coercion",
    "title": "Exam 1 review",
    "section": "Explicit coercion",
    "text": "Explicit coercion\n‚úÖ From numeric to character\n\ndf |&gt;\n  mutate(x_new = as.character(x))\n\n# A tibble: 3 √ó 4\n      x y     z     x_new\n  &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt;\n1     1 a     TRUE  1    \n2     2 b     FALSE 2    \n3     3 c     TRUE  3"
  },
  {
    "objectID": "slides/09-exam-1-review.html#explicit-coercion-1",
    "href": "slides/09-exam-1-review.html#explicit-coercion-1",
    "title": "Exam 1 review",
    "section": "Explicit coercion",
    "text": "Explicit coercion\n‚ùå From character to numeric\n\ndf |&gt;\n  mutate(y_new = as.numeric(y))\n\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `y_new = as.numeric(y)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n# A tibble: 3 √ó 4\n      x y     z     y_new\n  &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt; &lt;dbl&gt;\n1     1 a     TRUE     NA\n2     2 b     FALSE    NA\n3     3 c     TRUE     NA"
  },
  {
    "objectID": "slides/09-exam-1-review.html#implicit-coercion",
    "href": "slides/09-exam-1-review.html#implicit-coercion",
    "title": "Exam 1 review",
    "section": "Implicit coercion",
    "text": "Implicit coercion\n\nWhich of the column types were implicitly coerced?\n\n\ndf &lt;- tibble(\n  w = c(1, 2, 3),\n  x = c(\"a\", \"b\", 4),\n  y = c(\"c\", \"d\", NA),\n  z = c(5, 6, NA),\n)\ndf\n\n# A tibble: 3 √ó 4\n      w x     y         z\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 a     c         5\n2     2 b     d         6\n3     3 4     &lt;NA&gt;     NA"
  },
  {
    "objectID": "slides/09-exam-1-review.html#collecting-data",
    "href": "slides/09-exam-1-review.html#collecting-data",
    "title": "Exam 1 review",
    "section": "Collecting data",
    "text": "Collecting data\n\nSuppose you conduct a survey and ask students their student ID number and number of credits they‚Äôre taking this semester. What is the type of each variable?\n\n\n\nsurvey_raw &lt;- tibble(\n  student_id = c(273674, 298765, 287129, \"I don't remember\"),\n  n_credits = c(4, 4.5, \"I'm not sure yet\", \"2 - underloading\")\n)\nsurvey_raw\n\n# A tibble: 4 √ó 2\n  student_id       n_credits       \n  &lt;chr&gt;            &lt;chr&gt;           \n1 273674           4               \n2 298765           4.5             \n3 287129           I'm not sure yet\n4 I don't remember 2 - underloading"
  },
  {
    "objectID": "slides/09-exam-1-review.html#cleaning-data",
    "href": "slides/09-exam-1-review.html#cleaning-data",
    "title": "Exam 1 review",
    "section": "Cleaning data",
    "text": "Cleaning data\n\nsurvey &lt;- survey_raw |&gt;\n  mutate(\n    student_id = if_else(student_id == \"I don't remember\", NA, student_id),\n    n_credits = case_when(\n      n_credits == \"I'm not sure yet\" ~ NA,\n      n_credits == \"2 - underloading\" ~ \"2\",\n      .default = n_credits\n    ),\n    n_credits = as.numeric(n_credits)\n  )\nsurvey\n\n# A tibble: 4 √ó 2\n  student_id n_credits\n  &lt;chr&gt;          &lt;dbl&gt;\n1 273674           4  \n2 298765           4.5\n3 287129          NA  \n4 &lt;NA&gt;             2"
  },
  {
    "objectID": "slides/09-exam-1-review.html#cleaning-data-alternative",
    "href": "slides/09-exam-1-review.html#cleaning-data-alternative",
    "title": "Exam 1 review",
    "section": "Cleaning data ‚Äì alternative",
    "text": "Cleaning data ‚Äì alternative\n\nsurvey &lt;- survey_raw |&gt;\n  mutate(\n    student_id = parse_number(student_id),\n    n_credits = parse_number(n_credits)\n  )\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\n‚Ñπ In argument: `student_id = parse_number(student_id)`.\nCaused by warning:\n! 1 parsing failure.\nrow col expected           actual\n  4  -- a number I don't remember\n‚Ñπ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\nsurvey\n\n# A tibble: 4 √ó 2\n  student_id n_credits\n       &lt;dbl&gt;     &lt;dbl&gt;\n1     273674       4  \n2     298765       4.5\n3     287129      NA  \n4         NA       2"
  },
  {
    "objectID": "slides/09-exam-1-review.html#recap-type-coercion",
    "href": "slides/09-exam-1-review.html#recap-type-coercion",
    "title": "Exam 1 review",
    "section": "Recap: Type coercion",
    "text": "Recap: Type coercion\n\n\nIf variables in a data frame have multiple types of values, R will coerce them into a single type, which may or may not be what you want.\nIf what R does by default is not what you want, you can use explicit coercion functions like as.numeric(), as.character(), etc. to turn them into the types you want them to be, which will generally also involve cleaning up the features of the data that caused the unwanted implicit coercion in the first place."
  },
  {
    "objectID": "slides/09-exam-1-review.html#openintroloan50",
    "href": "slides/09-exam-1-review.html#openintroloan50",
    "title": "Exam 1 review",
    "section": "openintro::loan50",
    "text": "openintro::loan50\n\nloan50 |&gt;\n  select(annual_income, interest_rate, homeownership)\n\n# A tibble: 50 √ó 3\n   annual_income interest_rate homeownership\n           &lt;dbl&gt;         &lt;dbl&gt; &lt;fct&gt;        \n 1         59000         10.9  rent         \n 2         60000          9.92 rent         \n 3         75000         26.3  mortgage     \n 4         75000          9.92 rent         \n 5        254000          9.43 mortgage     \n 6         67000          9.92 mortgage     \n 7         28800         17.1  rent         \n 8         80000          6.08 mortgage     \n 9         34000          7.97 rent         \n10         80000         12.6  mortgage     \n# ‚Ñπ 40 more rows"
  },
  {
    "objectID": "slides/09-exam-1-review.html#aesthetic-mappings-1",
    "href": "slides/09-exam-1-review.html#aesthetic-mappings-1",
    "title": "Exam 1 review",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\n\nWhat will the following code result in?\n\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate, color = homeownership, shape = homeownership)\n) +\n  geom_point() +\n  scale_color_colorblind()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#aesthetic-mappings-2",
    "href": "slides/09-exam-1-review.html#aesthetic-mappings-2",
    "title": "Exam 1 review",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate, color = homeownership, shape = homeownership)\n) +\n  geom_point() +\n  scale_color_colorblind()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#global-mappings",
    "href": "slides/09-exam-1-review.html#global-mappings",
    "title": "Exam 1 review",
    "section": "Global mappings",
    "text": "Global mappings\n\nWhat will the following code result in?\n\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate, color = homeownership, shape = homeownership)\n) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  scale_color_colorblind()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#global-mappings-1",
    "href": "slides/09-exam-1-review.html#global-mappings-1",
    "title": "Exam 1 review",
    "section": "Global mappings",
    "text": "Global mappings\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate, color = homeownership, shape = homeownership)\n) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  scale_color_colorblind()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#local-mappings",
    "href": "slides/09-exam-1-review.html#local-mappings",
    "title": "Exam 1 review",
    "section": "Local mappings",
    "text": "Local mappings\n\nWhat will the following code result in?\n\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate)\n) +\n  geom_point(aes(color = homeownership)) +\n  geom_smooth(se = FALSE) +\n  scale_color_colorblind()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#local-mappings-1",
    "href": "slides/09-exam-1-review.html#local-mappings-1",
    "title": "Exam 1 review",
    "section": "Local mappings",
    "text": "Local mappings\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate)\n) +\n  geom_point(aes(color = homeownership)) +\n  geom_smooth(se = FALSE) +\n  scale_color_colorblind()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#mapping-vs.-setting",
    "href": "slides/09-exam-1-review.html#mapping-vs.-setting",
    "title": "Exam 1 review",
    "section": "Mapping vs.¬†setting",
    "text": "Mapping vs.¬†setting\n\nWhat will the following code result in?\n\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate)\n) +\n  geom_point(aes(color = homeownership)) +\n  geom_smooth(color = \"red\", se = FALSE) +\n  scale_color_colorblind()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#mapping-vs.-setting-1",
    "href": "slides/09-exam-1-review.html#mapping-vs.-setting-1",
    "title": "Exam 1 review",
    "section": "Mapping vs.¬†setting",
    "text": "Mapping vs.¬†setting\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate)\n) +\n  geom_point(aes(color = homeownership)) +\n  geom_smooth(color = \"red\", se = FALSE) +\n  scale_color_colorblind()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#recap-aesthetic-mappings",
    "href": "slides/09-exam-1-review.html#recap-aesthetic-mappings",
    "title": "Exam 1 review",
    "section": "Recap: Aesthetic mappings",
    "text": "Recap: Aesthetic mappings\n\n\nAesthetic mapping defined at the global level will be used by all geoms for which the aesthetic is defined.\nAesthetic mapping defined at the local level will be used only by the geoms they‚Äôre defined for."
  },
  {
    "objectID": "slides/09-exam-1-review.html#aside-legends",
    "href": "slides/09-exam-1-review.html#aside-legends",
    "title": "Exam 1 review",
    "section": "Aside: Legends",
    "text": "Aside: Legends\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate, color = homeownership, shape = homeownership)\n) +\n  geom_point() +\n  scale_color_colorblind()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#aside-legends-1",
    "href": "slides/09-exam-1-review.html#aside-legends-1",
    "title": "Exam 1 review",
    "section": "Aside: Legends",
    "text": "Aside: Legends\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate, color = homeownership, shape = homeownership)\n) +\n  geom_point() +\n  scale_color_colorblind() +\n  labs(color = \"Home ownership\")"
  },
  {
    "objectID": "slides/09-exam-1-review.html#aside-legends-2",
    "href": "slides/09-exam-1-review.html#aside-legends-2",
    "title": "Exam 1 review",
    "section": "Aside: Legends",
    "text": "Aside: Legends\n\nggplot(\n  loan50,\n  aes(x = annual_income, y = interest_rate, color = homeownership, shape = homeownership)\n) +\n  geom_point() +\n  scale_color_colorblind() +\n  labs(\n    color = \"Home ownership\",\n    shape = \"Home ownership\"\n  )"
  },
  {
    "objectID": "slides/09-exam-1-review.html#factors-1",
    "href": "slides/09-exam-1-review.html#factors-1",
    "title": "Exam 1 review",
    "section": "Factors",
    "text": "Factors\n\nFactors are used for categorical variables ‚Äì variables that have a fixed and known set of possible values.\nThey are also useful when you want to display character vectors in a non-alphabetical order.\n\n\n\nR4DS: https://r4ds.hadley.nz/factors."
  },
  {
    "objectID": "slides/09-exam-1-review.html#bar-plot",
    "href": "slides/09-exam-1-review.html#bar-plot",
    "title": "Exam 1 review",
    "section": "Bar plot",
    "text": "Bar plot\n\nggplot(loan50, aes(x = homeownership)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#bar-plot---reordered",
    "href": "slides/09-exam-1-review.html#bar-plot---reordered",
    "title": "Exam 1 review",
    "section": "Bar plot - reordered",
    "text": "Bar plot - reordered\n\nloan50 |&gt;\n  mutate(homeownership = fct_relevel(homeownership, \"mortgage\", \"rent\", \"own\")) |&gt;\n  ggplot(aes(x = homeownership)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/09-exam-1-review.html#frequency-table",
    "href": "slides/09-exam-1-review.html#frequency-table",
    "title": "Exam 1 review",
    "section": "Frequency table",
    "text": "Frequency table\n\nloan50 |&gt;\n  count(homeownership)\n\n# A tibble: 3 √ó 2\n  homeownership     n\n  &lt;fct&gt;         &lt;int&gt;\n1 rent             21\n2 mortgage         26\n3 own               3"
  },
  {
    "objectID": "slides/09-exam-1-review.html#bar-plot---reordered-1",
    "href": "slides/09-exam-1-review.html#bar-plot---reordered-1",
    "title": "Exam 1 review",
    "section": "Bar plot - reordered",
    "text": "Bar plot - reordered\n\nloan50 |&gt;\n  mutate(homeownership = fct_relevel(homeownership, \"own\", \"rent\", \"mortgage\")) |&gt;\n  count(homeownership)\n\n# A tibble: 3 √ó 2\n  homeownership     n\n  &lt;fct&gt;         &lt;int&gt;\n1 own               3\n2 rent             21\n3 mortgage         26"
  },
  {
    "objectID": "slides/09-exam-1-review.html#under-the-hood",
    "href": "slides/09-exam-1-review.html#under-the-hood",
    "title": "Exam 1 review",
    "section": "Under the hood",
    "text": "Under the hood\n\nclass(loan50$homeownership)\n\n[1] \"factor\"\n\n\n\n\ntypeof(loan50$homeownership)\n\n[1] \"integer\"\n\n\n\n\n\nlevels(loan50$homeownership)\n\n[1] \"rent\"     \"mortgage\" \"own\"     \n\n\n\n\n\nstr(loan50$homeownership)\n\n Factor w/ 3 levels \"rent\",\"mortgage\",..: 1 1 2 1 2 2 1 2 1 2 ..."
  },
  {
    "objectID": "slides/09-exam-1-review.html#recap-factors",
    "href": "slides/09-exam-1-review.html#recap-factors",
    "title": "Exam 1 review",
    "section": "Recap: Factors",
    "text": "Recap: Factors\n\n\nThe forcats package has a bunch of functions (that start with fct_*()) for dealing with factors and their levels: https://forcats.tidyverse.org/reference/index.html\nFactors and the order of their levels are relevant for displays (tables, plots) and they‚Äôll be relevant for modeling (later in the course)\nfactor is a data class"
  },
  {
    "objectID": "slides/09-exam-1-review.html#aside",
    "href": "slides/09-exam-1-review.html#aside",
    "title": "Exam 1 review",
    "section": "Aside: ==",
    "text": "Aside: ==\n\nloan50 |&gt;\n  mutate(homeownership_new = if_else(homeownership == \"rent\", \"don't own\", homeownership)) |&gt;\n  distinct(homeownership, homeownership_new)\n\n# A tibble: 3 √ó 2\n  homeownership homeownership_new\n  &lt;fct&gt;         &lt;chr&gt;            \n1 rent          don't own        \n2 mortgage      mortgage         \n3 own           own"
  },
  {
    "objectID": "slides/09-exam-1-review.html#aside-1",
    "href": "slides/09-exam-1-review.html#aside-1",
    "title": "Exam 1 review",
    "section": "Aside: |",
    "text": "Aside: |\n\nloan50 |&gt;\n  mutate(homeownership_new = if_else(homeownership == \"rent\" | homeownership == \"mortgage\", \"don't own\", homeownership)) |&gt;\n  distinct(homeownership, homeownership_new)\n\n# A tibble: 3 √ó 2\n  homeownership homeownership_new\n  &lt;fct&gt;         &lt;chr&gt;            \n1 rent          don't own        \n2 mortgage      don't own        \n3 own           own"
  },
  {
    "objectID": "slides/09-exam-1-review.html#aside-2",
    "href": "slides/09-exam-1-review.html#aside-2",
    "title": "Exam 1 review",
    "section": "Aside: |",
    "text": "Aside: |\n\nloan50 |&gt;\n  mutate(homeownership_new = if_else(homeownership %in% c(\"rent\", \"mortgage\"), \"don't own\", homeownership)) |&gt;\n  distinct(homeownership, homeownership_new)\n\n# A tibble: 3 √ó 2\n  homeownership homeownership_new\n  &lt;fct&gt;         &lt;chr&gt;            \n1 rent          don't own        \n2 mortgage      don't own        \n3 own           own"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#announcements",
    "href": "slides/01-meet-the-toolkit.html#announcements",
    "title": "Meet the toolkit",
    "section": "Announcements",
    "text": "Announcements\n\nIf you have not yet completed the Getting to know you survey, please do so asap!\nIf you have not yet accepted the invite to join the course GitHub Organization (I‚Äôm looking at 41 of you as of this morning!), please do so asap!\nOffice hours + locations linked at https://sta199-s24.github.io/course-team.html, come say hi to me or any of the TAs!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#course-homepage",
    "href": "slides/01-meet-the-toolkit.html#course-homepage",
    "title": "Meet the toolkit",
    "section": "Course homepage",
    "text": "Course homepage\nLet‚Äôs take a tour!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#collaboration-policy",
    "href": "slides/01-meet-the-toolkit.html#collaboration-policy",
    "title": "Meet the toolkit",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nOnly work that is clearly assigned as team work should be completed collaboratively.\nHomeworks must be completed individually. You may not directly share answers / code with others, however you are welcome to discuss the problems in general and ask for advice.\nExams must be completed individually. You may not discuss any aspect of the exam with peers. If you have questions, post as private questions on the course forum, only the teaching team will see and answer."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#sharing-reusing-code-policy",
    "href": "slides/01-meet-the-toolkit.html#sharing-reusing-code-policy",
    "title": "Meet the toolkit",
    "section": "Sharing / reusing code policy",
    "text": "Sharing / reusing code policy\n\nWe are aware that a huge volume of code is available on the web, and many tasks may have solutions posted\nUnless explicitly stated otherwise, this course‚Äôs policy is that you may make use of any online resources (e.g.¬†RStudio Community, StackOverflow, etc.) but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solution(s).\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#use-of-generative-ai",
    "href": "slides/01-meet-the-toolkit.html#use-of-generative-ai",
    "title": "Meet the toolkit",
    "section": "Use of generative AI",
    "text": "Use of generative AI\n\nTreat generative AI, such as ChatGPT, the same as other online resources.\nGuiding principles:\n\n(1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate‚Äîrather than hinder‚Äîlearning.\n(2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n‚úÖ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. See the syllabus for guidelines for citing AI-generated content.\n‚ùå AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#academic-integrity",
    "href": "slides/01-meet-the-toolkit.html#academic-integrity",
    "title": "Meet the toolkit",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#most-importantly",
    "href": "slides/01-meet-the-toolkit.html#most-importantly",
    "title": "Meet the toolkit",
    "section": "Most importantly!",
    "text": "Most importantly!\nAsk if you‚Äôre not sure if something violates a policy!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#five-tips-for-success",
    "href": "slides/01-meet-the-toolkit.html#five-tips-for-success",
    "title": "Meet the toolkit",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work before class.\nAsk questions.\nDo the readings.\nDo the lab.\nDon‚Äôt procrastinate ‚Äì at least on a weekly basis!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#course-toolkit-1",
    "href": "slides/01-meet-the-toolkit.html#course-toolkit-1",
    "title": "Meet the toolkit",
    "section": "Course toolkit",
    "text": "Course toolkit\n\n\nCourse operation\n\nMaterials: sta199-s24.github.io\nSubmission: Gradescope\nDiscussion: Ed Discussion\nGradebook: Canvas\n\n\nDoing data science\n\nComputing:\n\nR\nRStudio\ntidyverse\nQuarto\n\nVersion control and collaboration:\n\nGit\nGitHub"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#learning-goals",
    "href": "slides/01-meet-the-toolkit.html#learning-goals",
    "title": "Meet the toolkit",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the course, you will be able to‚Ä¶\n\n\ngain insight from data\ngain insight from data, reproducibly\ngain insight from data, reproducibly, using modern programming tools and techniques\ngain insight from data, reproducibly and collaboratively, using modern programming tools and techniques\ngain insight from data, reproducibly (with literate programming and version control) and collaboratively, using modern programming tools and techniques"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#reproducibility-checklist",
    "href": "slides/01-meet-the-toolkit.html#reproducibility-checklist",
    "title": "Meet the toolkit",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for a data analysis to be ‚Äúreproducible‚Äù?\n\n\nShort-term goals:\n\nAre the tables and figures reproducible from the code and data?\nDoes the code actually do what you think it does?\nIn addition to what was done, is it clear why it was done?\n\n\n\nLong-term goals:\n\nCan the code be used for other data?\nCan you extend the code to do other things?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#toolkit-for-reproducibility",
    "href": "slides/01-meet-the-toolkit.html#toolkit-for-reproducibility",
    "title": "Meet the toolkit",
    "section": "Toolkit for reproducibility",
    "text": "Toolkit for reproducibility\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-and-rstudio-1",
    "href": "slides/01-meet-the-toolkit.html#r-and-rstudio-1",
    "title": "Meet the toolkit",
    "section": "R and RStudio",
    "text": "R and RStudio\n\n\n\n\n\n\n\n\nR is an open-source statistical programming language\nR is also an environment for statistical computing and graphics\nIt‚Äôs easily extensible with packages\n\n\n\n\nRStudio is a convenient interface for R called an IDE (integrated development environment), e.g.¬†‚ÄúI write R code in the RStudio IDE‚Äù\nRStudio is not a requirement for programming with R, but it‚Äôs very commonly used by R programmers and data scientists"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-vs.-rstudio",
    "href": "slides/01-meet-the-toolkit.html#r-vs.-rstudio",
    "title": "Meet the toolkit",
    "section": "R vs.¬†RStudio",
    "text": "R vs.¬†RStudio\n\n\n\n\n\n\n\nSource: Modern Dive."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-packages",
    "href": "slides/01-meet-the-toolkit.html#r-packages",
    "title": "Meet the toolkit",
    "section": "R packages",
    "text": "R packages\n\n\nPackages: Fundamental units of reproducible R code, including reusable R functions, the documentation that describes how to use them, and sample data1\nAs of 15 January 2023, there are 20,252 R packages available on CRAN (the Comprehensive R Archive Network)2\nWe‚Äôre going to work with a small (but important) subset of these!\n\n\n\n\n1 Wickham and Bryan, R Packages.\n2 CRAN contributed packages."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-r-rstudio",
    "href": "slides/01-meet-the-toolkit.html#tour-r-rstudio",
    "title": "Meet the toolkit",
    "section": "Tour: R + RStudio",
    "text": "Tour: R + RStudio\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\nOption 2:\nClone the corresponding application exercise repo and follow along.\n ae-01-meet-the-penguins\nGo to the course GitHub organization and clone ae-01-meet-the-penguins to your container."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-r-rstudio",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-r-rstudio",
    "title": "Meet the toolkit",
    "section": "Tour recap: R + RStudio",
    "text": "Tour recap: R + RStudio"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#a-short-list-for-now-of-r-essentials",
    "href": "slides/01-meet-the-toolkit.html#a-short-list-for-now-of-r-essentials",
    "title": "Meet the toolkit",
    "section": "A short list (for now) of R essentials",
    "text": "A short list (for now) of R essentials\n\nFunctions are (most often) verbs, followed by what they will be applied to in parentheses:\n\n\ndo_this(to_this)\ndo_that(to_this, to_that, with_those)\n\n\n\nPackages are installed with the install.packages() function and loaded with the library function, once per session:\n\n\ninstall.packages(\"package_name\")\nlibrary(package_name)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-essentials-continued",
    "href": "slides/01-meet-the-toolkit.html#r-essentials-continued",
    "title": "Meet the toolkit",
    "section": "R essentials (continued)",
    "text": "R essentials (continued)\n\nColumns (variables) in data frames are accessed with $:\n\n\ndataframe$var_name\n\n\n\nObject documentation can be accessed with ?\n\n\n?mean"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tidyverse",
    "href": "slides/01-meet-the-toolkit.html#tidyverse",
    "title": "Meet the toolkit",
    "section": "tidyverse",
    "text": "tidyverse\n\n\n\n\ntidyverse.org\n\nThe tidyverse is an opinionated collection of R packages designed for data science\nAll packages share an underlying philosophy and a common grammar"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#quarto-1",
    "href": "slides/01-meet-the-toolkit.html#quarto-1",
    "title": "Meet the toolkit",
    "section": "Quarto",
    "text": "Quarto\n\n\nFully reproducible reports ‚Äì each time you render the analysis is ran from the beginning\nCode goes in chunks narrative goes outside of chunks\nA visual editor for a familiar / Google docs-like editing experience"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-quarto",
    "href": "slides/01-meet-the-toolkit.html#tour-quarto",
    "title": "Meet the toolkit",
    "section": "Tour: Quarto",
    "text": "Tour: Quarto\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\nOption 2:\nClone the corresponding application exercise repo (if you haven‚Äôt yet done so) and follow along.\n ae-01-meet-the-penguins\nGo to the course GitHub organization and clone ae-01-meet-the-penguins to your container."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-quarto",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-quarto",
    "title": "Meet the toolkit",
    "section": "Tour recap: Quarto",
    "text": "Tour recap: Quarto"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#environments",
    "href": "slides/01-meet-the-toolkit.html#environments",
    "title": "Meet the toolkit",
    "section": "Environments",
    "text": "Environments\n\n\n\n\n\n\nImportant\n\n\nThe environment of your Quarto document is separate from the Console!\n\n\n\nRemember this, and expect it to bite you a few times as you‚Äôre learning to work with Quarto!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#environments-1",
    "href": "slides/01-meet-the-toolkit.html#environments-1",
    "title": "Meet the toolkit",
    "section": "Environments",
    "text": "Environments\n\n\nFirst, run the following in the console:\n\nx &lt;- 2\nx * 3\n\n\n\nAll looks good, eh?\n\n\nThen, add the following in an R chunk in your Quarto document\n\nx * 3\n\n\n\nWhat happens? Why the error?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-quarto",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-quarto",
    "title": "Meet the toolkit",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise, lab, project, etc. is an Quarto document\nYou‚Äôll always have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#whats-with-all-the-hexes",
    "href": "slides/01-meet-the-toolkit.html#whats-with-all-the-hexes",
    "title": "Meet the toolkit",
    "section": "What‚Äôs with all the hexes?",
    "text": "What‚Äôs with all the hexes?\n\n\n\n\n\n\n\n\n\nüîó sta199-s24.github.io"
  },
  {
    "objectID": "slides/00-welcome-199.html#meet-the-prof",
    "href": "slides/00-welcome-199.html#meet-the-prof",
    "title": "Welcome to STA 199",
    "section": "Meet the prof",
    "text": "Meet the prof\n\n\nDr.¬†Mine √áetinkaya-Rundel\nProfessor of the Practice\nOld Chem 213"
  },
  {
    "objectID": "slides/00-welcome-199.html#meet-the-course-team",
    "href": "slides/00-welcome-199.html#meet-the-course-team",
    "title": "Welcome to STA 199",
    "section": "Meet the course team",
    "text": "Meet the course team\n\n\n\nMary Knox (Course coordinator)\nBetsy Bersson (Head TA)\nChris Oswald\nJasmine Wang\nMert Bildirici\nWill Tirone\nKrish Bansal\nCaitrin Murphy\nAvery Hodges\nJon Campbell\n\n\n\nFoxx Hart\nNetra MittalAlexa Fahrer\nDevin Johnson\nKonnie Huang\nLi Fan\nKelly Huang\nLeah Johnson\nLisa Zhang\nMiles King\nNoah Obuya"
  },
  {
    "objectID": "slides/00-welcome-199.html#meet-each-other",
    "href": "slides/00-welcome-199.html#meet-each-other",
    "title": "Welcome to STA 199",
    "section": "Meet each other!",
    "text": "Meet each other!\n\n\n\n‚àí+\n03:00"
  },
  {
    "objectID": "slides/00-welcome-199.html#meet-data-science",
    "href": "slides/00-welcome-199.html#meet-data-science",
    "title": "Welcome to STA 199",
    "section": "Meet data science",
    "text": "Meet data science\n\nData science is an exciting discipline that allows you to turn raw data into understanding, insight, and knowledge.\nWe‚Äôre going to learn to do this in a tidy way ‚Äì more on that later!\nThis is a course on introduction to data science, with an emphasis on statistical thinking."
  },
  {
    "objectID": "slides/00-welcome-199.html#excel---not",
    "href": "slides/00-welcome-199.html#excel---not",
    "title": "Welcome to STA 199",
    "section": "Excel - not‚Ä¶",
    "text": "Excel - not‚Ä¶"
  },
  {
    "objectID": "slides/00-welcome-199.html#r",
    "href": "slides/00-welcome-199.html#r",
    "title": "Welcome to STA 199",
    "section": "R",
    "text": "R"
  },
  {
    "objectID": "slides/00-welcome-199.html#rstudio",
    "href": "slides/00-welcome-199.html#rstudio",
    "title": "Welcome to STA 199",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "slides/00-welcome-199.html#data-science-life-cycle-1",
    "href": "slides/00-welcome-199.html#data-science-life-cycle-1",
    "title": "Welcome to STA 199",
    "section": "Data science life cycle",
    "text": "Data science life cycle"
  },
  {
    "objectID": "slides/00-welcome-199.html#import",
    "href": "slides/00-welcome-199.html#import",
    "title": "Welcome to STA 199",
    "section": "Import",
    "text": "Import"
  },
  {
    "objectID": "slides/00-welcome-199.html#tidy-transform",
    "href": "slides/00-welcome-199.html#tidy-transform",
    "title": "Welcome to STA 199",
    "section": "Tidy + transform",
    "text": "Tidy + transform"
  },
  {
    "objectID": "slides/00-welcome-199.html#visualize",
    "href": "slides/00-welcome-199.html#visualize",
    "title": "Welcome to STA 199",
    "section": "Visualize",
    "text": "Visualize"
  },
  {
    "objectID": "slides/00-welcome-199.html#model",
    "href": "slides/00-welcome-199.html#model",
    "title": "Welcome to STA 199",
    "section": "Model",
    "text": "Model"
  },
  {
    "objectID": "slides/00-welcome-199.html#understand",
    "href": "slides/00-welcome-199.html#understand",
    "title": "Welcome to STA 199",
    "section": "Understand",
    "text": "Understand"
  },
  {
    "objectID": "slides/00-welcome-199.html#section",
    "href": "slides/00-welcome-199.html#section",
    "title": "Welcome to STA 199",
    "section": "",
    "text": "# A tibble: 5 √ó 2\n  date             season\n  &lt;chr&gt;            &lt;chr&gt; \n1 23 January 2017  winter\n2 4 March 2017     spring\n3 14 June 2017     summer\n4 1 September 2017 fall  \n5 ...              ..."
  },
  {
    "objectID": "slides/00-welcome-199.html#communicate",
    "href": "slides/00-welcome-199.html#communicate",
    "title": "Welcome to STA 199",
    "section": "Communicate",
    "text": "Communicate"
  },
  {
    "objectID": "slides/00-welcome-199.html#understand-communicate",
    "href": "slides/00-welcome-199.html#understand-communicate",
    "title": "Welcome to STA 199",
    "section": "Understand + communicate",
    "text": "Understand + communicate"
  },
  {
    "objectID": "slides/00-welcome-199.html#program",
    "href": "slides/00-welcome-199.html#program",
    "title": "Welcome to STA 199",
    "section": "Program",
    "text": "Program"
  },
  {
    "objectID": "slides/00-welcome-199.html#application-exercise",
    "href": "slides/00-welcome-199.html#application-exercise",
    "title": "Welcome to STA 199",
    "section": "Application exercise",
    "text": "Application exercise\n\nOr more like demo for today‚Ä¶\nüìã github.com/sta199-s24/ae-00-unvotes"
  },
  {
    "objectID": "slides/00-welcome-199.html#homepage",
    "href": "slides/00-welcome-199.html#homepage",
    "title": "Welcome to STA 199",
    "section": "Homepage",
    "text": "Homepage\nhttps://sta199-s24.github.io\n\nAll course materials\nLinks to Canvas, GitHub, RStudio containers, etc."
  },
  {
    "objectID": "slides/00-welcome-199.html#course-toolkit",
    "href": "slides/00-welcome-199.html#course-toolkit",
    "title": "Welcome to STA 199",
    "section": "Course toolkit",
    "text": "Course toolkit\nAll linked from the course website:\n\nGitHub organization: github.com/sta199-s24\nRStudio containers: cmgr.oit.duke.edu/containers\nCommunication: Ed Discussion\nAssignment submission and feedback: Gradescope"
  },
  {
    "objectID": "slides/00-welcome-199.html#activities",
    "href": "slides/00-welcome-199.html#activities",
    "title": "Welcome to STA 199",
    "section": "Activities",
    "text": "Activities\n\nIntroduce new content and prepare for lectures by watching the videos and completing the readings\nAttend and actively participate in lectures and labs, office hours, team meetings\nPractice applying statistical concepts and computing with application exercises during lecture, graded for completion\nPut together what you‚Äôve learned to analyze real-world data\n\nLab assignments x 7\nExams x 2\nTerm project presented in the last lab session"
  },
  {
    "objectID": "slides/00-welcome-199.html#exams",
    "href": "slides/00-welcome-199.html#exams",
    "title": "Welcome to STA 199",
    "section": "Exams",
    "text": "Exams\n\nTwo exams, each 20%\nEach exam comprised of two parts:\n\nIn class: 75 minute in-class exam. Closed book, one sheet of notes (‚Äúcheat sheet‚Äù, no larger than 8 1/2 x 11, both sides, must be prepared by you) ‚Äì 70% of the grade\nTake home: The take home portion will follow from the in class exam and focus on the analysis of a dataset introduced in the take home exam ‚Äì 30% of the grade\n\n\n\n\n\n\n\n\nCaution\n\n\nExam dates cannot be changed and no make-up exams will be given. If you can‚Äôt take the exams on these dates, you should drop this class."
  },
  {
    "objectID": "slides/00-welcome-199.html#project",
    "href": "slides/00-welcome-199.html#project",
    "title": "Welcome to STA 199",
    "section": "Project",
    "text": "Project\n\nDataset of your choice, method of your choice\nTeamwork\nPresentation and write-up\nPresentations in the last lab\nInterim deadlines, peer review on content, peer evaluation for team contribution\nSome lab sessions allocated to working on projects, doing peer review, getting feedback from TAs\n\n\n\n\n\n\n\nCaution\n\n\nFinal presentation date cannot be changed. If you can‚Äôt present on that date, you should drop this class. You must complete the project to pass this class."
  },
  {
    "objectID": "slides/00-welcome-199.html#teams",
    "href": "slides/00-welcome-199.html#teams",
    "title": "Welcome to STA 199",
    "section": "Teams",
    "text": "Teams\n\nAssigned by me\nProject\nPeer evaluation during teamwork and after completion\nExpectations and roles\n\nEveryone is expected to contribute equal effort\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "slides/00-welcome-199.html#grading",
    "href": "slides/00-welcome-199.html#grading",
    "title": "Welcome to STA 199",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nLabs\n35%\n\n\nProject\n20%\n\n\nExam 1\n20%\n\n\nExam 2\n20%\n\n\nApplication Exercises\n5%\n\n\n\nNo specific points allocated to attendance, but attendance will be recorded periodically throughout the semester, and this information will be used as ‚Äúextra credit‚Äù if you‚Äôre in between two grades and a minor bump would help.\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/00-welcome-199.html#support",
    "href": "slides/00-welcome-199.html#support",
    "title": "Welcome to STA 199",
    "section": "Support",
    "text": "Support\n\nAttend office hours\nAsk and answer questions on the discussion forum\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/00-welcome-199.html#announcements",
    "href": "slides/00-welcome-199.html#announcements",
    "title": "Welcome to STA 199",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Canvas (Announcements tool) and sent via email, be sure to check both regularly\nI‚Äôll assume that you‚Äôve read an announcement by the next ‚Äúbusiness‚Äù day\nI‚Äôll (try my best to) send a weekly update announcement each Friday, outlining the plan for the following week and reminding you what you need to do to prepare, practice, and perform"
  },
  {
    "objectID": "slides/00-welcome-199.html#diversity-inclusion",
    "href": "slides/00-welcome-199.html#diversity-inclusion",
    "title": "Welcome to STA 199",
    "section": "Diversity + inclusion",
    "text": "Diversity + inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\n\nPlease let me know your preferred name and pronouns on the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisors, and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/00-welcome-199.html#accessibility",
    "href": "slides/00-welcome-199.html#accessibility",
    "title": "Welcome to STA 199",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I‚Äôm always learning how to do this better. If any course component is not accessible to you in any way, please don‚Äôt hesitate to let me know."
  },
  {
    "objectID": "slides/00-welcome-199.html#late-work-waivers-regrades-policy",
    "href": "slides/00-welcome-199.html#late-work-waivers-regrades-policy",
    "title": "Welcome to STA 199",
    "section": "Late work, waivers, regrades policy",
    "text": "Late work, waivers, regrades policy\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/00-welcome-199.html#academic-integrity",
    "href": "slides/00-welcome-199.html#academic-integrity",
    "title": "Welcome to STA 199",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised."
  },
  {
    "objectID": "slides/00-welcome-199.html#this-weeks-tasks",
    "href": "slides/00-welcome-199.html#this-weeks-tasks",
    "title": "Welcome to STA 199",
    "section": "This week‚Äôs tasks",
    "text": "This week‚Äôs tasks\n\nComplete Lab 0\n\nComputational setup\nGetting to know you survey\n\nRead the syllabus\nStart readings for next week"
  },
  {
    "objectID": "slides/00-welcome-199.html#midori-says",
    "href": "slides/00-welcome-199.html#midori-says",
    "title": "Welcome to STA 199",
    "section": "Midori says‚Ä¶",
    "text": "Midori says‚Ä¶\n\n\n\n\n\n\n\n\n\nüîó sta199-s24.github.io"
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#while-you-wait-for-class-to-begin",
    "href": "slides/18-model-selection-overfitting.html#while-you-wait-for-class-to-begin",
    "title": "Model selection and overfitting",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\n\nAny questions from prepare materials?"
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#announcements",
    "href": "slides/18-model-selection-overfitting.html#announcements",
    "title": "Model selection and overfitting",
    "section": "Announcements",
    "text": "Announcements\n\nRead the feedback (including written feedback) on labs\nProject repos to be released back to you on Friday\nStatus update emails in your inbox"
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#can-you-review-the-augment-function",
    "href": "slides/18-model-selection-overfitting.html#can-you-review-the-augment-function",
    "title": "Model selection and overfitting",
    "section": "Can you review the augment() function?",
    "text": "Can you review the augment() function?\nThe augment() function can be used to ‚Äúaugment‚Äù a data set (usually of new observations) with the model.\n\n\nIt calculates predictions, \\(\\hat{y}\\)s, under the given model.\nIt also calculates the residuals, \\(e\\)s, for each observation.\nIt returns a data frame of the input data augmented with predicted values and residuals."
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#augment---setup",
    "href": "slides/18-model-selection-overfitting.html#augment---setup",
    "title": "Model selection and overfitting",
    "section": "augment() - Setup",
    "text": "augment() - Setup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nmtcars_fit &lt;- linear_reg() |&gt;\n  fit(mpg ~ disp + cyl, data = mtcars)\n\ntidy(mtcars_fit)\n\n# A tibble: 3 √ó 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  34.7       2.55       13.6  4.02e-14\n2 disp         -0.0206    0.0103     -2.01 5.42e- 2\n3 cyl          -1.59      0.712      -2.23 3.37e- 2"
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#augment---augment-the-original-data",
    "href": "slides/18-model-selection-overfitting.html#augment---augment-the-original-data",
    "title": "Model selection and overfitting",
    "section": "augment() - Augment the original data",
    "text": "augment() - Augment the original data\n\naugment(mtcars_fit, new_data = mtcars)\n\n# A tibble: 32 √ó 13\n   .pred .resid   mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21.8 -0.844  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21.8 -0.844  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  26.1 -3.29   22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  19.8  1.57   21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  14.6  4.15   18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  20.5 -2.41   18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.6 -0.253  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  25.3 -0.892  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  25.4 -2.61   22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  21.7 -2.49   19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ‚Ñπ 22 more rows"
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#augment---augment-new-data",
    "href": "slides/18-model-selection-overfitting.html#augment---augment-new-data",
    "title": "Model selection and overfitting",
    "section": "augment() - Augment new data",
    "text": "augment() - Augment new data\n\nnew_cars &lt;- tibble(\n  mpg = c(23, 22), disp = c(150, 350), cyl = c(4, 6)\n)\n\nnew_cars\n\n# A tibble: 2 √ó 3\n    mpg  disp   cyl\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    23   150     4\n2    22   350     6\n\n\n\n\naugment(mtcars_fit, new_data = new_cars)\n\n# A tibble: 2 √ó 5\n  .pred .resid   mpg  disp   cyl\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  25.2  -2.22    23   150     4\n2  17.9   4.07    22   350     6"
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#what-is-the-difference-between-r2-and-adjusted-r2",
    "href": "slides/18-model-selection-overfitting.html#what-is-the-difference-between-r2-and-adjusted-r2",
    "title": "Model selection and overfitting",
    "section": "What is the difference between \\(R^2\\) and adjusted \\(R^2\\)?",
    "text": "What is the difference between \\(R^2\\) and adjusted \\(R^2\\)?\n\n\\(R^2\\):\n\nProportion of variability in the outcome explained by the model.\nUseful for quantifying the fit of a given model.\n\n\n\n\nAdjusted \\(R^2\\):\n\nProportion of variability in the outcome explained by the model, with a penalty added for the number of predictors in the model.\nUseful for comparing models."
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#application-exercise-ae-13-modeling-loans",
    "href": "slides/18-model-selection-overfitting.html#application-exercise-ae-13-modeling-loans",
    "title": "Model selection and overfitting",
    "section": "Application exercise: ae-13-modeling-loans",
    "text": "Application exercise: ae-13-modeling-loans\n\n\nGo to your project called ae.\nContinue working on ae-13-modeling-loans.qmd.\n\n\nGoals:\n\nReview prediction and interpretation of model results\nReview main and interaction effects models\nDiscuss model selection further"
  },
  {
    "objectID": "slides/18-model-selection-overfitting.html#recap-ae-13-modeling-loans",
    "href": "slides/18-model-selection-overfitting.html#recap-ae-13-modeling-loans",
    "title": "Model selection and overfitting",
    "section": "Recap: ae-13-modeling-loans",
    "text": "Recap: ae-13-modeling-loans\n\nWhat is the practical difference between a model with parallel and non-parallel lines?\nWhat is the definition of R-squared?\nWhy do we choose models based on adjusted R-squared and not R-squared?\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#while-you-wait-for-class-to-begin",
    "href": "slides/05-grammar-of-data-wrangling.html#while-you-wait-for-class-to-begin",
    "title": "Grammar of data wrangling",
    "section": "While you wait for class to begin‚Ä¶",
    "text": "While you wait for class to begin‚Ä¶\n\nGo to your ae repo, click Pull to get today‚Äôs application exercise to get ready for later.\nQuestions from the prepare materials?"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#asking-good-questions",
    "href": "slides/05-grammar-of-data-wrangling.html#asking-good-questions",
    "title": "Grammar of data wrangling",
    "section": "Asking good questions",
    "text": "Asking good questions\n\nPost content questions on Ed Discussion\nIf you have a coding question always provide the code, and if relevant, the error\n\nIf this feels impossible, don‚Äôt fret it, it‚Äôs ok to ask questions without the code. It‚Äôs just more efficient with it!\n\nTitle your thread in a way that can help others (e.g., ‚ÄúQ7‚Äù vs.¬†‚Äúerror with mutate() function in Lab 1 - Q7‚Äù)\nCheck for previous questions"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#coding-style-workflow",
    "href": "slides/05-grammar-of-data-wrangling.html#coding-style-workflow",
    "title": "Grammar of data wrangling",
    "section": "Coding style + workflow",
    "text": "Coding style + workflow\n\n\nAvoid long lines of code.\n\nWe should be able to see all of your code in the PDF document you submit.\n\nLabel code chunks.\n\nDo not put spaces in the code-chunk labels.\n\nRender, commit, and push regularly.\n\nThink about it like clicking to save regularly as you type a report."
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#lab-1",
    "href": "slides/05-grammar-of-data-wrangling.html#lab-1",
    "title": "Grammar of data wrangling",
    "section": "Lab 1",
    "text": "Lab 1"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#nyc-flights",
    "href": "slides/05-grammar-of-data-wrangling.html#nyc-flights",
    "title": "Grammar of data wrangling",
    "section": "NYC Flights",
    "text": "NYC Flights\n\nTo demonstrate data wrangling we will use flights, a tibble in the nycflights13 R package.\nThe data set includes characteristics of all flights departing from New York City (JFK, LGA, EWR) in 2013.\n\n\nlibrary(tidyverse)\nlibrary(nycflights13)"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#flights-dimensions",
    "href": "slides/05-grammar-of-data-wrangling.html#flights-dimensions",
    "title": "Grammar of data wrangling",
    "section": "flights ‚Äì dimensions",
    "text": "flights ‚Äì dimensions\n\nNumber of rows:\n\n\nnrow(flights)\n\n[1] 336776\n\n\n\n\nNumber of columns:\n\n\nncol(flights)\n\n[1] 19"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#flights-first-look",
    "href": "slides/05-grammar-of-data-wrangling.html#flights-first-look",
    "title": "Grammar of data wrangling",
    "section": "flights ‚Äì first look",
    "text": "flights ‚Äì first look\n\nglimpse()names()head()\n\n\n\nglimpse(flights)\n\nRows: 336,776\nColumns: 19\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013,‚Ä¶\n$ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, 558, 558, ‚Ä¶\n$ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, 600, 600, ‚Ä¶\n$ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1, 0, -1, 0‚Ä¶\n$ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849, 853, 924,‚Ä¶\n$ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851, 856, 917,‚Ä¶\n$ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -14, 31, -4,‚Ä¶\n$ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"AA\", \"B6\",‚Ä¶\n$ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 49, 71, 194‚Ä¶\n$ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N39463\", \"N516‚Ä¶\n$ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\", \"JFK\", \"L‚Ä¶\n$ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\", \"MCO\", \"O‚Ä¶\n$ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 158, 345, 3‚Ä¶\n$ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, 1028, 1005‚Ä¶\n$ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6,‚Ä¶\n$ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0, 0, 0, 0,‚Ä¶\n$ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2‚Ä¶\n\n\n\n\n\nnames(flights)\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"       \"sched_dep_time\"\n [6] \"dep_delay\"      \"arr_time\"       \"sched_arr_time\" \"arr_delay\"      \"carrier\"       \n[11] \"flight\"         \"tailnum\"        \"origin\"         \"dest\"           \"air_time\"      \n[16] \"distance\"       \"hour\"           \"minute\"         \"time_hour\"     \n\n\n\n\n\nhead(flights)\n\n# A tibble: 6 √ó 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n1  2013     1     1      517            515         2      830            819        11\n2  2013     1     1      533            529         4      850            830        20\n3  2013     1     1      542            540         2      923            850        33\n4  2013     1     1      544            545        -1     1004           1022       -18\n5  2013     1     1      554            600        -6      812            837       -25\n6  2013     1     1      554            558        -4      740            728        12\n# ‚Ñπ 10 more variables: carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;,\n#   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,\n#   time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#tibble-vs.-data-frame",
    "href": "slides/05-grammar-of-data-wrangling.html#tibble-vs.-data-frame",
    "title": "Grammar of data wrangling",
    "section": "tibble vs.¬†data frame",
    "text": "tibble vs.¬†data frame\n\n\ntibble: an opinionated version of the R data frame\nAll tibbles are data frames, but not all data frames are tibbles!\nTwo main differences between a tibble and a data frame:\n\nPrinting\nStricter subsetting"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#printing",
    "href": "slides/05-grammar-of-data-wrangling.html#printing",
    "title": "Grammar of data wrangling",
    "section": "Printing",
    "text": "Printing\n\ntibbledata.frame\n\n\nDisplay first 10 rows and all of the columns that fit on the screen will display, along with the type of each column.\n\nflights\n\n# A tibble: 336,776 √ó 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     1      517            515         2      830            819        11\n 2  2013     1     1      533            529         4      850            830        20\n 3  2013     1     1      542            540         2      923            850        33\n 4  2013     1     1      544            545        -1     1004           1022       -18\n 5  2013     1     1      554            600        -6      812            837       -25\n 6  2013     1     1      554            558        -4      740            728        12\n 7  2013     1     1      555            600        -5      913            854        19\n 8  2013     1     1      557            600        -3      709            723       -14\n 9  2013     1     1      557            600        -3      838            846        -8\n10  2013     1     1      558            600        -2      753            745         8\n# ‚Ñπ 336,766 more rows\n# ‚Ñπ 10 more variables: carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;,\n#   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,\n#   time_hour &lt;dttm&gt;\n\n\n\n\n(Attempt to) display all of the data, or die (crash) tryin (if the dataset is too large)!\n\ncars\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#stricter-subsetting",
    "href": "slides/05-grammar-of-data-wrangling.html#stricter-subsetting",
    "title": "Grammar of data wrangling",
    "section": "Stricter subsetting",
    "text": "Stricter subsetting\n\ntibbledata.frame\n\n\nWarning + NULL if variable not found.\n\nflights$apple\n\nWarning: Unknown or uninitialised column: `apple`.\n\n\nNULL\n\n\n\n\nOnly NULL if variable not found.\n\ncars$apple\n\nNULL"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#dplyr",
    "href": "slides/05-grammar-of-data-wrangling.html#dplyr",
    "title": "Grammar of data wrangling",
    "section": "dplyr",
    "text": "dplyr\nPrimary package in the tidyverse for data wrangling\n\n\ndplyr.tidyverse.org\n\n\nCheat sheet"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#row-operations",
    "href": "slides/05-grammar-of-data-wrangling.html#row-operations",
    "title": "Grammar of data wrangling",
    "section": "Row operations",
    "text": "Row operations\n\nslice(): chooses rows based on location\nfilter():chooses rows based on column values\narrange(): changes the order of the rows\nsample_n(): take a random subset of the rows"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#slice",
    "href": "slides/05-grammar-of-data-wrangling.html#slice",
    "title": "Grammar of data wrangling",
    "section": "slice()",
    "text": "slice()\nDisplay the first five rows of flights:\n\n1flights |&gt;\n2  slice(1:5)\n\n\n1\n\nTake the flights data frame, and then,\n\n2\n\nSlice its first five rows\n\n\n\n\n# A tibble: 5 √ó 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n1  2013     1     1      517            515         2      830            819        11\n2  2013     1     1      533            529         4      850            830        20\n3  2013     1     1      542            540         2      923            850        33\n4  2013     1     1      544            545        -1     1004           1022       -18\n5  2013     1     1      554            600        -6      812            837       -25\n# ‚Ñπ 10 more variables: carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;,\n#   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,\n#   time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#filter",
    "href": "slides/05-grammar-of-data-wrangling.html#filter",
    "title": "Grammar of data wrangling",
    "section": "filter()",
    "text": "filter()\nFilter for flights to RDU in flights:\n\n1flights |&gt;\n2  filter(dest == \"RDU\")\n\n\n1\n\nTake the flights data frame, and then,\n\n2\n\nFilter for rows where dest is equal to RDU\n\n\n\n\n# A tibble: 8,163 √ó 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     1      800            810       -10      949            955        -6\n 2  2013     1     1      832            840        -8     1006           1030       -24\n 3  2013     1     1      851            851         0     1032           1036        -4\n 4  2013     1     1      917            920        -3     1052           1108       -16\n 5  2013     1     1     1024           1030        -6     1204           1215       -11\n 6  2013     1     1     1127           1129        -2     1303           1309        -6\n 7  2013     1     1     1157           1205        -8     1342           1345        -3\n 8  2013     1     1     1240           1235         5     1415           1415         0\n 9  2013     1     1     1317           1325        -8     1454           1505       -11\n10  2013     1     1     1449           1450        -1     1651           1640        11\n# ‚Ñπ 8,153 more rows\n# ‚Ñπ 10 more variables: carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;,\n#   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,\n#   time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#the-pipe",
    "href": "slides/05-grammar-of-data-wrangling.html#the-pipe",
    "title": "Grammar of data wrangling",
    "section": "The pipe",
    "text": "The pipe\n\n\nThe pipe, |&gt;, is an operator (a tool) for passing information from one process to another.\nUse |&gt; mainly in data pipelines to pass the output of the previous line of code as the first input of the next line of code.\nWhen reading code ‚Äúin English‚Äù, say ‚Äúand then‚Äù whenever you see a pipe."
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#delayed-flights-to-rdu",
    "href": "slides/05-grammar-of-data-wrangling.html#delayed-flights-to-rdu",
    "title": "Grammar of data wrangling",
    "section": "Delayed flights to RDU",
    "text": "Delayed flights to RDU\n\nWhich airline is the most delayed, on average, arriving in RDU from a New York City airport?\n\n\nGoal:\n\n\n# A tibble: 5 √ó 2\n  carrier mean_arr_delay\n  &lt;chr&gt;            &lt;dbl&gt;\n1 UA               56   \n2 B6               13.3 \n3 EV               12.2 \n4 9E                9.67\n5 MQ                8.82"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#the-pipe-in-action",
    "href": "slides/05-grammar-of-data-wrangling.html#the-pipe-in-action",
    "title": "Grammar of data wrangling",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\n1flights\n\n\n1\n\nTake the flights data frame\n\n\n\n\n# A tibble: 336,776 √ó 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     1      517            515         2      830            819        11\n 2  2013     1     1      533            529         4      850            830        20\n 3  2013     1     1      542            540         2      923            850        33\n 4  2013     1     1      544            545        -1     1004           1022       -18\n 5  2013     1     1      554            600        -6      812            837       -25\n 6  2013     1     1      554            558        -4      740            728        12\n 7  2013     1     1      555            600        -5      913            854        19\n 8  2013     1     1      557            600        -3      709            723       -14\n 9  2013     1     1      557            600        -3      838            846        -8\n10  2013     1     1      558            600        -2      753            745         8\n# ‚Ñπ 336,766 more rows\n# ‚Ñπ 10 more variables: carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;,\n#   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,\n#   time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#the-pipe-in-action-1",
    "href": "slides/05-grammar-of-data-wrangling.html#the-pipe-in-action-1",
    "title": "Grammar of data wrangling",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\n1flights |&gt;\n2  filter(dest == \"RDU\")\n\n\n1\n\nTake the flights data frame,\n\n2\n\nand then filter for flights going to RDU\n\n\n\n\n# A tibble: 8,163 √ó 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     1      800            810       -10      949            955        -6\n 2  2013     1     1      832            840        -8     1006           1030       -24\n 3  2013     1     1      851            851         0     1032           1036        -4\n 4  2013     1     1      917            920        -3     1052           1108       -16\n 5  2013     1     1     1024           1030        -6     1204           1215       -11\n 6  2013     1     1     1127           1129        -2     1303           1309        -6\n 7  2013     1     1     1157           1205        -8     1342           1345        -3\n 8  2013     1     1     1240           1235         5     1415           1415         0\n 9  2013     1     1     1317           1325        -8     1454           1505       -11\n10  2013     1     1     1449           1450        -1     1651           1640        11\n# ‚Ñπ 8,153 more rows\n# ‚Ñπ 10 more variables: carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;,\n#   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,\n#   time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#the-pipe-in-action-2",
    "href": "slides/05-grammar-of-data-wrangling.html#the-pipe-in-action-2",
    "title": "Grammar of data wrangling",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\n1flights |&gt;\n2  filter(dest == \"RDU\") |&gt;\n3  group_by(carrier)\n\n\n1\n\nTake the flights data frame,\n\n2\n\nand then filter for flights going to RDU,\n\n3\n\nand then group by carrier\n\n\n\n\n# A tibble: 8,163 √ó 19\n# Groups:   carrier [5]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     1      800            810       -10      949            955        -6\n 2  2013     1     1      832            840        -8     1006           1030       -24\n 3  2013     1     1      851            851         0     1032           1036        -4\n 4  2013     1     1      917            920        -3     1052           1108       -16\n 5  2013     1     1     1024           1030        -6     1204           1215       -11\n 6  2013     1     1     1127           1129        -2     1303           1309        -6\n 7  2013     1     1     1157           1205        -8     1342           1345        -3\n 8  2013     1     1     1240           1235         5     1415           1415         0\n 9  2013     1     1     1317           1325        -8     1454           1505       -11\n10  2013     1     1     1449           1450        -1     1651           1640        11\n# ‚Ñπ 8,153 more rows\n# ‚Ñπ 10 more variables: carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;,\n#   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,\n#   time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#the-pipe-in-action-3",
    "href": "slides/05-grammar-of-data-wrangling.html#the-pipe-in-action-3",
    "title": "Grammar of data wrangling",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\n1flights |&gt;\n2  filter(dest == \"RDU\") |&gt;\n3  group_by(carrier) |&gt;\n4  summarize(mean_arr_delay = mean(arr_delay, na.rm = TRUE))\n\n\n1\n\nTake the flights data frame,\n\n2\n\nand then filter for flights going to RDU,\n\n3\n\nand then group by carrier,\n\n4\n\nand then calculate the mean arrival delay for each carrier\n\n\n\n\n# A tibble: 5 √ó 2\n  carrier mean_arr_delay\n  &lt;chr&gt;            &lt;dbl&gt;\n1 9E                9.67\n2 B6               13.3 \n3 EV               12.2 \n4 MQ                8.82\n5 UA               56"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#the-pipe-in-action-4",
    "href": "slides/05-grammar-of-data-wrangling.html#the-pipe-in-action-4",
    "title": "Grammar of data wrangling",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\n1flights |&gt;\n2  filter(dest == \"RDU\") |&gt;\n3  group_by(carrier) |&gt;\n4  summarize(mean_arr_delay = mean(arr_delay, na.rm = TRUE)) |&gt;\n5  arrange(desc(mean_arr_delay))\n\n\n1\n\nTake the flights data frame,\n\n2\n\nand then filter for flights going to RDU,\n\n3\n\nand then group by carrier,\n\n4\n\nand then calculate the mean arrival delay for each carrier,\n\n5\n\nand then arrange in descending order of mean arrival delay.\n\n\n\n\n# A tibble: 5 √ó 2\n  carrier mean_arr_delay\n  &lt;chr&gt;            &lt;dbl&gt;\n1 UA               56   \n2 B6               13.3 \n3 EV               12.2 \n4 9E                9.67\n5 MQ                8.82"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#column-operations",
    "href": "slides/05-grammar-of-data-wrangling.html#column-operations",
    "title": "Grammar of data wrangling",
    "section": "Column operations",
    "text": "Column operations\n\nselect(): changes whether or not a column is included.\nrename(): changes the name of columns.\nmutate(): changes the values of columns and creates new columns."
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#groups-of-rows",
    "href": "slides/05-grammar-of-data-wrangling.html#groups-of-rows",
    "title": "Grammar of data wrangling",
    "section": "Groups of rows",
    "text": "Groups of rows\n\nsummarize(): collapses a group into a single row.\ncount(): count unique values of one or more variables.\ngroup_by(): perform calculations separately for each value of a variable"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#ae-04-flights-wrangling",
    "href": "slides/05-grammar-of-data-wrangling.html#ae-04-flights-wrangling",
    "title": "Grammar of data wrangling",
    "section": "ae-04-flights-wrangling",
    "text": "ae-04-flights-wrangling\n\n\nGo to the project navigator in RStudio (top right corner of your RStudio window) and open the project called ae.\nIf there are any uncommitted files, commit them, and then click Pull.\nOpen the file called ae-04-flights-wrangling.qmd and render it."
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#recap-pipe",
    "href": "slides/05-grammar-of-data-wrangling.html#recap-pipe",
    "title": "Grammar of data wrangling",
    "section": "Recap: pipe",
    "text": "Recap: pipe\n\nThe pipe operator passes what comes before it into the function that comes after it as the first argument in that function.\n\n\nsum(1, 2)\n\n[1] 3\n\n1 |&gt; \n  sum(2)\n\n[1] 3\n\n\n\nAlways use a line break after the pipe, and indent the next line of code.\n\nJust like always use a line break between layers of ggplots, after +, and indent the next line."
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#recap-logical-operators",
    "href": "slides/05-grammar-of-data-wrangling.html#recap-logical-operators",
    "title": "Grammar of data wrangling",
    "section": "Recap: logical operators",
    "text": "Recap: logical operators\n\n\n\noperator\ndefinition\n\n\n\n\n&lt;\nis less than?\n\n\n&lt;=\nis less than or equal to?\n\n\n&gt;\nis greater than?\n\n\n&gt;=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#recap-logical-operators-1",
    "href": "slides/05-grammar-of-data-wrangling.html#recap-logical-operators-1",
    "title": "Grammar of data wrangling",
    "section": "Recap: logical operators",
    "text": "Recap: logical operators\n\n\n\n\n\n\n\noperator\ndefinition\n\n\n\n\nx & y\nis x AND y?\n\n\nx \\| y\nis x OR y?\n\n\nis.na(x)\nis x NA?\n\n\n!is.na(x)\nis x not NA?\n\n\nx %in% y\nis x in y?\n\n\n!(x %in% y)\nis x not in y?\n\n\n!x\nis not x? (only makes sense if x is TRUE or FALSE)\n\n\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#announcements",
    "href": "slides/15-linear-model-single-predictor.html#announcements",
    "title": "Linear regression with a single predictor",
    "section": "Announcements",
    "text": "Announcements\n\nWe did not finish AE 10 last time, answers are posted for review. Today‚Äôs AE 11 will review much of the material we didn‚Äôt get to in AE 10.\nThe midsemester course feedback survey is open until Sunday midnight. It‚Äôs on Canvas &gt; Quizzes, anonymous and optional but participation much appreciated!"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#questions-from-last-time",
    "href": "slides/15-linear-model-single-predictor.html#questions-from-last-time",
    "title": "Linear regression with a single predictor",
    "section": "Questions from last time",
    "text": "Questions from last time\n\nCan you iterate using a function with multiple variables?\n\nYes, a function can have multiple inputs (just like, for example, the *_join() functions we‚Äôve used take at least two inputs ‚Äì the two data frames to be joined). We won‚Äôt cover writing functions in detail in this class but R4DS - Chp 25 is a good resource for getting started, and STA 323 goes into this topic deeper.\n\n\nCan you get special permission to scrape (if so, how common is this?)\n\nProbably not? They would just give you the data! Or access to an API where you can fetch the data from."
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#questions-from-last-time-1",
    "href": "slides/15-linear-model-single-predictor.html#questions-from-last-time-1",
    "title": "Linear regression with a single predictor",
    "section": "Questions from last time",
    "text": "Questions from last time\n\nDo we have to use OpenIntro for data modelling?\n\nYes, I recommend the readings from the OpenIntro book for modeling, where relevant they‚Äôre linked from the prepare materials."
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#goals",
    "href": "slides/15-linear-model-single-predictor.html#goals",
    "title": "Linear regression with a single predictor",
    "section": "Goals",
    "text": "Goals\n\nModeling with a single predictor\nModel parameters, estimates, and error terms\nInterpreting slopes and intercepts"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#setup",
    "href": "slides/15-linear-model-single-predictor.html#setup",
    "title": "Linear regression with a single predictor",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(fivethirtyeight) # for the fandango dataset"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#spurious-correlations",
    "href": "slides/15-linear-model-single-predictor.html#spurious-correlations",
    "title": "Linear regression with a single predictor",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\n\nSource: tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#spurious-correlations-1",
    "href": "slides/15-linear-model-single-predictor.html#spurious-correlations-1",
    "title": "Linear regression with a single predictor",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\n\nSource: tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#data-prep",
    "href": "slides/15-linear-model-single-predictor.html#data-prep",
    "title": "Linear regression with a single predictor",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the dataset as movie_scores\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(\n    critics = rottentomatoes, \n    audience = rottentomatoes_user\n  )"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#data-overview",
    "href": "slides/15-linear-model-single-predictor.html#data-overview",
    "title": "Linear regression with a single predictor",
    "section": "Data overview",
    "text": "Data overview\n\nmovie_scores |&gt;\n  select(critics, audience)\n\n# A tibble: 146 √ó 2\n   critics audience\n     &lt;int&gt;    &lt;int&gt;\n 1      74       86\n 2      85       80\n 3      80       90\n 4      18       84\n 5      14       28\n 6      63       62\n 7      42       53\n 8      86       64\n 9      99       82\n10      89       87\n# ‚Ñπ 136 more rows"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#data-visualization",
    "href": "slides/15-linear-model-single-predictor.html#data-visualization",
    "title": "Linear regression with a single predictor",
    "section": "Data visualization",
    "text": "Data visualization"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#regression-model-1",
    "href": "slides/15-linear-model-single-predictor.html#regression-model-1",
    "title": "Linear regression with a single predictor",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the outcome, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#regression-model",
    "href": "slides/15-linear-model-single-predictor.html#regression-model",
    "title": "Linear regression with a single predictor",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{#325b74}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{#325b74}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{#325b74}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#simple-linear-regression",
    "href": "slides/15-linear-model-single-predictor.html#simple-linear-regression",
    "title": "Linear regression with a single predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nUse simple linear regression to model the relationship between a quantitative outcome (\\(Y\\)) and a single quantitative predictor (\\(X\\)): \\[\\Large{Y = \\beta_0 + \\beta_1 X + \\epsilon}\\]\n\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error (residual)"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#simple-linear-regression-1",
    "href": "slides/15-linear-model-single-predictor.html#simple-linear-regression-1",
    "title": "Linear regression with a single predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\\[\\Large{\\hat{Y} = b_0 + b_1 X}\\]\n\n\\(b_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\\(b_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#choosing-values-for-b_1-and-b_0",
    "href": "slides/15-linear-model-single-predictor.html#choosing-values-for-b_1-and-b_0",
    "title": "Linear regression with a single predictor",
    "section": "Choosing values for \\(b_1\\) and \\(b_0\\)",
    "text": "Choosing values for \\(b_1\\) and \\(b_0\\)"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#residuals",
    "href": "slides/15-linear-model-single-predictor.html#residuals",
    "title": "Linear regression with a single predictor",
    "section": "Residuals",
    "text": "Residuals\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y - \\hat{y}\\]"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#least-squares-line",
    "href": "slides/15-linear-model-single-predictor.html#least-squares-line",
    "title": "Linear regression with a single predictor",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe least squares line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#least-squares-line-1",
    "href": "slides/15-linear-model-single-predictor.html#least-squares-line-1",
    "title": "Linear regression with a single predictor",
    "section": "Least squares line",
    "text": "Least squares line\n\nmovies_fit &lt;- linear_reg() |&gt;\n  fit(audience ~ critics, data = movie_scores)\n\ntidy(movies_fit)\n\n# A tibble: 2 √ó 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#properties-of-least-squares-regression",
    "href": "slides/15-linear-model-single-predictor.html#properties-of-least-squares-regression",
    "title": "Linear regression with a single predictor",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point (the coordinates corresponding to average \\(X\\) and average \\(Y\\)): \\(b_0 = \\bar{Y} - b_1~\\bar{X}\\)\nSlope has the same sign as the correlation coefficient: \\(b_1 = r \\frac{s_Y}{s_X}\\)\nSum of the residuals is zero: \\(\\sum_{i = 1}^n \\epsilon_i = 0\\)\nResiduals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#interpreting-the-slope",
    "href": "slides/15-linear-model-single-predictor.html#interpreting-the-slope",
    "title": "Linear regression with a single predictor",
    "section": "Interpreting the slope",
    "text": "Interpreting the slope\n\nQuestionSubmit\n\n\n\nThe slope of the model for predicting audience score from critics score is 0.519. Which of the following is the best interpretation of this value?\n\n\nFor every one point increase in the critics score, the audience score goes up by 0.519 points, on average.\nFor every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\nFor every one point increase in the critics score, the audience score goes up by 0.519 points.\nFor every one point increase in the audience score, the critics score goes up by 0.519 points, on average."
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#interpreting-slope-intercept",
    "href": "slides/15-linear-model-single-predictor.html#interpreting-slope-intercept",
    "title": "Linear regression with a single predictor",
    "section": "Interpreting slope & intercept",
    "text": "Interpreting slope & intercept\n\\[\\widehat{\\text{audience}} = 32.3 + 0.519 \\times \\text{critics}\\]\n\n\nSlope: For every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\nIntercept: If the critics score is 0 points, we expect the audience score to be 32.3 points."
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#is-the-intercept-meaningful",
    "href": "slides/15-linear-model-single-predictor.html#is-the-intercept-meaningful",
    "title": "Linear regression with a single predictor",
    "section": "Is the intercept meaningful?",
    "text": "Is the intercept meaningful?\n‚úÖ The intercept is meaningful in context of the data if\n\nthe predictor can feasibly take values equal to or near zero or\nthe predictor has values near zero in the observed data\n\n\nüõë Otherwise, it might not be meaningful!"
  },
  {
    "objectID": "slides/15-linear-model-single-predictor.html#application-exercise-ae-11-penguins-modeling",
    "href": "slides/15-linear-model-single-predictor.html#application-exercise-ae-11-penguins-modeling",
    "title": "Linear regression with a single predictor",
    "section": "Application exercise: ae-11-penguins-modeling",
    "text": "Application exercise: ae-11-penguins-modeling\n\n\nGo back to your project called ae.\nIf there are any uncommitted files, commit them, and push.\nPull, and then work on ae-11-penguins-modeling.qmd.\n\n\n\n\n\n\nüîó sta199-s24.github.io ¬†¬∑¬† ‚ùì Ask on Ed"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Course GitHub organization\nüîó on GitHub\n\n\nRStudio containers\nüîó on Duke Container Manager\n\n\nOffice hours\nüîó on Google Sheets\n\n\nEd Discussion\nüîó on Canvas\n\n\nClass recordings\nüîó on Panopto\n\n\nGradescope\nüîó on Canvas\n\n\nGradebook\nüîó on Canvas\n\n\nTexbooks\nüîó R for Data Science\nüîó Introduction to Modern Statistics\n\n\nPackage documentation\nüîó ggplot2: ggplot2.tidyverse.org\nüîó dplyr: dplyr.tidyverse.org\nüîó tidyr: tidyr.tidyverse.org\nüîó forcats: forcats.tidyverse.org\nüîó stringr: stringr.tidyverse.org\nüîó lubridate: lubridate.tidyverse.org\nüîó readr: readr.tidyverse.org\nüîó readxl: readxl.tidyverse.org",
    "crumbs": [
      "Course information",
      "Useful links"
    ]
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA198-199 on the Reservations available menu on the right. You only need to do this once, and when you do, you‚Äôll see this container moved to the My reservations menu on the left.\nNext, click on STA198-199 under My reservations to access the RStudio instance you‚Äôll use for the course.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone‚Äôs office hours here.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#ed-discussion",
    "href": "course-support.html#ed-discussion",
    "title": "Course support",
    "section": "Ed Discussion",
    "text": "Ed Discussion\nHave a question that can‚Äôt wait for office hours? Prefer to write out your question in detail rather than asking in person? The course discussion forum, Ed Discussion, is the best venue for these! There is a chance another student has already asked a similar question, so please check the other posts on before asking a new question. If you know the answer to a question that is posted, I encourage you to respond!",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go to Ed Discussion), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email Dr.¬†Mine √áetinkaya-Rundel at mc301@duke.edu.\nIf there is a question that‚Äôs not appropriate for the public forum, you are welcome to email me directly. If you email me, please include ‚ÄúSTA 199‚Äù in the subject line. Barring extenuating circumstances, I will respond to STA 199 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times.¬† Duke encourages all students to access these resources.\n\nCAPS: Duke Counseling & Pyschological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000.\nDuWell: (919) 681-8421, provides Moments of Mindfulness (stress management and resilience building) and meditation programming to assist students in developing a daily emotional well-being practice. To see schedules for programs please see https://studentaffairs.duke.edu/duwell. All are welcome and no experience necessary.\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student‚Äôs behavior or health visit the website for resources and assistance: http://studentaffairs.duke.edu/dukereach.\nTimelyCare: (formerly known as Blue Devils Care) An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling: https://bluedevilscare.duke.edu.\nTwo-Click Support: Duke Student Government and DukeReach partnership that connects students to help in just two clicks: https://bit.ly/TwoClickSupport.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#course-costs",
    "href": "course-support.html#course-costs",
    "title": "Course support",
    "section": "Course costs",
    "text": "Course costs\n\nTextbooks: The textbooks for this course are freely available on the web.\nLaptops: Each student is expected to have a laptop they can bring to each lecture and lab.\n\nIf you are having difficulty with costs associated with this course, here are some resources:\n\nContact the financial aid office¬†(whether or not you are on aid). They have¬†loans and¬†resources for connecting students with programs on campus that might be able to help alleviate these costs.\nDukeLIFE offers course materials assistance for eligible students. Please note that¬†students who are eligible for DukeLIFE benefits are notified prior to the start of the semester; program resources are limited.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-canvas",
    "href": "course-support.html#assistance-with-zoom-or-canvas",
    "title": "Course support",
    "section": "Assistance with Zoom or Canvas",
    "text": "Assistance with Zoom or Canvas\nFor technical help with Canvas or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Canvas here.\nNote that we will be making minimal use of Canvas in this course (primarily for announcements and grade book). All assignment submission will take place on GitHub and conversation on Ed Discussion.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  }
]